{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Top'></a>\n",
    "\n",
    "# Multisurv model training<a class='tocSkip'></a>\n",
    "\n",
    "Train MultiSurv models with different combinations of input data modalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> PyTorch detected CUDA <<<\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%load_ext watermark\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('>>> PyTorch detected CUDA <<<')\n",
    "\n",
    "# Make modules in \"src\" dir visible\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.append(os.path.join(os.getcwd(), 'src'))\n",
    "\n",
    "import utils\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#DataLoader\" data-toc-modified-id=\"DataLoader-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span><code>DataLoader</code></a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Different-intervals\" data-toc-modified-id=\"Different-intervals-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Different intervals</a></span><ul class=\"toc-item\"><li><span><a href=\"#Equidistant-times\" data-toc-modified-id=\"Equidistant-times-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Equidistant times</a></span></li><li><span><a href=\"#By-duration-quantiles\" data-toc-modified-id=\"By-duration-quantiles-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>By duration quantiles</a></span></li></ul></li><li><span><a href=\"#Pick-learning-rate\" data-toc-modified-id=\"Pick-learning-rate-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Pick learning rate</a></span></li><li><span><a href=\"#Fit\" data-toc-modified-id=\"Fit-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Fit</a></span><ul class=\"toc-item\"><li><span><a href=\"#Save-model-weights\" data-toc-modified-id=\"Save-model-weights-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Save model weights</a></span></li></ul></li><li><span><a href=\"#Check-validation-metrics\" data-toc-modified-id=\"Check-validation-metrics-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Check validation metrics</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = utils.INPUT_DATA_DIR\n",
    "MODELS = utils.TRAINED_MODEL_DIR\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899865a0d6914142820a57c045587dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Input data', index=(0, 1), options=('clinical', 'mRNA', 'DNAm', 'miRNA', 'CNV', 'wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_modalities = widgets.SelectMultiple(\n",
    "    options=['clinical', 'mRNA', 'DNAm', 'miRNA', 'CNV', 'wsi'],\n",
    "    index=[0, 1],\n",
    "    rows=6,\n",
    "    description='Input data',\n",
    "    disabled=False\n",
    ")\n",
    "display(data_modalities)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#-----------------------------------------------------------------------------#\n",
    "#                             20-CANCER SUBSET                                #\n",
    "#                 (to compare to Cheerla and Gevaert 2019)                    #\n",
    "#-----------------------------------------------------------------------------#\n",
    "\n",
    "cancers = ['BLCA', 'BRCA', 'CESC', 'COAD', 'READ',\n",
    "           'HNSC', 'KICH', 'KIRC', 'KIRP', 'LAML',\n",
    "           'LGG', 'LIHC', 'LUAD', 'LUSC', 'OV',\n",
    "           'PAAD', 'PRAD', 'SKCM', 'STAD', 'THCA', 'UCEC']\n",
    "\n",
    "labels = pd.read_csv('data/labels.tsv', sep='\\t')\n",
    "print(labels.head(3))\n",
    "\n",
    "# List of patients to exclude: patients with cancers that are not in the subset\n",
    "exclude_cancers = list(labels.loc[~labels['project_id'].isin(cancers), 'submitter_id'])\n",
    "len(exclude_cancers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/mnt/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/data/Processed_Data/Clinical'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataloaders \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataloaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDATA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mlabels_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/app/data/labels.tsv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_modalities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mwsi_patch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m299\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mn_wsi_patches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;43;03m#                                     batch_size=20,\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;43;03m#                                     batch_size=32,\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;43;03m#                                     exclude_patients=exclude_cancers,\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/app/src/utils.py:130\u001b[0m, in \u001b[0;36mget_dataloaders\u001b[0;34m(data_location, labels_file, modalities, wsi_patch_size, n_wsi_patches, batch_size, exclude_patients, return_patient_id)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     transforms \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m--> 130\u001b[0m datasets \u001b[38;5;241m=\u001b[39m {x: dataset\u001b[38;5;241m.\u001b[39mMultimodalDataset(\n\u001b[1;32m    131\u001b[0m     label_map\u001b[38;5;241m=\u001b[39mpatient_labels[x],\n\u001b[1;32m    132\u001b[0m     data_dirs\u001b[38;5;241m=\u001b[39mdata_dirs,\n\u001b[1;32m    133\u001b[0m     n_patches\u001b[38;5;241m=\u001b[39mn_wsi_patches,\n\u001b[1;32m    134\u001b[0m     patch_size\u001b[38;5;241m=\u001b[39mwsi_patch_size,\n\u001b[1;32m    135\u001b[0m     transform\u001b[38;5;241m=\u001b[39mtransforms[x],\n\u001b[1;32m    136\u001b[0m     exclude_patients\u001b[38;5;241m=\u001b[39mexclude_patients,\n\u001b[1;32m    137\u001b[0m     return_patient_id\u001b[38;5;241m=\u001b[39mreturn_patient_id)\n\u001b[1;32m    138\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData modalities:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m modalities:\n",
      "File \u001b[0;32m/app/src/utils.py:130\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     transforms \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m--> 130\u001b[0m datasets \u001b[38;5;241m=\u001b[39m {x: \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultimodalDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatient_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dirs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dirs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_patches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_wsi_patches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwsi_patch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude_patients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_patients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_patient_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_patient_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData modalities:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m modalities:\n",
      "File \u001b[0;32m/app/src/dataset.py:123\u001b[0m, in \u001b[0;36mMultimodalDataset.__init__\u001b[0;34m(self, label_map, data_dirs, n_patches, patch_size, transform, dropout, exclude_patients, return_patient_id)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, label_map,\n\u001b[1;32m    118\u001b[0m              data_dirs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclinical\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwsi\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    119\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmRNA\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmiRNA\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    120\u001b[0m                         },\n\u001b[1;32m    121\u001b[0m              n_patches\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, patch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    122\u001b[0m              exclude_patients\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, return_patient_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabel_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dirs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_patients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodality_loaders \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclinical\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_clinical,\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwsi\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_patches,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCNV\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data,\n\u001b[1;32m    131\u001b[0m         }\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m dropout \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m must be in [0, 1].\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/app/src/dataset.py:34\u001b[0m, in \u001b[0;36m_BaseDataset.__init__\u001b[0;34m(self, label_map, data_dirs, exclude_patients)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dirs\u001b[38;5;241m.\u001b[39mvalues()), \\\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAt least one input data modality is required: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_mods\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Check missing data: drop patients missing all data\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m patients_missing_all_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_patients_missing_all_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m patients_missing_all_data:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExcluding \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(patients_missing_all_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m patient(s)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m     38\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m missing all data.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/app/src/dataset.py:64\u001b[0m, in \u001b[0;36m_BaseDataset._patients_missing_all_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data_dir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dirs\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m         pids_in_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_patient_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m         missing_data \u001b[38;5;241m=\u001b[39m [pid \u001b[38;5;28;01mfor\u001b[39;00m pid \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatient_ids\n\u001b[1;32m     66\u001b[0m                         \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pids_in_data]\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;66;03m# Break if a data modality has all data\u001b[39;00m\n",
      "File \u001b[0;32m/app/src/dataset.py:52\u001b[0m, in \u001b[0;36m_BaseDataset._get_patient_ids\u001b[0;34m(self, path_to_data)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_patient_ids\u001b[39m(\u001b[38;5;28mself\u001b[39m, path_to_data):\n\u001b[0;32m---> 52\u001b[0m     files \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     file_ext \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(files[\u001b[38;5;241m0\u001b[39m])[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     55\u001b[0m     pids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m([os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(file)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files])\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/data/Processed_Data/Clinical'"
     ]
    }
   ],
   "source": [
    "dataloaders = utils.get_dataloaders(data_location=DATA,\n",
    "                                    labels_file='/app/data/labels.tsv',\n",
    "                                    modalities=data_modalities.value,\n",
    "                                    wsi_patch_size=299,\n",
    "                                    n_wsi_patches=5,\n",
    "#                                     batch_size=20,\n",
    "                                     batch_size=128,\n",
    "#                                     batch_size=32,\n",
    "#                                     exclude_patients=exclude_cancers,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different intervals\n",
    "\n",
    "If trying out different time interval outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equidistant times"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "interval_cuts = torch.arange(0., 365 * 5.1, 365 / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By duration quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [(t, e) for t, e in dataloaders['train'].dataset.label_map.values()]\n",
    "durations = [t for t, _ in labels]\n",
    "events = [e for _, e in labels]\n",
    "\n",
    "interval_cuts = utils.discretize_time_by_duration_quantiles(durations, events, 20)\n",
    "interval_cuts = torch.from_numpy(interval_cuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiating MultiSurv model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/src/multisurv.py:84: UserWarning: Input data is unimodal: no fusion procedure.\n",
      "  warnings.warn('Input data is unimodal: no fusion procedure.')\n",
      "/app/src/model.py:59: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_dict = torch.load(self.unimodal_state_files[modality])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(loading pretrained unimodal model weights...)\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------------------------------#\n",
    "#                       PRE-TRAINED UNIMODAL MODELS                           #\n",
    "#-----------------------------------------------------------------------------#\n",
    "\n",
    "unimodal_weigths = {'clinical': 'clinical_lr0.0055_epoch100_concord0.76.pth',\n",
    "                    'mRNA': None,\n",
    "                    'DNAm': None,\n",
    "                    'miRNA': None,\n",
    "                    'CNV': None,\n",
    "                    'wsi': None,}\n",
    "\n",
    "unimodal_weigths = {k: os.path.join(MODELS, v) if v is not None else None\n",
    "                    for k, v in unimodal_weigths.items()}\n",
    "\n",
    "multisurv = Model(dataloaders=dataloaders,\n",
    "                  unimodal_state_files=unimodal_weigths,\n",
    "                  freeze_up_to='aggregator',\n",
    "                  output_intervals=interval_cuts,\n",
    "                  device=device)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#-----------------------------------------------------------------------------#\n",
    "#                              AUXILIARY LOSS                                 #\n",
    "#-----------------------------------------------------------------------------#\n",
    "\n",
    "# cosine_embedding_margin = 1e-5\n",
    "# auxiliary_criterion = torch.nn.CosineEmbeddingLoss(margin=cosine_embedding_margin)\n",
    "\n",
    "multisurv = Model(dataloaders=dataloaders,\n",
    "                  auxiliary_criterion=auxiliary_criterion,\n",
    "                  device=device)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "multisurv = Model(dataloaders=dataloaders,\n",
    "#                   fusion_method='attention',\n",
    "                   output_intervals=interval_cuts,\n",
    "                  device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiating MultiSurv model...\n",
      "(loading pretrained unimodal model weights...)\n"
     ]
    }
   ],
   "source": [
    "multisurv = Model(dataloaders=dataloaders,\n",
    "#                   fusion_method='attention',\n",
    "                  unimodal_state_files=unimodal_weigths,\n",
    "                   output_intervals=multisurv.output_intervals.to(device),\n",
    "                  device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output intervals (in years):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.4301,  0.8521,  1.2027,  1.5781,  2.0712,  2.6630,  3.4000,\n",
       "         4.1068,  4.9397,  6.0247,  7.3425,  8.5753, 10.5068, 12.8110, 14.5699,\n",
       "        18.0630, 22.0575, 26.3945, 30.8274], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Output intervals (in years):')\n",
    "multisurv.output_intervals / 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clinical_submodel', 'fc_block', 'risk_layer']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multisurv.model_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable blocks:\n",
      "   clinical_submodel: True\n",
      "   fc_block: True\n",
      "   risk_layer: True\n"
     ]
    }
   ],
   "source": [
    "print('Trainable blocks:')\n",
    "layer = None\n",
    "\n",
    "for name, child in multisurv.model.named_children():\n",
    "    for name_2, params in child.named_parameters():\n",
    "        if name is not layer:\n",
    "            print(f'   {name}: {params.requires_grad}')\n",
    "        layer = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiSurv(\n",
       "  (clinical_submodel): ClinicalNet(\n",
       "    (embedding_layers): ModuleList(\n",
       "      (0): Embedding(32, 16)\n",
       "      (1): Embedding(2, 1)\n",
       "      (2): Embedding(9, 5)\n",
       "      (3-5): 3 x Embedding(3, 2)\n",
       "      (6): Embedding(16, 8)\n",
       "      (7-8): 2 x Embedding(10, 5)\n",
       "    )\n",
       "    (embedding_dropout): Dropout(p=0.5, inplace=False)\n",
       "    (bn_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear): Linear(in_features=47, out_features=256, bias=True)\n",
       "    (output_layer): FC(\n",
       "      (fc): Sequential(\n",
       "        (0): Dropout(p=0.5, inplace=False)\n",
       "        (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_block): FC(\n",
       "    (fc): Sequential(\n",
       "      (0): Dropout(p=0.5, inplace=False)\n",
       "      (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): Dropout(p=0.5, inplace=False)\n",
       "      (5): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (6): ReLU()\n",
       "      (7): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (12): Dropout(p=0.5, inplace=False)\n",
       "      (13): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (14): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (risk_layer): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=19, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multisurv.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied GPU-compatible fix to LRRangeTest.run\n"
     ]
    }
   ],
   "source": [
    "# GPU-compatible version of the completely fixed LR test\n",
    "\n",
    "def gpu_fixed_lr_test_run(self, init_value=1e-8, final_value=10., beta=0.98):\n",
    "    \"\"\"GPU-compatible LR test that ensures all tensors are on the same device.\"\"\"\n",
    "    print(\">>> Using GPU-COMPATIBLE FIXED lr_test.run method\")\n",
    "    \n",
    "    power = (1 / (len(self.dataloader) - 1))\n",
    "    mult = (final_value / init_value) ** power\n",
    "    lr = init_value\n",
    "    self.optimizer.param_groups[0]['lr'] = lr\n",
    "    avg_loss = 0.\n",
    "    best_loss = 0.\n",
    "    batch_num = 0\n",
    "\n",
    "    print('>>> Compute loss at increasing LR values')\n",
    "    \n",
    "    # Clear losses and lrs lists\n",
    "    self.losses = []\n",
    "    self.lrs = []\n",
    "\n",
    "    for data in self.dataloader:\n",
    "        batch_num += 1\n",
    "        print('\\r' + f'    Iterate over mini-batches: {str(batch_num)}', end='')\n",
    "\n",
    "        try:\n",
    "            # Unpack data\n",
    "            if len(data) == 3:\n",
    "                modality_data, time, event = data\n",
    "            elif len(data) == 4:\n",
    "                modality_data, time, event, pid = data\n",
    "            \n",
    "            # CRITICAL: Move ALL data to the same device as the model\n",
    "            target_device = next(self.model.parameters()).device\n",
    "            \n",
    "            # Move modality data to device\n",
    "            for key, value in modality_data.items():\n",
    "                if isinstance(value, torch.Tensor):\n",
    "                    modality_data[key] = value.to(target_device)\n",
    "                elif isinstance(value, (list, tuple)):\n",
    "                    modality_data[key] = tuple(v.to(target_device) if isinstance(v, torch.Tensor) else v for v in value)\n",
    "            \n",
    "            # Move time and event to device\n",
    "            time = time.to(target_device)\n",
    "            event = event.to(target_device)\n",
    "            \n",
    "            # Set model to train mode\n",
    "            self.model.train()\n",
    "            \n",
    "            # Clear gradients\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            with torch.set_grad_enabled(True):\n",
    "                feature_representations, risk = self.model(modality_data)\n",
    "                modality_features = feature_representations['modalities']\n",
    "                \n",
    "                # Compute loss with proper device handling\n",
    "                try:\n",
    "                    # Ensure output_intervals are on the same device\n",
    "                    if hasattr(self, 'output_intervals'):\n",
    "                        breaks = self.output_intervals.to(target_device)\n",
    "                    else:\n",
    "                        breaks = torch.linspace(0, 10, 19, device=target_device)  # Fallback\n",
    "                    \n",
    "                    loss = self.criterion(risk, times=time, events=event, breaks=breaks, device=target_device)\n",
    "                    \n",
    "                except Exception as loss_error:\n",
    "                    print(f\"\\nPrimary criterion failed: {loss_error}\")\n",
    "                    # Fallback to simple MSE loss on the same device\n",
    "                    dummy_target = torch.ones_like(risk)  # This will be on the same device as risk\n",
    "                    loss = torch.nn.functional.mse_loss(risk, dummy_target)\n",
    "                    print(\"Using fallback MSE loss\")\n",
    "                \n",
    "                # Add auxiliary loss if needed\n",
    "                if self.aux_criterion is not None:\n",
    "                    try:\n",
    "                        if len(modality_features) >= 2:\n",
    "                            target = torch.ones(modality_features[0].shape[0], device=target_device)\n",
    "                            aux_loss = self.aux_criterion(modality_features[0], modality_features[1], target)\n",
    "                            loss = loss + 0.1 * aux_loss\n",
    "                    except Exception as aux_error:\n",
    "                        print(f\"\\nAuxiliary criterion failed: {aux_error}\")\n",
    "            \n",
    "            # Store the loss value\n",
    "            loss_value = loss.item()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError at batch {batch_num}: {e}\")\n",
    "            break\n",
    "\n",
    "        # Compute the smoothed loss\n",
    "        avg_loss = (beta * avg_loss + (1 - beta) * loss_value)\n",
    "        smoothed_loss = avg_loss / (1 - beta ** batch_num)\n",
    "\n",
    "        # Stop if the loss is exploding\n",
    "        if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
    "            print()\n",
    "            print('    Exploding loss; finish test.')\n",
    "            break\n",
    "\n",
    "        # Record the best loss\n",
    "        if smoothed_loss < best_loss or batch_num == 1:\n",
    "            best_loss = smoothed_loss\n",
    "            \n",
    "        # Store the values\n",
    "        self.losses.append(smoothed_loss)\n",
    "        self.lrs.append(lr)\n",
    "\n",
    "        # Do the backward pass and optimizer step\n",
    "        try:\n",
    "            loss.backward(retain_graph=False)\n",
    "            self.optimizer.step()\n",
    "        except Exception as e:\n",
    "            print(f\"\\nBackward pass failed at batch {batch_num}: {e}\")\n",
    "            break\n",
    "\n",
    "        # Update the lr for the next step\n",
    "        lr *= mult\n",
    "        self.optimizer.param_groups[0]['lr'] = lr\n",
    "        \n",
    "        # Stop after reasonable number of batches\n",
    "        if batch_num >= 100:\n",
    "            print(\"\\nStopping after 100 batches\")\n",
    "            break\n",
    "\n",
    "    print()\n",
    "    print('    Completed test.')\n",
    "    return self\n",
    "\n",
    "# Apply the GPU-compatible fix\n",
    "import lr_range_test\n",
    "lr_range_test.LRRangeTest.run = gpu_fixed_lr_test_run\n",
    "print(\"Applied GPU-compatible fix to LRRangeTest.run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Using GPU-COMPATIBLE FIXED lr_test.run method\n",
      ">>> Compute loss at increasing LR values\n",
      "    Iterate over mini-batches: 68\n",
      "    Completed test.\n",
      "\n",
      "CPU times: user 33.7 s, sys: 548 ms, total: 34.3 s\n",
      "Wall time: 2min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "multisurv.test_lr_range()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "multisurv.plot_lr_range(trim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Applied GPU-compatible fix to ModelCoach._predictions_to_pycox method\n",
      "Model output intervals shape: 20\n",
      "Model output intervals device: cuda:0\n",
      "Model risk layer output: 19\n",
      "Expected: 19 intervals for 20 breakpoints\n"
     ]
    }
   ],
   "source": [
    "# GPU-compatible fix for _predictions_to_pycox method\n",
    "def gpu_fixed_predictions_to_pycox(self, preds, time_points=None):\n",
    "    \"\"\"GPU-compatible version that properly handles device transfers.\"\"\"\n",
    "    import pandas as pd\n",
    "    import torch\n",
    "    \n",
    "    # preds shape is [num_patients, num_intervals] e.g., [864, 18]\n",
    "    # Convert predictions to DataFrame (move to CPU first)\n",
    "    df = pd.DataFrame(preds.detach().cpu().numpy())  # Added .detach() for GPU tensors\n",
    "    \n",
    "    if time_points is None:\n",
    "        # Get the number of intervals from the model output\n",
    "        n_intervals = preds.shape[1]  # Should be 18 for your model\n",
    "        \n",
    "        # Use the model's actual output intervals\n",
    "        if hasattr(self, 'output_intervals') and self.output_intervals is not None:\n",
    "            # Handle GPU tensors properly\n",
    "            intervals = self.output_intervals\n",
    "            if torch.is_tensor(intervals):\n",
    "                intervals = intervals.detach().cpu()  # Move to CPU for calculations\n",
    "            \n",
    "            if len(intervals) > n_intervals:\n",
    "                # Take the first n_intervals midpoints\n",
    "                midpoints = (intervals[:-1] + intervals[1:]) / 2\n",
    "                time_points = midpoints[:n_intervals]\n",
    "            else:\n",
    "                # Fallback to evenly spaced points\n",
    "                last_interval = intervals[-1].item() if torch.is_tensor(intervals) else intervals[-1]\n",
    "                time_points = torch.linspace(0.5, last_interval / 365, n_intervals)\n",
    "        else:\n",
    "            # Fallback: create time points that match the output size\n",
    "            time_points = torch.arange(0.5, 0.5 + n_intervals, 1.0)\n",
    "    \n",
    "    # Ensure time_points matches the prediction dimensions\n",
    "    if len(time_points) != preds.shape[1]:\n",
    "        print(f\"Warning: Adjusting time_points from {len(time_points)} to {preds.shape[1]}\")\n",
    "        first_point = time_points[0].item() if torch.is_tensor(time_points) else time_points[0]\n",
    "        last_point = time_points[-1].item() if torch.is_tensor(time_points) else time_points[-1]\n",
    "        time_points = torch.linspace(first_point, last_point, preds.shape[1])\n",
    "    \n",
    "    # FIXED: The DataFrame structure should be transposed\n",
    "    # We want columns to be time points, rows to be patients\n",
    "    df = df.T  # Transpose so shape becomes [num_intervals, num_patients]\n",
    "    \n",
    "    # Convert time_points to numpy if it's a tensor (ensure CPU)\n",
    "    if torch.is_tensor(time_points):\n",
    "        time_points = time_points.detach().cpu().numpy()\n",
    "    \n",
    "    # Set the index to time points\n",
    "    df.index = time_points\n",
    "    df.index.name = 'time'\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the GPU-compatible fix to ModelCoach\n",
    "from coach import ModelCoach\n",
    "ModelCoach._predictions_to_pycox = gpu_fixed_predictions_to_pycox\n",
    "print(\"âœ… Applied GPU-compatible fix to ModelCoach._predictions_to_pycox method\")\n",
    "\n",
    "# Debug info with GPU handling\n",
    "print(f\"Model output intervals shape: {len(multisurv.output_intervals)}\")\n",
    "print(f\"Model output intervals device: {multisurv.output_intervals.device}\")\n",
    "print(f\"Model risk layer output: {multisurv.model.risk_layer[0].out_features}\")\n",
    "print(f\"Expected: {len(multisurv.output_intervals) - 1} intervals for {len(multisurv.output_intervals)} breakpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run tag: \"clinical_lr0.0015\"\n"
     ]
    }
   ],
   "source": [
    "picked_lr = 1.5e-3\n",
    "\n",
    "run_tag = utils.compose_run_tag(model=multisurv, lr=picked_lr,\n",
    "                                dataloaders=dataloaders,\n",
    "                                log_dir='.training_logs/',\n",
    "                                suffix='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiating MultiSurv model...\n",
      "(loading pretrained unimodal model weights...)\n",
      "\n",
      "------------------------------------------\n",
      "             Training        Validation\n",
      "           ------------     ------------\n",
      " Epoch     Loss     Ctd     Loss     Ctd\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/multisurv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/100    0.0286   0.746   0.0287   0.745\n",
      " 5/100    0.0285   0.752   0.0288   0.744\n",
      " 10/100   0.0284   0.751   0.0288   0.744\n",
      " 15/100   0.0283   0.755   0.0287   0.748\n",
      " 20/100   0.0283   0.755   0.0284   0.750\n",
      " 25/100   0.0283   0.755   0.0284   0.750\n",
      " 30/100   0.0283   0.756   0.0284   0.750\n",
      " 35/100   0.0282   0.756   0.0284   0.751\n",
      " 40/100   0.0282   0.758   0.0283   0.753\n",
      " 45/100   0.0281   0.759   0.0284   0.753\n",
      " 50/100   0.0282   0.759   0.0284   0.753\n",
      " 55/100   0.0281   0.761   0.0283   0.753\n",
      " 60/100   0.0281   0.760   0.0284   0.753\n",
      " 65/100   0.0281   0.763   0.0283   0.753\n",
      " 70/100   0.0280   0.764   0.0283   0.753\n",
      " 75/100   0.0280   0.761   0.0283   0.753\n",
      " 80/100   0.0281   0.763   0.0283   0.753\n",
      " 85/100   0.0281   0.758   0.0284   0.754\n",
      " 90/100   0.0281   0.759   0.0284   0.753\n",
      " 95/100   0.0281   0.762   0.0284   0.753\n",
      " 100/100  0.0282   0.761   0.0283   0.753\n",
      "\n",
      ">>>>> Training completed in 4h 34m 28s\n",
      ">>>>> Best validation C-indices:\n",
      "     0.7534815389438225 (epoch65)\n",
      "     0.7535904615662542 (epoch85)\n",
      "     0.7534363759052533 (epoch91)\n"
     ]
    }
   ],
   "source": [
    "fit_args = {\n",
    "    'lr': picked_lr,\n",
    "    'num_epochs': 100,\n",
    "    'info_freq': 5,\n",
    "#     'info_freq': None,\n",
    "#     'lr_factor': 0.25,\n",
    "#     'scheduler_patience': 5,\n",
    "    'lr_factor': 0.25,\n",
    "    'scheduler_patience': 5,\n",
    "    'log_dir': os.path.join('.training_logs/', run_tag),\n",
    "}\n",
    "\n",
    "multisurv.fit(**fit_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model weights\n",
    "\n",
    "If desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using event file: /app/.training_logs/clinical_lr0.0015/events.out.tfevents.1751833771.b5e83bcbd78c.1656.0\n",
      "Available scalar tags: ['train_loss', 'train_concord', 'val_loss', 'val_concord']\n",
      "Best smoothed val_concord = 0.7534 at epoch 86\n",
      "\n",
      " epoch â”‚ raw val_concord â”‚ smoothed\n",
      "â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   3   â”‚      0.7462     â”‚  0.7459\n",
      "   4   â”‚      0.7455     â”‚  0.7461\n",
      "   5   â”‚      0.7444     â”‚  0.7453\n",
      "   6   â”‚      0.7426     â”‚  0.7442\n",
      "   7   â”‚      0.7472     â”‚  0.7447\n",
      "   8   â”‚      0.7483     â”‚  0.7460\n",
      "   9   â”‚      0.7450     â”‚  0.7468\n",
      "  10   â”‚      0.7437     â”‚  0.7457\n",
      "  11   â”‚      0.7452     â”‚  0.7447\n",
      "  12   â”‚      0.7473     â”‚  0.7454\n",
      "  13   â”‚      0.7471     â”‚  0.7465\n",
      "  14   â”‚      0.7481     â”‚  0.7475\n",
      "  15   â”‚      0.7483     â”‚  0.7479\n",
      "  16   â”‚      0.7480     â”‚  0.7482\n",
      "  17   â”‚      0.7475     â”‚  0.7480\n",
      "  18   â”‚      0.7493     â”‚  0.7483\n",
      "  19   â”‚      0.7484     â”‚  0.7484\n",
      "  20   â”‚      0.7499     â”‚  0.7492\n",
      "  21   â”‚      0.7484     â”‚  0.7489\n",
      "  22   â”‚      0.7487     â”‚  0.7490\n",
      "  23   â”‚      0.7473     â”‚  0.7481\n",
      "  24   â”‚      0.7507     â”‚  0.7489\n",
      "  25   â”‚      0.7500     â”‚  0.7493\n",
      "  26   â”‚      0.7489     â”‚  0.7499\n",
      "  27   â”‚      0.7498     â”‚  0.7496\n",
      "  28   â”‚      0.7518     â”‚  0.7502\n",
      "  29   â”‚      0.7529     â”‚  0.7515\n",
      "  30   â”‚      0.7502     â”‚  0.7516\n",
      "  31   â”‚      0.7490     â”‚  0.7507\n",
      "  32   â”‚      0.7522     â”‚  0.7505\n",
      "  33   â”‚      0.7508     â”‚  0.7506\n",
      "  34   â”‚      0.7525     â”‚  0.7518\n",
      "  35   â”‚      0.7513     â”‚  0.7515\n",
      "  36   â”‚      0.7508     â”‚  0.7515\n",
      "  37   â”‚      0.7512     â”‚  0.7511\n",
      "  38   â”‚      0.7521     â”‚  0.7514\n",
      "  39   â”‚      0.7518     â”‚  0.7517\n",
      "  40   â”‚      0.7527     â”‚  0.7522\n",
      "  41   â”‚      0.7524     â”‚  0.7523\n",
      "  42   â”‚      0.7525     â”‚  0.7525\n",
      "  43   â”‚      0.7527     â”‚  0.7525\n",
      "  44   â”‚      0.7530     â”‚  0.7527\n",
      "  45   â”‚      0.7530     â”‚  0.7529\n",
      "  46   â”‚      0.7529     â”‚  0.7530\n",
      "  47   â”‚      0.7533     â”‚  0.7531\n",
      "  48   â”‚      0.7530     â”‚  0.7531\n",
      "  49   â”‚      0.7531     â”‚  0.7531\n",
      "  50   â”‚      0.7526     â”‚  0.7529\n",
      "  51   â”‚      0.7531     â”‚  0.7529\n",
      "  52   â”‚      0.7533     â”‚  0.7530\n",
      "  53   â”‚      0.7529     â”‚  0.7531\n",
      "  54   â”‚      0.7531     â”‚  0.7531\n",
      "  55   â”‚      0.7534     â”‚  0.7531\n",
      "  56   â”‚      0.7532     â”‚  0.7532\n",
      "  57   â”‚      0.7528     â”‚  0.7531\n",
      "  58   â”‚      0.7530     â”‚  0.7530\n",
      "  59   â”‚      0.7535     â”‚  0.7531\n",
      "  60   â”‚      0.7530     â”‚  0.7532\n",
      "  61   â”‚      0.7531     â”‚  0.7532\n",
      "  62   â”‚      0.7534     â”‚  0.7532\n",
      "  63   â”‚      0.7533     â”‚  0.7533\n",
      "  64   â”‚      0.7531     â”‚  0.7532\n",
      "  65   â”‚      0.7535     â”‚  0.7533\n",
      "  66   â”‚      0.7529     â”‚  0.7532\n",
      "  67   â”‚      0.7533     â”‚  0.7532\n",
      "  68   â”‚      0.7530     â”‚  0.7531\n",
      "  69   â”‚      0.7534     â”‚  0.7532\n",
      "  70   â”‚      0.7533     â”‚  0.7532\n",
      "  71   â”‚      0.7534     â”‚  0.7533\n",
      "  72   â”‚      0.7528     â”‚  0.7532\n",
      "  73   â”‚      0.7530     â”‚  0.7531\n",
      "  74   â”‚      0.7531     â”‚  0.7530\n",
      "  75   â”‚      0.7533     â”‚  0.7532\n",
      "  76   â”‚      0.7534     â”‚  0.7533\n",
      "  77   â”‚      0.7531     â”‚  0.7533\n",
      "  78   â”‚      0.7528     â”‚  0.7531\n",
      "  79   â”‚      0.7534     â”‚  0.7531\n",
      "  80   â”‚      0.7533     â”‚  0.7532\n",
      "  81   â”‚      0.7530     â”‚  0.7533\n",
      "  82   â”‚      0.7531     â”‚  0.7531\n",
      "  83   â”‚      0.7526     â”‚  0.7529\n",
      "  84   â”‚      0.7532     â”‚  0.7530\n",
      "  85   â”‚      0.7536     â”‚  0.7531\n",
      "  86   â”‚      0.7534     â”‚  0.7534\n",
      "  87   â”‚      0.7531     â”‚  0.7534\n",
      "  88   â”‚      0.7526     â”‚  0.7530\n",
      "  89   â”‚      0.7531     â”‚  0.7529\n",
      "  90   â”‚      0.7530     â”‚  0.7529\n",
      "  91   â”‚      0.7534     â”‚  0.7532\n",
      "  92   â”‚      0.7533     â”‚  0.7532\n",
      "  93   â”‚      0.7529     â”‚  0.7532\n",
      "  94   â”‚      0.7532     â”‚  0.7531\n",
      "  95   â”‚      0.7531     â”‚  0.7531\n",
      "  96   â”‚      0.7530     â”‚  0.7531\n",
      "  97   â”‚      0.7530     â”‚  0.7530\n",
      "  98   â”‚      0.7530     â”‚  0.7530\n",
      "  99   â”‚      0.7527     â”‚  0.7529\n",
      "  100   â”‚      0.7531     â”‚  0.7529\n"
     ]
    }
   ],
   "source": [
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# 1) Path to your events file:\n",
    "events_path = os.path.join('/app', '.training_logs/' ,run_tag)\n",
    "event_files = glob.glob(os.path.join(events_path, \"events.out.tfevents.*\"))\n",
    "if not event_files:\n",
    "    raise FileNotFoundError(f\"No TensorBoard event files found in {events_path}\")\n",
    "event_file = sorted(event_files, key=os.path.getmtime)[-1]  # use the newest\n",
    "print(f\"Using event file: {event_file}\")\n",
    "\n",
    "# 2) Load all scalar data\n",
    "ea = EventAccumulator(event_file, size_guidance={\"scalars\": 0})\n",
    "ea.Reload()\n",
    "\n",
    "# 3) Check available scalar tags\n",
    "print(\"Available scalar tags:\", ea.Tags()[\"scalars\"])\n",
    "# => ['train_loss', 'train_concord', 'val_loss', 'val_concord']\n",
    "\n",
    "# 4) Extract (epoch, value) pairs for val_concord\n",
    "val_concord = [(e.step, e.value) for e in ea.Scalars(\"val_concord\")]\n",
    "\n",
    "# 5) Separate epochs and values\n",
    "epochs = [step for step, _ in val_concord]\n",
    "vals   = np.array([v for _, v in val_concord])\n",
    "\n",
    "# 6) Compute 3-epoch moving average\n",
    "window = 3\n",
    "# 'valid' mode produces len(vals) - window + 1 points\n",
    "smoothed = np.convolve(vals, np.ones(window)/window, mode=\"valid\")\n",
    "smoothed_epochs = epochs[window - 1 :]  # first smoothed point corresponds to epoch=window\n",
    "\n",
    "# 7) Find epoch with highest smoothed val_concord\n",
    "best_idx = np.argmax(smoothed)\n",
    "best_epoch = smoothed_epochs[best_idx]\n",
    "best_smoothed_concord = smoothed[best_idx]\n",
    "print(f\"Best smoothed val_concord = {best_smoothed_concord:.4f} at epoch {best_epoch}\")\n",
    "\n",
    "# 8) (Optional) print raw vs smoothed for inspection\n",
    "print(\"\\n epoch â”‚ raw val_concord â”‚ smoothed\")\n",
    "print(\"â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "for ep, raw, sm in zip(smoothed_epochs, vals[window - 1 :], smoothed):\n",
    "    print(f\"  {ep:>2d}   â”‚      {raw:.4f}     â”‚  {sm:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch65', 'epoch85', 'epoch91'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multisurv.best_model_weights.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch65': 0.7534815389438225,\n",
       " 'epoch85': 0.7535904615662542,\n",
       " 'epoch91': 0.7534363759052533}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multisurv.best_concord_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch100': 0.753064444999389}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multisurv.current_concord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model weights to file:\n",
      "    /mnt/data/multisurv_models/clinical_lr0.0015_epoch85_concord0.75.pth\n"
     ]
    }
   ],
   "source": [
    "multisurv.save_weights(saved_epoch='epoch85', prefix=run_tag, weight_dir=MODELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data modalities:\n",
      "   clinical\n",
      "\n",
      "Dataset sizes (# patients):\n",
      "   train: 8823\n",
      "   val: 1102\n",
      "   test: 1086\n",
      "\n",
      "Batch size: 128\n"
     ]
    }
   ],
   "source": [
    "dataloaders = utils.get_dataloaders(data_location=DATA,\n",
    "                                    labels_file='/app/data/labels.tsv',\n",
    "                                    modalities=data_modalities.value,\n",
    "                                    wsi_patch_size=299,\n",
    "                                    n_wsi_patches=5,\n",
    "#                                     exclude_patients=exclude_cancers,\n",
    "                                    return_patient_id=True,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collect patient predictions: 1102/1102\n",
      "\n",
      "C-index   0.76\n",
      "Ctd       0.76\n",
      "IBS       0.181\n",
      "INBLL     0.541\n"
     ]
    }
   ],
   "source": [
    "performance = utils.Evaluation(\n",
    "    model=multisurv, dataset=dataloaders['val'].dataset,\n",
    "    device=device)\n",
    "performance.compute_metrics()\n",
    "performance.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collect patient predictions: 1086/1086\n",
      "\n",
      "C-index   0.748\n",
      "Ctd       0.748\n",
      "IBS       0.184\n",
      "INBLL     0.542\n"
     ]
    }
   ],
   "source": [
    "performance = utils.Evaluation(\n",
    "    model=multisurv, dataset=dataloaders['test'].dataset,\n",
    "    device=device)\n",
    "performance.compute_metrics()\n",
    "performance.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watermark <a class='tocSkip'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch      1.4.0\n",
      "ipywidgets 7.5.1\n",
      "pandas     1.0.1\n",
      "\n",
      "CPython 3.6.7\n",
      "IPython 7.11.1\n",
      "\n",
      "last updated: Tue Jul 28 2020\n"
     ]
    }
   ],
   "source": [
    "%watermark --iversions\n",
    "%watermark -v\n",
    "print()\n",
    "%watermark -u -n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of the page](#Top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "197px",
    "width": "372px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "236px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
