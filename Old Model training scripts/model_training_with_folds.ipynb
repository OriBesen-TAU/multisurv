{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Top'></a>\n",
    "\n",
    "# Multisurv model training<a class='tocSkip'></a>\n",
    "\n",
    "Train MultiSurv models with different combinations of input data modalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /opt/conda/envs/multisurv/lib/python3.8/site-packages (2.17.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (1.62.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (3.6)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (1.24.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (25.0)\n",
      "Requirement already satisfied: protobuf in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (4.25.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (75.3.0)\n",
      "Requirement already satisfied: six>1.9 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (3.0.6)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard) (8.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.21.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> PyTorch detected CUDA <<<\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%load_ext watermark\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('>>> PyTorch detected CUDA <<<')\n",
    "\n",
    "# Make modules in \"src\" dir visible\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.append(os.path.join(os.getcwd(), 'src'))\n",
    "\n",
    "import utils\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#DataLoader\" data-toc-modified-id=\"DataLoader-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span><code>DataLoader</code></a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Different-intervals\" data-toc-modified-id=\"Different-intervals-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Different intervals</a></span><ul class=\"toc-item\"><li><span><a href=\"#Equidistant-times\" data-toc-modified-id=\"Equidistant-times-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Equidistant times</a></span></li><li><span><a href=\"#By-duration-quantiles\" data-toc-modified-id=\"By-duration-quantiles-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>By duration quantiles</a></span></li></ul></li><li><span><a href=\"#Pick-learning-rate\" data-toc-modified-id=\"Pick-learning-rate-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Pick learning rate</a></span></li><li><span><a href=\"#Fit\" data-toc-modified-id=\"Fit-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Fit</a></span><ul class=\"toc-item\"><li><span><a href=\"#Save-model-weights\" data-toc-modified-id=\"Save-model-weights-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Save model weights</a></span></li></ul></li><li><span><a href=\"#Check-validation-metrics\" data-toc-modified-id=\"Check-validation-metrics-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Check validation metrics</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ PyTorch is using: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "âœ… NVIDIA GPU detected - good for training!\n",
      "\n",
      "==================================================\n",
      "=== GPU DETECTION REPORT ===\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "PyTorch version: 2.4.0\n",
      "Number of CUDA devices: 1\n",
      "\n",
      "=== AVAILABLE GPUS ===\n",
      "GPU 0: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "  Memory: 8.0 GB\n",
      "  Compute Capability: 8.9\n",
      "  Multi Processors: 24\n",
      "\n",
      "=== CURRENT SELECTION ===\n",
      "Current CUDA device: 0\n",
      "Current GPU name: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "\n",
      "=== MEMORY USAGE ===\n",
      "GPU 0 (NVIDIA GeForce RTX 4060 Laptop GPU):\n",
      "  Allocated: 0.00 GB\n",
      "  Reserved: 0.00 GB\n",
      "  Total: 8.0 GB\n",
      "\n",
      "=== GPU FUNCTIONALITY TEST ===\n",
      "âœ… GPU computation successful\n",
      "Test tensor device: cuda:0\n",
      "Result tensor device: cuda:0\n",
      "\n",
      "=== NVIDIA SYSTEM INFO ===\n",
      "NVIDIA-SMI Output:\n",
      "Sat Jun 21 10:07:59 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 575.64.01              Driver Version: 576.80         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 ...    On  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   42C    P0             15W /   89W |     123MiB /   8188MiB |      3%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            1229      C   /python3.8                            N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n",
      "âœ… Using single GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "\n",
      "=== PYTORCH GPU VERIFICATION ===\n",
      "âœ… PyTorch using: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "âœ… Confirmed: Using NVIDIA GPU\n",
      "\n",
      "=== RECOMMENDATION ===\n",
      "âœ… Ready for GPU training with device: cuda:0\n",
      "Use: multisurv.device = cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import subprocess\n",
    "\n",
    "def check_gpu_setup():\n",
    "    \"\"\"Complete GPU detection and verification.\"\"\"\n",
    "    \n",
    "    print(\"=== GPU DETECTION REPORT ===\")\n",
    "    \n",
    "    # 1. Check CUDA availability\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    \n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"âŒ CUDA not available - will use CPU\")\n",
    "        return\n",
    "    \n",
    "    # 2. Check number of GPUs\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"Number of CUDA devices: {gpu_count}\")\n",
    "    \n",
    "    # 3. List all available GPUs\n",
    "    print(\"\\n=== AVAILABLE GPUS ===\")\n",
    "    for i in range(gpu_count):\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        print(f\"GPU {i}: {props.name}\")\n",
    "        print(f\"  Memory: {props.total_memory / 1024**3:.1f} GB\")\n",
    "        print(f\"  Compute Capability: {props.major}.{props.minor}\")\n",
    "        print(f\"  Multi Processors: {props.multi_processor_count}\")\n",
    "    \n",
    "    # 4. Check current device\n",
    "    current_device = torch.cuda.current_device()\n",
    "    current_name = torch.cuda.get_device_name(current_device)\n",
    "    print(f\"\\n=== CURRENT SELECTION ===\")\n",
    "    print(f\"Current CUDA device: {current_device}\")\n",
    "    print(f\"Current GPU name: {current_name}\")\n",
    "    \n",
    "    # 5. Memory usage\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"\\n=== MEMORY USAGE ===\")\n",
    "        for i in range(gpu_count):\n",
    "            allocated = torch.cuda.memory_allocated(i) / 1024**3\n",
    "            reserved = torch.cuda.memory_reserved(i) / 1024**3\n",
    "            total = torch.cuda.get_device_properties(i).total_memory / 1024**3\n",
    "            print(f\"GPU {i} ({torch.cuda.get_device_name(i)}):\")\n",
    "            print(f\"  Allocated: {allocated:.2f} GB\")\n",
    "            print(f\"  Reserved: {reserved:.2f} GB\")\n",
    "            print(f\"  Total: {total:.1f} GB\")\n",
    "    \n",
    "    # 6. Test tensor creation on GPU\n",
    "    print(f\"\\n=== GPU FUNCTIONALITY TEST ===\")\n",
    "    try:\n",
    "        # Create test tensor on GPU\n",
    "        test_tensor = torch.randn(1000, 1000).cuda()\n",
    "        result = torch.mm(test_tensor, test_tensor)\n",
    "        print(f\"âœ… GPU computation successful\")\n",
    "        print(f\"Test tensor device: {test_tensor.device}\")\n",
    "        print(f\"Result tensor device: {result.device}\")\n",
    "        \n",
    "        # Cleanup\n",
    "        del test_tensor, result\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ GPU computation failed: {e}\")\n",
    "\n",
    "def check_nvidia_system():\n",
    "    \"\"\"Check NVIDIA system information.\"\"\"\n",
    "    print(\"\\n=== NVIDIA SYSTEM INFO ===\")\n",
    "    \n",
    "    try:\n",
    "        # Run nvidia-smi command\n",
    "        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(\"NVIDIA-SMI Output:\")\n",
    "            print(result.stdout)\n",
    "        else:\n",
    "            print(\"âŒ nvidia-smi command failed\")\n",
    "            print(result.stderr)\n",
    "    except FileNotFoundError:\n",
    "        print(\"âŒ nvidia-smi not found - NVIDIA drivers may not be installed\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error running nvidia-smi: {e}\")\n",
    "\n",
    "def set_gpu_preference():\n",
    "    \"\"\"Set GPU preference if multiple GPUs available.\"\"\"\n",
    "    \n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"No CUDA GPUs available\")\n",
    "        return None\n",
    "    \n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    \n",
    "    if gpu_count == 1:\n",
    "        device = torch.device('cuda:0')\n",
    "        print(f\"âœ… Using single GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        return device\n",
    "    \n",
    "    print(f\"\\n=== MULTIPLE GPUS DETECTED ({gpu_count}) ===\")\n",
    "    \n",
    "    # Show GPU options\n",
    "    for i in range(gpu_count):\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        print(f\"GPU {i}: {props.name} ({props.total_memory / 1024**3:.1f} GB)\")\n",
    "    \n",
    "    # Find the most powerful GPU (by memory)\n",
    "    best_gpu = 0\n",
    "    best_memory = 0\n",
    "    \n",
    "    for i in range(gpu_count):\n",
    "        memory = torch.cuda.get_device_properties(i).total_memory\n",
    "        if memory > best_memory:\n",
    "            best_memory = memory\n",
    "            best_gpu = i\n",
    "    \n",
    "    device = torch.device(f'cuda:{best_gpu}')\n",
    "    print(f\"âœ… Auto-selected most powerful GPU: {torch.cuda.get_device_name(best_gpu)}\")\n",
    "    \n",
    "    # Set as current device\n",
    "    torch.cuda.set_device(best_gpu)\n",
    "    \n",
    "    return device\n",
    "\n",
    "def verify_pytorch_gpu_usage():\n",
    "    \"\"\"Verify PyTorch is actually using the NVIDIA GPU (not Intel).\"\"\"\n",
    "    \n",
    "    print(\"\\n=== PYTORCH GPU VERIFICATION ===\")\n",
    "    \n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"âŒ PyTorch not using GPU - will use CPU\")\n",
    "        return False\n",
    "    \n",
    "    # Create tensor and check device\n",
    "    x = torch.randn(100, 100).cuda()\n",
    "    gpu_name = torch.cuda.get_device_name(x.device)\n",
    "    \n",
    "    print(f\"âœ… PyTorch using: {gpu_name}\")\n",
    "    \n",
    "    # Check if it's NVIDIA (not Intel)\n",
    "    if 'nvidia' in gpu_name.lower() or 'geforce' in gpu_name.lower() or 'rtx' in gpu_name.lower() or 'gtx' in gpu_name.lower():\n",
    "        print(f\"âœ… Confirmed: Using NVIDIA GPU\")\n",
    "        return True\n",
    "    elif 'intel' in gpu_name.lower():\n",
    "        print(f\"âš ï¸  Warning: Using Intel GPU - this may be slow for deep learning\")\n",
    "        return False\n",
    "    else:\n",
    "        print(f\"â“ Unknown GPU type: {gpu_name}\")\n",
    "        return True\n",
    "\n",
    "# Run all checks\n",
    "def complete_gpu_check():\n",
    "    \"\"\"Run complete GPU diagnostic.\"\"\"\n",
    "    check_gpu_setup()\n",
    "    check_nvidia_system()\n",
    "    device = set_gpu_preference()\n",
    "    is_nvidia = verify_pytorch_gpu_usage()\n",
    "    \n",
    "    print(f\"\\n=== RECOMMENDATION ===\")\n",
    "    if is_nvidia and device:\n",
    "        print(f\"âœ… Ready for GPU training with device: {device}\")\n",
    "        print(f\"Use: multisurv.device = {device}\")\n",
    "    else:\n",
    "        print(\"âš ï¸  Consider using CPU training: multisurv.device = torch.device('cpu')\")\n",
    "    \n",
    "    return device\n",
    "\n",
    "# Quick check function\n",
    "def quick_gpu_check():\n",
    "    \"\"\"Quick GPU check for immediate feedback.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        print(f\"ðŸŽ¯ PyTorch is using: {gpu_name}\")\n",
    "        \n",
    "        if any(keyword in gpu_name.lower() for keyword in ['nvidia', 'geforce', 'rtx', 'gtx']):\n",
    "            print(\"âœ… NVIDIA GPU detected - good for training!\")\n",
    "        else:\n",
    "            print(\"âš ï¸  Non-NVIDIA GPU detected\")\n",
    "    else:\n",
    "        print(\"âŒ No GPU available - will use CPU\")\n",
    "\n",
    "# Run the checks\n",
    "quick_gpu_check()\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "complete_gpu_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = utils.INPUT_DATA_DIR\n",
    "MODELS = utils.TRAINED_MODEL_DIR\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3316f8248284780902e745afdaa3072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Input data', index=(0, 1), options=('clinical', 'mRNA', 'DNAm', 'miRNA', 'CNV', 'wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_modalities = widgets.SelectMultiple(\n",
    "    options=['clinical', 'mRNA', 'DNAm', 'miRNA', 'CNV', 'wsi'],\n",
    "    index=[0, 1],\n",
    "    rows=6,\n",
    "    description='Input data',\n",
    "    disabled=False\n",
    ")\n",
    "display(data_modalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   submitter_id      time  event  group\n",
      "0  TCGA-Z7-A8R6  8.920548      0  train\n",
      "1  TCGA-C8-A1HE  1.027397      0    val\n",
      "2  TCGA-A8-A07B  3.583562      0  train\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------------------------------#\n",
    "#                             20-CANCER SUBSET                                #\n",
    "#                 (to compare to Cheerla and Gevaert 2019)                    #\n",
    "#-----------------------------------------------------------------------------#\n",
    "\n",
    "cancers = ['BRCA']\n",
    "\n",
    "labels = pd.read_csv('/app/data/labels_fold4.tsv', sep='\\t')\n",
    "print(labels.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data modalities:\n",
      "   clinical\n",
      "\n",
      "Dataset sizes (# patients):\n",
      "   train: 711\n",
      "   val: 165\n",
      "   test: 218\n",
      "\n",
      "Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "dataloaders = utils.get_dataloaders(data_location=DATA,\n",
    "                                    labels_file='/app/data/labels_fold4.tsv',\n",
    "                                    modalities=data_modalities.value,\n",
    "                                    wsi_patch_size=299,\n",
    "                                    n_wsi_patches=5,\n",
    "#                                     batch_size=20,\n",
    "#                                    batch_size=64,\n",
    "                                     batch_size=32,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train event rate: 13.78%\n",
      "Val event rate: 13.94%\n",
      "Test event rate: 13.76%\n"
     ]
    }
   ],
   "source": [
    "# Compare event rates across splits\n",
    "def get_event_rate(dataset):\n",
    "    events = [e for _, e in dataset.label_map.values()]\n",
    "    return sum(events) / len(events)\n",
    "\n",
    "print(f\"Train event rate: {get_event_rate(dataloaders['train'].dataset):.2%}\")\n",
    "print(f\"Val event rate: {get_event_rate(dataloaders['val'].dataset):.2%}\")\n",
    "print(f\"Test event rate: {get_event_rate(dataloaders['test'].dataset):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN set (n=711):\n",
      "Clinical features shape: ({'clinical': (tensor([0., 4., 0., 0., 0., 2., 0.]), tensor([0.3597]))}, 23.44109589041096, 0)\n",
      "\n",
      "VAL set (n=165):\n",
      "Clinical features shape: ({'clinical': (tensor([0., 0., 0., 0., 0., 0., 2.]), tensor([0.3913]))}, 8.301369863013699, 0)\n",
      "\n",
      "TEST set (n=218):\n",
      "Clinical features shape: ({'clinical': (tensor([0., 4., 0., 0., 0., 2., 0.]), tensor([0.7440]))}, 8.564383561643835, 1)\n"
     ]
    }
   ],
   "source": [
    "# Check if clinical features are similar across splits\n",
    "# Look for any systematic differences\n",
    "for split in ['train', 'val', 'test']:\n",
    "    data = dataloaders[split].dataset\n",
    "    print(f\"\\n{split.upper()} set (n={len(data)}):\")\n",
    "    # Get first patient's clinical data to see structure\n",
    "    if len(data) > 0:\n",
    "        clinical = data[0]\n",
    "        print(f\"Clinical features shape: {clinical}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train range: [0.000, 1.000]\n",
      "Val range: [0.037, 1.000]\n",
      "Test range: [0.051, 1.000]\n"
     ]
    }
   ],
   "source": [
    "# 1. First, check the continuous feature distribution\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract continuous feature values for all patients\n",
    "def get_continuous_feature(dataset):\n",
    "    values = []\n",
    "    for i in range(len(dataset)):\n",
    "        clinical_data = dataset[i][0]  # Get the data part\n",
    "        continuous_val = clinical_data['clinical'][1].item()  # The continuous feature\n",
    "        values.append(continuous_val)\n",
    "    return np.array(values)\n",
    "\n",
    "train_cont = get_continuous_feature(dataloaders['train'].dataset)\n",
    "val_cont = get_continuous_feature(dataloaders['val'].dataset)\n",
    "test_cont = get_continuous_feature(dataloaders['test'].dataset)\n",
    "\n",
    "# Plot distributions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(train_cont, alpha=0.5, label=f'Train (mean={train_cont.mean():.3f})', bins=30)\n",
    "plt.hist(val_cont, alpha=0.5, label=f'Val (mean={val_cont.mean():.3f})', bins=30)\n",
    "plt.hist(test_cont, alpha=0.5, label=f'Test (mean={test_cont.mean():.3f})', bins=30)\n",
    "plt.legend()\n",
    "plt.title('Distribution of Continuous Clinical Feature')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Train range: [{train_cont.min():.3f}, {train_cont.max():.3f}]\")\n",
    "print(f\"Val range: [{val_cont.min():.3f}, {val_cont.max():.3f}]\")\n",
    "print(f\"Test range: [{test_cont.min():.3f}, {test_cont.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different intervals\n",
    "\n",
    "If trying out different time interval outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equidistant times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_cuts = torch.arange(0., 365 * 5.1, 365 / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By duration quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [(t, e) for t, e in dataloaders['train'].dataset.label_map.values()]\n",
    "durations = [t for t, _ in labels]\n",
    "events = [e for _, e in labels]\n",
    "\n",
    "interval_cuts = utils.discretize_time_by_duration_quantiles(durations, events, 20)\n",
    "interval_cuts = torch.from_numpy(interval_cuts)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#-----------------------------------------------------------------------------#\n",
    "#                       PRE-TRAINED UNIMODAL MODELS                           #\n",
    "#-----------------------------------------------------------------------------#\n",
    "\n",
    "unimodal_weigths = {'clinical': 'clinical_lr0.005_epoch49_acc0.78.pth',\n",
    "                    'mRNA': 'mRNA_lr0.005_epoch54_acc0.76.pth',\n",
    "                    'DNAm': 'DNAm_lr0.005_epoch57_acc0.77.pth',\n",
    "                    'miRNA': None,\n",
    "                    'CNV': None,\n",
    "                    'wsi': None,}\n",
    "\n",
    "unimodal_weigths = {k: os.path.join(MODELS, v) if v is not None else None\n",
    "                    for k, v in unimodal_weigths.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiating MultiSurv model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/src/multisurv.py:84: UserWarning: Input data is unimodal: no fusion procedure.\n",
      "  warnings.warn('Input data is unimodal: no fusion procedure.')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "multisurv = Model(\n",
    "    dataloaders=dataloaders,\n",
    "    auxiliary_criterion=None,  # No auxiliary loss needed\n",
    "    output_intervals=interval_cuts,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gpu_enabled_multisurv():\n",
    "    \"\"\"Create a fresh MultiSurv instance with proper GPU setup.\"\"\"\n",
    "    \n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Creating MultiSurv with device: {device}\")\n",
    "    \n",
    "    \n",
    "    # Create new model with GPU device\n",
    "    gpu_multisurv = Model(\n",
    "        dataloaders=multisurv.dataloaders,  # Reuse existing dataloaders\n",
    "        fusion_method=multisurv.fusion_method,\n",
    "        output_intervals=multisurv.output_intervals.to(device),  # Move to GPU\n",
    "        device=device  # Set device properly\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… GPU-enabled MultiSurv created!\")\n",
    "    return gpu_multisurv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MultiSurv with device: cuda:0\n",
      "Instantiating MultiSurv model...\n",
      "âœ… GPU-enabled MultiSurv created!\n"
     ]
    }
   ],
   "source": [
    "gpu_multisurv = create_gpu_enabled_multisurv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output intervals (in years):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  1.5671,  2.4630,  3.4849,  4.6192,  5.2438,  6.4959,  7.0082,\n",
       "         7.8575,  8.3151,  9.4685, 10.6110, 10.7973, 11.3945, 11.9288, 17.2384,\n",
       "        17.6877, 18.0630, 23.5753], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Output intervals (in years):')\n",
    "gpu_multisurv.output_intervals / 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clinical_submodel', 'fc_block', 'risk_layer']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_multisurv.model_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable blocks:\n",
      "   clinical_submodel: True\n",
      "   fc_block: True\n",
      "   risk_layer: True\n"
     ]
    }
   ],
   "source": [
    "print('Trainable blocks:')\n",
    "layer = None\n",
    "\n",
    "for name, child in gpu_multisurv.model.named_children():\n",
    "    for name_2, params in child.named_parameters():\n",
    "        if name is not layer:\n",
    "            print(f'   {name}: {params.requires_grad}')\n",
    "        layer = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiSurv(\n",
       "  (clinical_submodel): ClinicalNet(\n",
       "    (embedding_layers): ModuleList(\n",
       "      (0): Embedding(2, 1)\n",
       "      (1): Embedding(7, 4)\n",
       "      (2-4): 3 x Embedding(3, 2)\n",
       "      (5-6): 2 x Embedding(4, 2)\n",
       "    )\n",
       "    (embedding_dropout): Dropout(p=0.5, inplace=False)\n",
       "    (bn_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear): Linear(in_features=16, out_features=256, bias=True)\n",
       "    (output_layer): FC(\n",
       "      (fc): Sequential(\n",
       "        (0): Dropout(p=0.5, inplace=False)\n",
       "        (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_block): FC(\n",
       "    (fc): Sequential(\n",
       "      (0): Dropout(p=0.5, inplace=False)\n",
       "      (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): Dropout(p=0.5, inplace=False)\n",
       "      (5): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (6): ReLU()\n",
       "      (7): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (12): Dropout(p=0.5, inplace=False)\n",
       "      (13): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (14): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (risk_layer): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=18, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_multisurv.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ GPU Memory: 1.52 GB allocated, 1.63 GB reserved\n",
      "ðŸ” GPU cache size: 1.63 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1229/1937229576.py:9: FutureWarning: `torch.cuda.memory_cached` has been renamed to `torch.cuda.memory_reserved`\n",
      "  print(f\"ðŸ” GPU cache size: {torch.cuda.memory_cached(0) / 1024**3:.2f} GB\")\n"
     ]
    }
   ],
   "source": [
    "# Check GPU usage after LR test\n",
    "def monitor_gpu_real_time():\n",
    "    import torch\n",
    "    allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "    reserved = torch.cuda.memory_reserved(0) / 1024**3\n",
    "    print(f\"ðŸŽ¯ GPU Memory: {allocated:.2f} GB allocated, {reserved:.2f} GB reserved\")\n",
    "    \n",
    "    # Check if there are any tensors on GPU\n",
    "    print(f\"ðŸ” GPU cache size: {torch.cuda.memory_cached(0) / 1024**3:.2f} GB\")\n",
    "monitor_gpu_real_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features:\n",
      " tensor([0., 4., 0., 0., 0., 2., 0.])\n",
      "Continuous features:\n",
      " tensor([0.3597])\n"
     ]
    }
   ],
   "source": [
    "data_example, _, _ = dataloaders['train'].dataset[0]\n",
    "print(\"Categorical features:\\n\", data_example['clinical'][0])\n",
    "print(\"Continuous features:\\n\", data_example['clinical'][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied GPU-compatible fix to LRRangeTest.run\n"
     ]
    }
   ],
   "source": [
    "# GPU-compatible version of the completely fixed LR test\n",
    "\n",
    "def gpu_fixed_lr_test_run(self, init_value=1e-8, final_value=10., beta=0.98):\n",
    "    \"\"\"GPU-compatible LR test that ensures all tensors are on the same device.\"\"\"\n",
    "    print(\">>> Using GPU-COMPATIBLE FIXED lr_test.run method\")\n",
    "    \n",
    "    power = (1 / (len(self.dataloader) - 1))\n",
    "    mult = (final_value / init_value) ** power\n",
    "    lr = init_value\n",
    "    self.optimizer.param_groups[0]['lr'] = lr\n",
    "    avg_loss = 0.\n",
    "    best_loss = 0.\n",
    "    batch_num = 0\n",
    "\n",
    "    print('>>> Compute loss at increasing LR values')\n",
    "    \n",
    "    # Clear losses and lrs lists\n",
    "    self.losses = []\n",
    "    self.lrs = []\n",
    "\n",
    "    for data in self.dataloader:\n",
    "        batch_num += 1\n",
    "        print('\\r' + f'    Iterate over mini-batches: {str(batch_num)}', end='')\n",
    "\n",
    "        try:\n",
    "            # Unpack data\n",
    "            if len(data) == 3:\n",
    "                modality_data, time, event = data\n",
    "            elif len(data) == 4:\n",
    "                modality_data, time, event, pid = data\n",
    "            \n",
    "            # CRITICAL: Move ALL data to the same device as the model\n",
    "            target_device = next(self.model.parameters()).device\n",
    "            \n",
    "            # Move modality data to device\n",
    "            for key, value in modality_data.items():\n",
    "                if isinstance(value, torch.Tensor):\n",
    "                    modality_data[key] = value.to(target_device)\n",
    "                elif isinstance(value, (list, tuple)):\n",
    "                    modality_data[key] = tuple(v.to(target_device) if isinstance(v, torch.Tensor) else v for v in value)\n",
    "            \n",
    "            # Move time and event to device\n",
    "            time = time.to(target_device)\n",
    "            event = event.to(target_device)\n",
    "            \n",
    "            # Set model to train mode\n",
    "            self.model.train()\n",
    "            \n",
    "            # Clear gradients\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            with torch.set_grad_enabled(True):\n",
    "                feature_representations, risk = self.model(modality_data)\n",
    "                modality_features = feature_representations['modalities']\n",
    "                \n",
    "                # Compute loss with proper device handling\n",
    "                try:\n",
    "                    # Ensure output_intervals are on the same device\n",
    "                    if hasattr(self, 'output_intervals'):\n",
    "                        breaks = self.output_intervals.to(target_device)\n",
    "                    else:\n",
    "                        breaks = torch.linspace(0, 10, 19, device=target_device)  # Fallback\n",
    "                    \n",
    "                    loss = self.criterion(risk, times=time, events=event, breaks=breaks, device=target_device)\n",
    "                    \n",
    "                except Exception as loss_error:\n",
    "                    print(f\"\\nPrimary criterion failed: {loss_error}\")\n",
    "                    # Fallback to simple MSE loss on the same device\n",
    "                    dummy_target = torch.ones_like(risk)  # This will be on the same device as risk\n",
    "                    loss = torch.nn.functional.mse_loss(risk, dummy_target)\n",
    "                    print(\"Using fallback MSE loss\")\n",
    "                \n",
    "                # Add auxiliary loss if needed\n",
    "                if self.aux_criterion is not None:\n",
    "                    try:\n",
    "                        if len(modality_features) >= 2:\n",
    "                            target = torch.ones(modality_features[0].shape[0], device=target_device)\n",
    "                            aux_loss = self.aux_criterion(modality_features[0], modality_features[1], target)\n",
    "                            loss = loss + 0.1 * aux_loss\n",
    "                    except Exception as aux_error:\n",
    "                        print(f\"\\nAuxiliary criterion failed: {aux_error}\")\n",
    "            \n",
    "            # Store the loss value\n",
    "            loss_value = loss.item()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError at batch {batch_num}: {e}\")\n",
    "            break\n",
    "\n",
    "        # Compute the smoothed loss\n",
    "        avg_loss = (beta * avg_loss + (1 - beta) * loss_value)\n",
    "        smoothed_loss = avg_loss / (1 - beta ** batch_num)\n",
    "\n",
    "        # Stop if the loss is exploding\n",
    "        if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
    "            print()\n",
    "            print('    Exploding loss; finish test.')\n",
    "            break\n",
    "\n",
    "        # Record the best loss\n",
    "        if smoothed_loss < best_loss or batch_num == 1:\n",
    "            best_loss = smoothed_loss\n",
    "            \n",
    "        # Store the values\n",
    "        self.losses.append(smoothed_loss)\n",
    "        self.lrs.append(lr)\n",
    "\n",
    "        # Do the backward pass and optimizer step\n",
    "        try:\n",
    "            loss.backward(retain_graph=False)\n",
    "            self.optimizer.step()\n",
    "        except Exception as e:\n",
    "            print(f\"\\nBackward pass failed at batch {batch_num}: {e}\")\n",
    "            break\n",
    "\n",
    "        # Update the lr for the next step\n",
    "        lr *= mult\n",
    "        self.optimizer.param_groups[0]['lr'] = lr\n",
    "        \n",
    "        # Stop after reasonable number of batches\n",
    "        if batch_num >= 100:\n",
    "            print(\"\\nStopping after 100 batches\")\n",
    "            break\n",
    "\n",
    "    print()\n",
    "    print('    Completed test.')\n",
    "    return self\n",
    "\n",
    "# Apply the GPU-compatible fix\n",
    "import lr_range_test\n",
    "lr_range_test.LRRangeTest.run = gpu_fixed_lr_test_run\n",
    "print(\"Applied GPU-compatible fix to LRRangeTest.run\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Ultimate fix: Replace the entire lr_range_test.py run method\n",
    "\n",
    "def completely_fixed_lr_test_run(self, init_value=1e-8, final_value=10., beta=0.98):\n",
    "    \"\"\"Completely rewritten LR test that avoids the inplace operation issue.\"\"\"\n",
    "    print(\">>> Using COMPLETELY FIXED lr_test.run method\")\n",
    "    \n",
    "    power = (1 / (len(self.dataloader) - 1))\n",
    "    mult = (final_value / init_value) ** power\n",
    "    lr = init_value\n",
    "    self.optimizer.param_groups[0]['lr'] = lr\n",
    "    avg_loss = 0.\n",
    "    best_loss = 0.\n",
    "    batch_num = 0\n",
    "\n",
    "    print('>>> Compute loss at increasing LR values')\n",
    "    \n",
    "    # Clear losses and lrs lists\n",
    "    self.losses = []\n",
    "    self.lrs = []\n",
    "\n",
    "    for data in self.dataloader:\n",
    "        batch_num += 1\n",
    "        print('\\r' + f'    Iterate over mini-batches: {str(batch_num)}', end='')\n",
    "\n",
    "        try:\n",
    "            # COMPLETELY MANUAL APPROACH - avoid ModelCoach entirely\n",
    "            \n",
    "            # Unpack data\n",
    "            if len(data) == 3:\n",
    "                modality_data, time, event = data\n",
    "            elif len(data) == 4:\n",
    "                modality_data, time, event, pid = data\n",
    "            \n",
    "            # Move to device manually\n",
    "            for key, value in modality_data.items():\n",
    "                if isinstance(value, torch.Tensor):\n",
    "                    modality_data[key] = value.to(self.device)\n",
    "                elif isinstance(value, (list, tuple)):\n",
    "                    modality_data[key] = tuple(v.to(self.device) if isinstance(v, torch.Tensor) else v for v in value)\n",
    "            \n",
    "            time = time.to(self.device)\n",
    "            event = event.to(self.device)\n",
    "            \n",
    "            # Set model to train mode\n",
    "            self.model.train()\n",
    "            \n",
    "            # Clear gradients\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            with torch.set_grad_enabled(True):\n",
    "                feature_representations, risk = self.model(modality_data)\n",
    "                modality_features = feature_representations['modalities']\n",
    "                \n",
    "                # Compute loss manually (fix the arguments)\n",
    "                try:\n",
    "                    # The loss function signature is: forward(risk, times, events, breaks, device)\n",
    "                    # NOT forward(risk, times, events, modality_features, breaks)\n",
    "                    breaks = self.output_intervals\n",
    "                    if isinstance(breaks, (list, tuple)):\n",
    "                        breaks = torch.tensor(breaks, dtype=torch.float32, device=self.device)\n",
    "                    \n",
    "                    loss = self.criterion(risk, times=time, events=event, breaks=breaks, device=self.device)\n",
    "                        \n",
    "                except Exception as loss_error:\n",
    "                    print(f\"\\nPrimary criterion failed: {loss_error}\")\n",
    "                    # Fallback to simple MSE loss for LR range test\n",
    "                    dummy_target = torch.ones_like(risk)\n",
    "                    loss = torch.nn.functional.mse_loss(risk, dummy_target)\n",
    "                    print(\"Using fallback MSE loss\")\n",
    "                \n",
    "                # Add auxiliary loss if needed (fix the argument mismatch)\n",
    "                if self.aux_criterion is not None:\n",
    "                    try:\n",
    "                        # CosineEmbeddingLoss expects (input1, input2, target)\n",
    "                        # Let's use the two modality features\n",
    "                        if len(modality_features) >= 2:\n",
    "                            # Create a dummy target (1 for similar, -1 for dissimilar)\n",
    "                            target = torch.ones(modality_features[0].shape[0], device=self.device)\n",
    "                            aux_loss = self.aux_criterion(modality_features[0], modality_features[1], target)\n",
    "                            loss = loss + 0.1 * aux_loss  # Scale down aux loss\n",
    "                        else:\n",
    "                            print(\"Skipping aux loss - insufficient modality features\")\n",
    "                    except Exception as aux_error:\n",
    "                        print(f\"\\nAuxiliary criterion failed: {aux_error}\")\n",
    "                        print(\"Skipping auxiliary loss\")\n",
    "            \n",
    "            # Store the loss value\n",
    "            loss_value = loss.item()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError at batch {batch_num}: {e}\")\n",
    "            break\n",
    "\n",
    "        # Compute the smoothed loss\n",
    "        avg_loss = (beta * avg_loss + (1 - beta) * loss_value)\n",
    "        smoothed_loss = avg_loss / (1 - beta ** batch_num)\n",
    "\n",
    "        # Stop if the loss is exploding\n",
    "        if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
    "            print()\n",
    "            print('    Exploding loss; finish test.')\n",
    "            break\n",
    "\n",
    "        # Record the best loss\n",
    "        if smoothed_loss < best_loss or batch_num == 1:\n",
    "            best_loss = smoothed_loss\n",
    "            \n",
    "        # Store the values\n",
    "        self.losses.append(smoothed_loss)\n",
    "        self.lrs.append(lr)\n",
    "\n",
    "        # Do the backward pass and optimizer step\n",
    "        try:\n",
    "            # CRITICAL: Use retain_graph=False and no double backward pass\n",
    "            loss.backward(retain_graph=False)\n",
    "            self.optimizer.step()\n",
    "        except Exception as e:\n",
    "            print(f\"\\nBackward pass failed at batch {batch_num}: {e}\")\n",
    "            break\n",
    "\n",
    "        # Update the lr for the next step\n",
    "        lr *= mult\n",
    "        self.optimizer.param_groups[0]['lr'] = lr\n",
    "        \n",
    "        # Stop after reasonable number of batches to avoid infinite loops\n",
    "        if batch_num >= 100:\n",
    "            print(\"\\nStopping after 100 batches\")\n",
    "            break\n",
    "\n",
    "    print()\n",
    "    print('    Completed test.')\n",
    "    return self\n",
    "\n",
    "# Apply the complete fix\n",
    "import lr_range_test\n",
    "lr_range_test.LRRangeTest.run = completely_fixed_lr_test_run\n",
    "print(\"Applied COMPLETE fix to LRRangeTest.run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Using GPU-COMPATIBLE FIXED lr_test.run method\n",
      ">>> Compute loss at increasing LR values\n",
      "    Iterate over mini-batches: 22\n",
      "    Completed test.\n",
      "CPU times: user 1.19 s, sys: 124 ms, total: 1.31 s\n",
      "Wall time: 2.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)  # Disable anomaly detection too\n",
    "gpu_multisurv.test_lr_range()  # Use the new GPU instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loss values collected: 22\n",
      "Number of learning rates tested: 22\n",
      "LR range: 1.00e-06 to 1.00e+01\n",
      "Loss range: 0.051364 to 0.068512\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the results\n",
    "print(f\"Number of loss values collected: {len(gpu_multisurv.lr_test.losses)}\")\n",
    "print(f\"Number of learning rates tested: {len(gpu_multisurv.lr_test.lrs)}\")\n",
    "print(f\"LR range: {min(gpu_multisurv.lr_test.lrs):.2e} to {max(gpu_multisurv.lr_test.lrs):.2e}\")\n",
    "print(f\"Loss range: {min(gpu_multisurv.lr_test.losses):.6f} to {max(gpu_multisurv.lr_test.losses):.6f}\")\n",
    "\n",
    "# Plot the results to find optimal learning rate\n",
    "gpu_multisurv.plot_lr_range(trim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Fix for the _predictions_to_pycox method in coach.py\n",
    "\n",
    "def fixed_predictions_to_pycox(self, preds, time_points=None):\n",
    "    \"\"\"Fixed version that properly handles the DataFrame structure.\"\"\"\n",
    "    import pandas as pd\n",
    "    import torch\n",
    "    \n",
    "    # preds shape is [num_patients, num_intervals] e.g., [864, 18]\n",
    "    # Convert predictions to DataFrame\n",
    "    df = pd.DataFrame(preds.cpu().numpy())\n",
    "    \n",
    "    if time_points is None:\n",
    "        # Get the number of intervals from the model output\n",
    "        n_intervals = preds.shape[1]  # Should be 18 for your model\n",
    "        \n",
    "        # Use the model's actual output intervals\n",
    "        if hasattr(self, 'output_intervals') and self.output_intervals is not None:\n",
    "            # Use the midpoints of the output intervals\n",
    "            intervals = self.output_intervals\n",
    "            if len(intervals) > n_intervals:\n",
    "                # Take the first n_intervals midpoints\n",
    "                midpoints = (intervals[:-1] + intervals[1:]) / 2\n",
    "                time_points = midpoints[:n_intervals]\n",
    "            else:\n",
    "                # Fallback to evenly spaced points\n",
    "                time_points = torch.linspace(0.5, intervals[-1].item() / 365, n_intervals)\n",
    "        else:\n",
    "            # Fallback: create time points that match the output size\n",
    "            time_points = torch.arange(0.5, 0.5 + n_intervals, 1.0)\n",
    "    \n",
    "    # Ensure time_points matches the prediction dimensions\n",
    "    if len(time_points) != preds.shape[1]:\n",
    "        print(f\"Warning: Adjusting time_points from {len(time_points)} to {preds.shape[1]}\")\n",
    "        time_points = torch.linspace(time_points[0], time_points[-1], preds.shape[1])\n",
    "    \n",
    "    # FIXED: The DataFrame structure should be transposed\n",
    "    # We want columns to be time points, rows to be patients\n",
    "    df = df.T  # Transpose so shape becomes [num_intervals, num_patients]\n",
    "    \n",
    "    # Convert time_points to numpy if it's a tensor\n",
    "    if torch.is_tensor(time_points):\n",
    "        time_points = time_points.cpu().numpy()\n",
    "    \n",
    "    # Set the index to time points\n",
    "    df.index = time_points\n",
    "    df.index.name = 'time'\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the fix to ModelCoach\n",
    "from coach import ModelCoach\n",
    "ModelCoach._predictions_to_pycox = fixed_predictions_to_pycox\n",
    "print(\"Applied corrected fix to ModelCoach._predictions_to_pycox method\")\n",
    "\n",
    "# Debug info\n",
    "print(f\"Model output intervals shape: {len(gpu_multisurv.output_intervals)}\")\n",
    "print(f\"Model risk layer output: {gpu_multisurv.model.risk_layer[0].out_features}\")\n",
    "print(f\"Expected: {len(gpu_multisurv.output_intervals) - 1} intervals for {len(gpu_multisurv.output_intervals)} breakpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Applied GPU-compatible fix to ModelCoach._predictions_to_pycox method\n",
      "Model output intervals shape: 19\n",
      "Model output intervals device: cuda:0\n",
      "Model risk layer output: 18\n",
      "Expected: 18 intervals for 19 breakpoints\n"
     ]
    }
   ],
   "source": [
    "# GPU-compatible fix for _predictions_to_pycox method\n",
    "def gpu_fixed_predictions_to_pycox(self, preds, time_points=None):\n",
    "    \"\"\"GPU-compatible version that properly handles device transfers.\"\"\"\n",
    "    import pandas as pd\n",
    "    import torch\n",
    "    \n",
    "    # preds shape is [num_patients, num_intervals] e.g., [864, 18]\n",
    "    # Convert predictions to DataFrame (move to CPU first)\n",
    "    df = pd.DataFrame(preds.detach().cpu().numpy())  # Added .detach() for GPU tensors\n",
    "    \n",
    "    if time_points is None:\n",
    "        # Get the number of intervals from the model output\n",
    "        n_intervals = preds.shape[1]  # Should be 18 for your model\n",
    "        \n",
    "        # Use the model's actual output intervals\n",
    "        if hasattr(self, 'output_intervals') and self.output_intervals is not None:\n",
    "            # Handle GPU tensors properly\n",
    "            intervals = self.output_intervals\n",
    "            if torch.is_tensor(intervals):\n",
    "                intervals = intervals.detach().cpu()  # Move to CPU for calculations\n",
    "            \n",
    "            if len(intervals) > n_intervals:\n",
    "                # Take the first n_intervals midpoints\n",
    "                midpoints = (intervals[:-1] + intervals[1:]) / 2\n",
    "                time_points = midpoints[:n_intervals]\n",
    "            else:\n",
    "                # Fallback to evenly spaced points\n",
    "                last_interval = intervals[-1].item() if torch.is_tensor(intervals) else intervals[-1]\n",
    "                time_points = torch.linspace(0.5, last_interval / 365, n_intervals)\n",
    "        else:\n",
    "            # Fallback: create time points that match the output size\n",
    "            time_points = torch.arange(0.5, 0.5 + n_intervals, 1.0)\n",
    "    \n",
    "    # Ensure time_points matches the prediction dimensions\n",
    "    if len(time_points) != preds.shape[1]:\n",
    "        print(f\"Warning: Adjusting time_points from {len(time_points)} to {preds.shape[1]}\")\n",
    "        first_point = time_points[0].item() if torch.is_tensor(time_points) else time_points[0]\n",
    "        last_point = time_points[-1].item() if torch.is_tensor(time_points) else time_points[-1]\n",
    "        time_points = torch.linspace(first_point, last_point, preds.shape[1])\n",
    "    \n",
    "    # FIXED: The DataFrame structure should be transposed\n",
    "    # We want columns to be time points, rows to be patients\n",
    "    df = df.T  # Transpose so shape becomes [num_intervals, num_patients]\n",
    "    \n",
    "    # Convert time_points to numpy if it's a tensor (ensure CPU)\n",
    "    if torch.is_tensor(time_points):\n",
    "        time_points = time_points.detach().cpu().numpy()\n",
    "    \n",
    "    # Set the index to time points\n",
    "    df.index = time_points\n",
    "    df.index.name = 'time'\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the GPU-compatible fix to ModelCoach\n",
    "from coach import ModelCoach\n",
    "ModelCoach._predictions_to_pycox = gpu_fixed_predictions_to_pycox\n",
    "print(\"âœ… Applied GPU-compatible fix to ModelCoach._predictions_to_pycox method\")\n",
    "\n",
    "# Debug info with GPU handling\n",
    "print(f\"Model output intervals shape: {len(gpu_multisurv.output_intervals)}\")\n",
    "print(f\"Model output intervals device: {gpu_multisurv.output_intervals.device}\")\n",
    "print(f\"Model risk layer output: {gpu_multisurv.model.risk_layer[0].out_features}\")\n",
    "print(f\"Expected: {len(gpu_multisurv.output_intervals) - 1} intervals for {len(gpu_multisurv.output_intervals)} breakpoints\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "import os\n",
    "import time\n",
    "import utils\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# 2. Set up training parameters\n",
    "picked_lr = 5e-3\n",
    "\n",
    "# Add timestamp to make unique run tags\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "run_tag = utils.compose_run_tag(\n",
    "    model=gpu_multisurv, \n",
    "    lr=picked_lr,\n",
    "    dataloaders=gpu_multisurv.dataloaders,\n",
    "    log_dir='./training_logs/',\n",
    "    suffix=f'_breast_cancer_{timestamp}'  # Add timestamp\n",
    ")\n",
    "\n",
    "# 3. Create log directory (now it will be unique)\n",
    "log_dir = os.path.join('./training_logs/', run_tag)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "print(f\"Log directory created: {log_dir}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "fit_args = {\n",
    "    'lr': picked_lr,\n",
    "    'num_epochs': 75,\n",
    "    'info_freq': 5,\n",
    "    'lr_factor': 0.5,\n",
    "    'scheduler_patience': 10,\n",
    "    'log_dir': log_dir,  # Use the verified directory\n",
    "}\n",
    "\n",
    "print(f\"Starting training with LR: {picked_lr}\")\n",
    "\n",
    "# 4. Train the model\n",
    "gpu_multisurv.fit(**fit_args)\n",
    "\n",
    "# 5. Calculate and display elapsed time\n",
    "hrs, mins, secs = utils.elapsed_time(start_time)\n",
    "print(f\"Training completed in {hrs}h {mins}m {secs}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PRE-TRAINING GPU VERIFICATION ===\n",
      "GPU model device: cuda:0\n",
      "GPU intervals device: cuda:0\n",
      "GPU device setting: cuda:0\n",
      "GPU memory before training: 1.64 GB\n",
      "Run tag: \"clinical_lr0.001_breast_cancer_gpu_20250621_104816\"\n",
      "âœ… Log directory created: ./training_logs/clinical_lr0.001_breast_cancer_gpu_20250621_104816\n",
      "âœ… Setup complete - ready for GPU training!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup with GPU verification\n",
    "import os\n",
    "import time\n",
    "import utils\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# 2. Verify GPU setup before training\n",
    "print(\"=== PRE-TRAINING GPU VERIFICATION ===\")\n",
    "print(f\"GPU model device: {next(gpu_multisurv.model.parameters()).device}\")\n",
    "print(f\"GPU intervals device: {gpu_multisurv.output_intervals.device}\")\n",
    "print(f\"GPU device setting: {gpu_multisurv.device}\")\n",
    "\n",
    "# Check GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "    print(f\"GPU memory before training: {allocated:.2f} GB\")\n",
    "\n",
    "# 3. Set up training parameters\n",
    "picked_lr = 1e-3\n",
    "\n",
    "# Add timestamp to make unique run tags\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "run_tag = utils.compose_run_tag(\n",
    "    model=gpu_multisurv, \n",
    "    lr=picked_lr,\n",
    "    dataloaders=gpu_multisurv.dataloaders,\n",
    "    log_dir='./training_logs/',\n",
    "    suffix=f'_breast_cancer_gpu_{timestamp}'  # Added 'gpu' to indicate GPU training\n",
    ")\n",
    "\n",
    "# 4. Create log directory\n",
    "log_dir = os.path.join('./training_logs/', run_tag)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "print(f\"âœ… Log directory created: {log_dir}\")\n",
    "\n",
    "print(\"âœ… Setup complete - ready for GPU training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting GPU training with LR: 0.001\n",
      "ðŸ“Š Expected to see GPU utilization spike during training\n",
      "ðŸ“ Logs will be saved to: ./training_logs/clinical_lr0.001_breast_cancer_gpu_20250621_104816\n",
      "\n",
      "=== GPU STATUS BEFORE TRAINING ===\n",
      "ðŸŽ¯ GPU Memory: 1.64 GB allocated, 1.69 GB reserved\n",
      "\n",
      "â° Training started at: 10:48:16\n",
      "Instantiating MultiSurv model...\n",
      "\n",
      "------------------------------------------\n",
      "             Training        Validation\n",
      "           ------------     ------------\n",
      " Epoch     Loss     Ctd     Loss     Ctd\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/multisurv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/100    0.0288   0.489   0.0182   0.658\n",
      " 5/100    0.0194   0.624   0.0193   0.593\n",
      " 10/100   0.0184   0.625   0.0180   0.626\n",
      " 15/100   0.0184   0.637   0.0190   0.616\n",
      " 20/100   0.0166   0.639   0.0184   0.597\n",
      " 25/100   0.0166   0.660   0.0189   0.641\n",
      " 30/100   0.0173   0.652   0.0206   0.649\n",
      " 35/100   0.0148   0.686   0.0178   0.626\n",
      " 40/100   0.0151   0.657   0.0176   0.658\n",
      " 45/100   0.0142   0.663   0.0174   0.624\n",
      " 50/100   0.0148   0.620   0.0186   0.605\n",
      " 55/100   0.0148   0.628   0.0178   0.592\n",
      " 60/100   0.0150   0.650   0.0168   0.635\n",
      " 65/100   0.0141   0.659   0.0181   0.712\n",
      " 70/100   0.0142   0.648   0.0179   0.650\n",
      " 75/100   0.0144   0.626   0.0184   0.664\n",
      " 80/100   0.0140   0.642   0.0181   0.552\n",
      " 85/100   0.0135   0.694   0.0181   0.640\n",
      " 90/100   0.0139   0.692   0.0186   0.605\n",
      " 95/100   0.0134   0.687   0.0185   0.605\n",
      " 100/100  0.0134   0.697   0.0184   0.542\n",
      "\n",
      ">>>>> Training completed in 5m 11s\n",
      ">>>>> Best validation C-indices:\n",
      "     0.6986301369863014 (epoch63)\n",
      "     0.7110834371108343 (epoch64)\n",
      "     0.7123287671232876 (epoch65)\n",
      "\n",
      "âœ… Training completed successfully!\n",
      "\n",
      "=== GPU STATUS AFTER TRAINING ===\n",
      "ðŸŽ¯ GPU Memory: 1.84 GB allocated, 1.99 GB reserved\n",
      "\n",
      "â° Training completed in 0h 5m 11s\n",
      "ðŸ Training finished at: 10:53:27\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Training execution with GPU monitoring\n",
    "fit_args = {\n",
    "    'lr': picked_lr,\n",
    "    'num_epochs': 100,\n",
    "    'info_freq': 5,\n",
    "    'lr_factor': 0.5,\n",
    "    'scheduler_patience': 20,\n",
    "    'log_dir': log_dir,\n",
    "}\n",
    "\n",
    "print(f\"ðŸš€ Starting GPU training with LR: {picked_lr}\")\n",
    "print(f\"ðŸ“Š Expected to see GPU utilization spike during training\")\n",
    "print(f\"ðŸ“ Logs will be saved to: {log_dir}\")\n",
    "\n",
    "# Function to monitor GPU during training\n",
    "def check_gpu_status():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "        reserved = torch.cuda.memory_reserved(0) / 1024**3\n",
    "        print(f\"ðŸŽ¯ GPU Memory: {allocated:.2f} GB allocated, {reserved:.2f} GB reserved\")\n",
    "    else:\n",
    "        print(\"âŒ CUDA not available\")\n",
    "\n",
    "# Check GPU before training\n",
    "print(\"\\n=== GPU STATUS BEFORE TRAINING ===\")\n",
    "check_gpu_status()\n",
    "\n",
    "# Clear any cached memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Start training\n",
    "print(f\"\\nâ° Training started at: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "\n",
    "try:\n",
    "    # This is where the actual training happens\n",
    "    gpu_multisurv.fit(**fit_args)\n",
    "    \n",
    "    print(f\"\\nâœ… Training completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Training failed with error: {e}\")\n",
    "    print(\"This might be due to GPU memory issues or device mismatches\")\n",
    "    # Print more debug info\n",
    "    print(f\"Model device: {next(gpu_multisurv.model.parameters()).device}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# Check GPU after training\n",
    "print(\"\\n=== GPU STATUS AFTER TRAINING ===\")\n",
    "check_gpu_status()\n",
    "\n",
    "# Calculate and display elapsed time\n",
    "hrs, mins, secs = utils.elapsed_time(start_time)\n",
    "print(f\"\\nâ° Training completed in {hrs}h {mins}m {secs}s\")\n",
    "print(f\"ðŸ Training finished at: {datetime.now().strftime('%H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model weights\n",
    "\n",
    "If desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch63', 'epoch64', 'epoch65'])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_multisurv.best_model_weights.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch63': 0.6986301369863014,\n",
       " 'epoch64': 0.7110834371108343,\n",
       " 'epoch65': 0.7123287671232876}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_multisurv.best_concord_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch100': 0.5417185554171855}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_multisurv.current_concord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model weights to file:\n",
      "    /mnt/data/multisurv_models/clinical_lr0.001_breast_cancer_gpu_20250621_100930_epoch85_concord0.71.pth\n"
     ]
    }
   ],
   "source": [
    "gpu_multisurv.save_weights(saved_epoch='epoch85', prefix=run_tag, weight_dir=MODELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Applied fix to _BaseEvaluation._predictions_to_pycox\n",
      "âœ… Applied fix to Evaluation._predictions_to_pycox\n",
      "ðŸ’¡ Note: There's a syntax warning in evaluation.py line 187\n",
      "   Change 'self.type is not 'MultiSurv'' to 'self.type != 'MultiSurv''\n",
      "   This doesn't affect functionality but should be fixed in the source code\n",
      "\n",
      "ðŸ”§ Evaluation fixes applied! Now try running your evaluation again.\n"
     ]
    }
   ],
   "source": [
    "# Fix for evaluation.py _predictions_to_pycox method\n",
    "\n",
    "def fixed_evaluation_predictions_to_pycox(self, data, time_points=None):\n",
    "    \"\"\"Fixed evaluation version that handles the correct dimensions.\"\"\"\n",
    "    import pandas as pd\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    \n",
    "    # Extract predictions from data\n",
    "    # data should be a list of tuples: (predictions, times, events, patient_ids)\n",
    "    predictions_list = []\n",
    "    for item in data:\n",
    "        pred = item[0]  # The prediction tensor\n",
    "        if torch.is_tensor(pred):\n",
    "            pred = pred.detach().cpu().numpy()\n",
    "        predictions_list.append(pred)\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    predictions = np.array(predictions_list)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(predictions)\n",
    "    \n",
    "    if time_points is None:\n",
    "        # Get the number of intervals from the model output\n",
    "        n_intervals = predictions.shape[1]  # Should be 18 for your model\n",
    "        \n",
    "        # Use the model's actual output intervals if available\n",
    "        if hasattr(self, 'model') and hasattr(self.model, 'output_intervals') and self.model.output_intervals is not None:\n",
    "            # Use the midpoints of the output intervals\n",
    "            intervals = self.model.output_intervals\n",
    "            if torch.is_tensor(intervals):\n",
    "                intervals = intervals.detach().cpu().numpy()\n",
    "            \n",
    "            if len(intervals) > n_intervals:\n",
    "                # Take the first n_intervals midpoints\n",
    "                midpoints = (intervals[:-1] + intervals[1:]) / 2\n",
    "                time_points = midpoints[:n_intervals]\n",
    "            else:\n",
    "                # Fallback to evenly spaced points\n",
    "                last_interval = intervals[-1] if not torch.is_tensor(intervals) else intervals[-1].item()\n",
    "                time_points = np.linspace(0.5, last_interval / 365, n_intervals)\n",
    "        else:\n",
    "            # Fallback: create time points that match the output size\n",
    "            time_points = np.arange(0.5, 0.5 + n_intervals, 1.0)\n",
    "    \n",
    "    # Ensure time_points matches the prediction dimensions\n",
    "    if len(time_points) != predictions.shape[1]:\n",
    "        print(f\"Warning: Adjusting time_points from {len(time_points)} to {predictions.shape[1]}\")\n",
    "        first_point = time_points[0] if len(time_points) > 0 else 0.5\n",
    "        last_point = time_points[-1] if len(time_points) > 0 else n_intervals + 0.5\n",
    "        time_points = np.linspace(first_point, last_point, predictions.shape[1])\n",
    "    \n",
    "    # FIXED: The DataFrame structure should be transposed\n",
    "    # We want columns to be time points, rows to be patients\n",
    "    df = df.T  # Transpose so shape becomes [num_intervals, num_patients]\n",
    "    \n",
    "    # Convert time_points to numpy if it's a tensor\n",
    "    if torch.is_tensor(time_points):\n",
    "        time_points = time_points.detach().cpu().numpy()\n",
    "    \n",
    "    # Set the index to time points\n",
    "    df.index = time_points\n",
    "    df.index.name = 'time'\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the fix to the evaluation module\n",
    "import evaluation\n",
    "\n",
    "# Check if the _BaseEvaluation class exists and patch it\n",
    "if hasattr(evaluation, '_BaseEvaluation'):\n",
    "    evaluation._BaseEvaluation._predictions_to_pycox = fixed_evaluation_predictions_to_pycox\n",
    "    print(\"âœ… Applied fix to _BaseEvaluation._predictions_to_pycox\")\n",
    "else:\n",
    "    print(\"âŒ _BaseEvaluation class not found\")\n",
    "\n",
    "# Also check for Evaluation class\n",
    "if hasattr(evaluation, 'Evaluation'):\n",
    "    evaluation.Evaluation._predictions_to_pycox = fixed_evaluation_predictions_to_pycox\n",
    "    print(\"âœ… Applied fix to Evaluation._predictions_to_pycox\")\n",
    "\n",
    "# Fix the syntax warning too\n",
    "def patch_syntax_warning():\n",
    "    \"\"\"Fix the syntax warning in evaluation.py if possible.\"\"\"\n",
    "    print(\"ðŸ’¡ Note: There's a syntax warning in evaluation.py line 187\")\n",
    "    print(\"   Change 'self.type is not 'MultiSurv'' to 'self.type != 'MultiSurv''\")\n",
    "    print(\"   This doesn't affect functionality but should be fixed in the source code\")\n",
    "\n",
    "patch_syntax_warning()\n",
    "\n",
    "print(\"\\nðŸ”§ Evaluation fixes applied! Now try running your evaluation again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Applied clinical data shape fix to Evaluation._get_patient_predictions\n"
     ]
    }
   ],
   "source": [
    "# Fix the data shape issue in get_patient_predictions\n",
    "def fixed_get_patient_predictions(self, idx):\n",
    "    \"\"\"Fixed version that handles 1D continuous tensor correctly.\"\"\"\n",
    "    patient_data = self.dataset[idx]\n",
    "    data_dict, time, event = patient_data\n",
    "    \n",
    "    # Create batch data\n",
    "    batch_data = {}\n",
    "    for key, value in data_dict.items():\n",
    "        if key == 'clinical' and isinstance(value, tuple):\n",
    "            cat, cont = value\n",
    "            # Fix: ensure continuous is 2D [1, n_features]\n",
    "            if cont.dim() == 1:\n",
    "                cont = cont.unsqueeze(0)\n",
    "            batch_data[key] = (cat.unsqueeze(0).to(self.device), \n",
    "                              cont.unsqueeze(0).to(self.device))\n",
    "        else:\n",
    "            batch_data[key] = value.unsqueeze(0).to(self.device)\n",
    "    \n",
    "    # Get prediction\n",
    "    with torch.no_grad():\n",
    "        _, risk = self.model.model(batch_data)\n",
    "    \n",
    "    return risk.squeeze(0).cpu()\n",
    "\n",
    "# Apply the fix\n",
    "import evaluation\n",
    "evaluation.Evaluation._get_patient_predictions = fixed_get_patient_predictions\n",
    "print(\"âœ… Applied clinical data shape fix to Evaluation._get_patient_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Applied final fix for nested dictionary structure\n"
     ]
    }
   ],
   "source": [
    "# Final fix for _predictions_to_pycox\n",
    "def fixed_evaluation_predictions_to_pycox_final(self, data, time_points=None):\n",
    "    \"\"\"Fixed version that handles the nested dictionary structure.\"\"\"\n",
    "    import pandas as pd\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    \n",
    "    # Extract predictions from the nested dictionary structure\n",
    "    predictions_list = []\n",
    "    times_list = []\n",
    "    events_list = []\n",
    "    patient_ids = []\n",
    "    \n",
    "    for patient_id, patient_data in data.items():\n",
    "        if isinstance(patient_data, dict):\n",
    "            # Extract probabilities from the dictionary\n",
    "            prob = patient_data['probabilities']\n",
    "            if torch.is_tensor(prob):\n",
    "                prob = prob.detach().cpu().numpy()\n",
    "            predictions_list.append(prob)\n",
    "            \n",
    "            # Also collect times and events for verification\n",
    "            times_list.append(patient_data['time'])\n",
    "            events_list.append(patient_data['event'])\n",
    "            patient_ids.append(patient_id)\n",
    "        else:\n",
    "            # Fallback for other formats\n",
    "            if torch.is_tensor(patient_data):\n",
    "                predictions_list.append(patient_data.detach().cpu().numpy())\n",
    "            else:\n",
    "                predictions_list.append(patient_data[0])\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    predictions = np.array(predictions_list)\n",
    "    print(f\"Extracted predictions shape: {predictions.shape}\")\n",
    "    \n",
    "    # Create DataFrame with patients as rows, time intervals as columns\n",
    "    df = pd.DataFrame(predictions)\n",
    "    \n",
    "    if time_points is None:\n",
    "        n_intervals = predictions.shape[1]\n",
    "        \n",
    "        # Use the model's actual output intervals if available\n",
    "        if hasattr(self, 'model') and hasattr(self.model, 'output_intervals') and self.model.output_intervals is not None:\n",
    "            intervals = self.model.output_intervals\n",
    "            if torch.is_tensor(intervals):\n",
    "                intervals = intervals.detach().cpu().numpy()\n",
    "            \n",
    "            # Create midpoints for time intervals\n",
    "            if len(intervals) == n_intervals + 1:\n",
    "                # intervals are boundaries, we need midpoints\n",
    "                time_points = (intervals[:-1] + intervals[1:]) / 2\n",
    "            else:\n",
    "                # Fallback\n",
    "                time_points = np.linspace(0.5, 20, n_intervals)\n",
    "        else:\n",
    "            # Fallback: create evenly spaced time points\n",
    "            time_points = np.arange(0.5, 0.5 + n_intervals, 1.0)\n",
    "    \n",
    "    # Ensure time_points matches prediction dimensions\n",
    "    if len(time_points) != predictions.shape[1]:\n",
    "        time_points = np.linspace(0.5, 20, predictions.shape[1])\n",
    "    \n",
    "    # Transpose so time is the index (required by pycox)\n",
    "    df = df.T\n",
    "    df.index = time_points\n",
    "    df.index.name = 'time'\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the final fix\n",
    "import evaluation\n",
    "evaluation.Evaluation._predictions_to_pycox = fixed_evaluation_predictions_to_pycox_final\n",
    "print(\"âœ… Applied final fix for nested dictionary structure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collect patient predictions: 165/165\n",
      "\n",
      "C-index   0.541\n",
      "Ctd       0.499\n",
      "IBS       0.141\n",
      "INBLL     0.434\n"
     ]
    }
   ],
   "source": [
    "performance = utils.Evaluation(\n",
    "    model=gpu_multisurv, dataset=dataloaders['val'].dataset,\n",
    "    device=device)\n",
    "performance.compute_metrics()\n",
    "cv_results.append(performance)\n",
    "performance.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collect patient predictions: 218/218\n",
      "\n",
      "TEST SET RESULTS:\n",
      "C-index   0.594\n",
      "Ctd       0.59\n",
      "IBS       0.164\n",
      "INBLL     0.488\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on TEST set (not validation)\n",
    "performance = utils.Evaluation(\n",
    "    model=gpu_multisurv, \n",
    "    dataset=dataloaders['test'].dataset,  # Note: 'test' not 'val'\n",
    "    device=device\n",
    ")\n",
    "performance.compute_metrics()\n",
    "cv_results_test.append(performance)\n",
    "print(\"TEST SET RESULTS:\")\n",
    "performance.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-index   0.498\n",
      "Ctd       0.56\n",
      "IBS       0.213\n",
      "INBLL     0.669\n",
      "C-index   0.577\n",
      "Ctd       0.565\n",
      "IBS       0.173\n",
      "INBLL     0.536\n",
      "C-index   0.636\n",
      "Ctd       0.633\n",
      "IBS       0.157\n",
      "INBLL     0.475\n",
      "C-index   0.594\n",
      "Ctd       0.59\n",
      "IBS       0.164\n",
      "INBLL     0.488\n"
     ]
    }
   ],
   "source": [
    "for i in cv_results_test:\n",
    "    i.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4-fold CV Results (val group):\n",
      "Mean Ctd: 0.564\n",
      "Std Ctd: 0.084\n",
      "\n",
      "4-fold CV Results (test group):\n",
      "Mean Ctd: 0.587\n",
      "Std Ctd: 0.029\n"
     ]
    }
   ],
   "source": [
    "results_ctd = [0.702, 0.493, 0.562, 0.499]\n",
    "results_test_ctd = [0.56, 0.565, 0.633, 0.59]\n",
    "\n",
    "print(f\"\\n4-fold CV Results (val group):\")\n",
    "print(f\"Mean Ctd: {np.mean([r for r in results_ctd]):.3f}\")\n",
    "print(f\"Std Ctd: {np.std([r for r in results_ctd]):.3f}\")\n",
    "\n",
    "print(f\"\\n4-fold CV Results (test group):\")\n",
    "print(f\"Mean Ctd: {np.mean([r for r in results_test_ctd]):.3f}\")\n",
    "print(f\"Std Ctd: {np.std([r for r in results_test_ctd]):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watermark <a class='tocSkip'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark --iversions\n",
    "%watermark -v\n",
    "print()\n",
    "%watermark -u -n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of the page](#Top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "197px",
    "width": "372px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "236px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
