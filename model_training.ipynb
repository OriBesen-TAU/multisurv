{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Top'></a>\n",
    "\n",
    "# Multisurv model training<a class='tocSkip'></a>\n",
    "\n",
    "Train MultiSurv models with different combinations of input data modalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /opt/conda/envs/multisurv/lib/python3.8/site-packages (2.17.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (1.62.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (3.6)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (1.24.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (25.0)\n",
      "Requirement already satisfied: protobuf in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (4.25.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (75.3.0)\n",
      "Requirement already satisfied: six>1.9 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (3.0.6)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard) (8.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.21.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> PyTorch detected CUDA <<<\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%load_ext watermark\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pynvml\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('>>> PyTorch detected CUDA <<<')\n",
    "\n",
    "# Make modules in \"src\" dir visible\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.append(os.path.join(os.getcwd(), 'src'))\n",
    "\n",
    "import utils\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#DataLoader\" data-toc-modified-id=\"DataLoader-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span><code>DataLoader</code></a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Different-intervals\" data-toc-modified-id=\"Different-intervals-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Different intervals</a></span><ul class=\"toc-item\"><li><span><a href=\"#Equidistant-times\" data-toc-modified-id=\"Equidistant-times-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Equidistant times</a></span></li><li><span><a href=\"#By-duration-quantiles\" data-toc-modified-id=\"By-duration-quantiles-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>By duration quantiles</a></span></li></ul></li><li><span><a href=\"#Pick-learning-rate\" data-toc-modified-id=\"Pick-learning-rate-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Pick learning rate</a></span></li><li><span><a href=\"#Fit\" data-toc-modified-id=\"Fit-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Fit</a></span><ul class=\"toc-item\"><li><span><a href=\"#Save-model-weights\" data-toc-modified-id=\"Save-model-weights-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Save model weights</a></span></li></ul></li><li><span><a href=\"#Check-validation-metrics\" data-toc-modified-id=\"Check-validation-metrics-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Check validation metrics</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 PyTorch is using: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "✅ NVIDIA GPU detected - good for training!\n",
      "\n",
      "==================================================\n",
      "=== GPU DETECTION REPORT ===\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "PyTorch version: 2.4.0\n",
      "Number of CUDA devices: 1\n",
      "\n",
      "=== AVAILABLE GPUS ===\n",
      "GPU 0: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "  Memory: 8.0 GB\n",
      "  Compute Capability: 8.9\n",
      "  Multi Processors: 24\n",
      "\n",
      "=== CURRENT SELECTION ===\n",
      "Current CUDA device: 0\n",
      "Current GPU name: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "\n",
      "=== MEMORY USAGE ===\n",
      "GPU 0 (NVIDIA GeForce RTX 4060 Laptop GPU):\n",
      "  Allocated: 0.00 GB\n",
      "  Reserved: 0.00 GB\n",
      "  Total: 8.0 GB\n",
      "\n",
      "=== GPU FUNCTIONALITY TEST ===\n",
      "✅ GPU computation successful\n",
      "Test tensor device: cuda:0\n",
      "Result tensor device: cuda:0\n",
      "\n",
      "=== NVIDIA SYSTEM INFO ===\n",
      "NVIDIA-SMI Output:\n",
      "Thu Jun 19 12:00:38 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 575.64.01              Driver Version: 576.80         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 ...    On  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   45C    P0             16W /  112W |     123MiB /   8188MiB |     10%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A              28      C   /python3.8                            N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n",
      "✅ Using single GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "\n",
      "=== PYTORCH GPU VERIFICATION ===\n",
      "✅ PyTorch using: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "✅ Confirmed: Using NVIDIA GPU\n",
      "\n",
      "=== RECOMMENDATION ===\n",
      "✅ Ready for GPU training with device: cuda:0\n",
      "Use: multisurv.device = cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import subprocess\n",
    "\n",
    "def check_gpu_setup():\n",
    "    \"\"\"Complete GPU detection and verification.\"\"\"\n",
    "    \n",
    "    print(\"=== GPU DETECTION REPORT ===\")\n",
    "    \n",
    "    # 1. Check CUDA availability\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    \n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"❌ CUDA not available - will use CPU\")\n",
    "        return\n",
    "    \n",
    "    # 2. Check number of GPUs\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"Number of CUDA devices: {gpu_count}\")\n",
    "    \n",
    "    # 3. List all available GPUs\n",
    "    print(\"\\n=== AVAILABLE GPUS ===\")\n",
    "    for i in range(gpu_count):\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        print(f\"GPU {i}: {props.name}\")\n",
    "        print(f\"  Memory: {props.total_memory / 1024**3:.1f} GB\")\n",
    "        print(f\"  Compute Capability: {props.major}.{props.minor}\")\n",
    "        print(f\"  Multi Processors: {props.multi_processor_count}\")\n",
    "    \n",
    "    # 4. Check current device\n",
    "    current_device = torch.cuda.current_device()\n",
    "    current_name = torch.cuda.get_device_name(current_device)\n",
    "    print(f\"\\n=== CURRENT SELECTION ===\")\n",
    "    print(f\"Current CUDA device: {current_device}\")\n",
    "    print(f\"Current GPU name: {current_name}\")\n",
    "    \n",
    "    # 5. Memory usage\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"\\n=== MEMORY USAGE ===\")\n",
    "        for i in range(gpu_count):\n",
    "            allocated = torch.cuda.memory_allocated(i) / 1024**3\n",
    "            reserved = torch.cuda.memory_reserved(i) / 1024**3\n",
    "            total = torch.cuda.get_device_properties(i).total_memory / 1024**3\n",
    "            print(f\"GPU {i} ({torch.cuda.get_device_name(i)}):\")\n",
    "            print(f\"  Allocated: {allocated:.2f} GB\")\n",
    "            print(f\"  Reserved: {reserved:.2f} GB\")\n",
    "            print(f\"  Total: {total:.1f} GB\")\n",
    "    \n",
    "    # 6. Test tensor creation on GPU\n",
    "    print(f\"\\n=== GPU FUNCTIONALITY TEST ===\")\n",
    "    try:\n",
    "        # Create test tensor on GPU\n",
    "        test_tensor = torch.randn(1000, 1000).cuda()\n",
    "        result = torch.mm(test_tensor, test_tensor)\n",
    "        print(f\"✅ GPU computation successful\")\n",
    "        print(f\"Test tensor device: {test_tensor.device}\")\n",
    "        print(f\"Result tensor device: {result.device}\")\n",
    "        \n",
    "        # Cleanup\n",
    "        del test_tensor, result\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ GPU computation failed: {e}\")\n",
    "\n",
    "def check_nvidia_system():\n",
    "    \"\"\"Check NVIDIA system information.\"\"\"\n",
    "    print(\"\\n=== NVIDIA SYSTEM INFO ===\")\n",
    "    \n",
    "    try:\n",
    "        # Run nvidia-smi command\n",
    "        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(\"NVIDIA-SMI Output:\")\n",
    "            print(result.stdout)\n",
    "        else:\n",
    "            print(\"❌ nvidia-smi command failed\")\n",
    "            print(result.stderr)\n",
    "    except FileNotFoundError:\n",
    "        print(\"❌ nvidia-smi not found - NVIDIA drivers may not be installed\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error running nvidia-smi: {e}\")\n",
    "\n",
    "def set_gpu_preference():\n",
    "    \"\"\"Set GPU preference if multiple GPUs available.\"\"\"\n",
    "    \n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"No CUDA GPUs available\")\n",
    "        return None\n",
    "    \n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    \n",
    "    if gpu_count == 1:\n",
    "        device = torch.device('cuda:0')\n",
    "        print(f\"✅ Using single GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        return device\n",
    "    \n",
    "    print(f\"\\n=== MULTIPLE GPUS DETECTED ({gpu_count}) ===\")\n",
    "    \n",
    "    # Show GPU options\n",
    "    for i in range(gpu_count):\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        print(f\"GPU {i}: {props.name} ({props.total_memory / 1024**3:.1f} GB)\")\n",
    "    \n",
    "    # Find the most powerful GPU (by memory)\n",
    "    best_gpu = 0\n",
    "    best_memory = 0\n",
    "    \n",
    "    for i in range(gpu_count):\n",
    "        memory = torch.cuda.get_device_properties(i).total_memory\n",
    "        if memory > best_memory:\n",
    "            best_memory = memory\n",
    "            best_gpu = i\n",
    "    \n",
    "    device = torch.device(f'cuda:{best_gpu}')\n",
    "    print(f\"✅ Auto-selected most powerful GPU: {torch.cuda.get_device_name(best_gpu)}\")\n",
    "    \n",
    "    # Set as current device\n",
    "    torch.cuda.set_device(best_gpu)\n",
    "    \n",
    "    return device\n",
    "\n",
    "def verify_pytorch_gpu_usage():\n",
    "    \"\"\"Verify PyTorch is actually using the NVIDIA GPU (not Intel).\"\"\"\n",
    "    \n",
    "    print(\"\\n=== PYTORCH GPU VERIFICATION ===\")\n",
    "    \n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"❌ PyTorch not using GPU - will use CPU\")\n",
    "        return False\n",
    "    \n",
    "    # Create tensor and check device\n",
    "    x = torch.randn(100, 100).cuda()\n",
    "    gpu_name = torch.cuda.get_device_name(x.device)\n",
    "    \n",
    "    print(f\"✅ PyTorch using: {gpu_name}\")\n",
    "    \n",
    "    # Check if it's NVIDIA (not Intel)\n",
    "    if 'nvidia' in gpu_name.lower() or 'geforce' in gpu_name.lower() or 'rtx' in gpu_name.lower() or 'gtx' in gpu_name.lower():\n",
    "        print(f\"✅ Confirmed: Using NVIDIA GPU\")\n",
    "        return True\n",
    "    elif 'intel' in gpu_name.lower():\n",
    "        print(f\"⚠️  Warning: Using Intel GPU - this may be slow for deep learning\")\n",
    "        return False\n",
    "    else:\n",
    "        print(f\"❓ Unknown GPU type: {gpu_name}\")\n",
    "        return True\n",
    "\n",
    "# Run all checks\n",
    "def complete_gpu_check():\n",
    "    \"\"\"Run complete GPU diagnostic.\"\"\"\n",
    "    check_gpu_setup()\n",
    "    check_nvidia_system()\n",
    "    device = set_gpu_preference()\n",
    "    is_nvidia = verify_pytorch_gpu_usage()\n",
    "    \n",
    "    print(f\"\\n=== RECOMMENDATION ===\")\n",
    "    if is_nvidia and device:\n",
    "        print(f\"✅ Ready for GPU training with device: {device}\")\n",
    "        print(f\"Use: multisurv.device = {device}\")\n",
    "    else:\n",
    "        print(\"⚠️  Consider using CPU training: multisurv.device = torch.device('cpu')\")\n",
    "    \n",
    "    return device\n",
    "\n",
    "# Quick check function\n",
    "def quick_gpu_check():\n",
    "    \"\"\"Quick GPU check for immediate feedback.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        print(f\"🎯 PyTorch is using: {gpu_name}\")\n",
    "        \n",
    "        if any(keyword in gpu_name.lower() for keyword in ['nvidia', 'geforce', 'rtx', 'gtx']):\n",
    "            print(\"✅ NVIDIA GPU detected - good for training!\")\n",
    "        else:\n",
    "            print(\"⚠️  Non-NVIDIA GPU detected\")\n",
    "    else:\n",
    "        print(\"❌ No GPU available - will use CPU\")\n",
    "\n",
    "# Run the checks\n",
    "quick_gpu_check()\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "complete_gpu_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = utils.INPUT_DATA_DIR\n",
    "MODELS = utils.TRAINED_MODEL_DIR\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4952887d97314b7e9ae4501d42b6d468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Input data', index=(0, 1), options=('clinical', 'mRNA', 'DNAm', 'miRNA', 'CNV', 'w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_modalities = widgets.SelectMultiple(\n",
    "    options=['clinical', 'mRNA', 'DNAm', 'miRNA', 'CNV', 'wsi'],\n",
    "    index=[0, 1],\n",
    "    rows=6,\n",
    "    description='Input data',\n",
    "    disabled=False\n",
    ")\n",
    "display(data_modalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   submitter_id      time  event  group\n",
      "0  TCGA-Z7-A8R6  8.920548      0  train\n",
      "1  TCGA-C8-A1HE  1.027397      0  train\n",
      "2  TCGA-A8-A07B  3.583562      0  train\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------------------------------#\n",
    "#                             20-CANCER SUBSET                                #\n",
    "#                 (to compare to Cheerla and Gevaert 2019)                    #\n",
    "#-----------------------------------------------------------------------------#\n",
    "\n",
    "cancers = ['BRCA']\n",
    "\n",
    "labels = pd.read_csv('/app/data/labels.tsv', sep='\\t')\n",
    "print(labels.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data modalities:\n",
      "   clinical\n",
      "\n",
      "Dataset sizes (# patients):\n",
      "   train: 876\n",
      "   val: 110\n",
      "   test: 108\n",
      "\n",
      "Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "dataloaders = utils.get_dataloaders(data_location=DATA,\n",
    "                                    labels_file='/app/data/labels.tsv',\n",
    "                                    modalities=data_modalities.value,\n",
    "                                    wsi_patch_size=299,\n",
    "                                    n_wsi_patches=5,\n",
    "#                                     batch_size=20,\n",
    "#                                    batch_size=64,\n",
    "                                     batch_size=32,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different intervals\n",
    "\n",
    "If trying out different time interval outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equidistant times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_cuts = torch.arange(0., 365 * 5.1, 365 / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By duration quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [(t, e) for t, e in dataloaders['train'].dataset.label_map.values()]\n",
    "durations = [t for t, _ in labels]\n",
    "events = [e for _, e in labels]\n",
    "\n",
    "interval_cuts = utils.discretize_time_by_duration_quantiles(durations, events, 20)\n",
    "interval_cuts = torch.from_numpy(interval_cuts)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#-----------------------------------------------------------------------------#\n",
    "#                       PRE-TRAINED UNIMODAL MODELS                           #\n",
    "#-----------------------------------------------------------------------------#\n",
    "\n",
    "unimodal_weigths = {'clinical': 'clinical_lr0.005_epoch49_acc0.78.pth',\n",
    "                    'mRNA': 'mRNA_lr0.005_epoch54_acc0.76.pth',\n",
    "                    'DNAm': 'DNAm_lr0.005_epoch57_acc0.77.pth',\n",
    "                    'miRNA': None,\n",
    "                    'CNV': None,\n",
    "                    'wsi': None,}\n",
    "\n",
    "unimodal_weigths = {k: os.path.join(MODELS, v) if v is not None else None\n",
    "                    for k, v in unimodal_weigths.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiating MultiSurv model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/src/multisurv.py:84: UserWarning: Input data is unimodal: no fusion procedure.\n",
      "  warnings.warn('Input data is unimodal: no fusion procedure.')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "multisurv = Model(\n",
    "    dataloaders=dataloaders,\n",
    "    auxiliary_criterion=None,  # No auxiliary loss needed\n",
    "    output_intervals=interval_cuts,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gpu_enabled_multisurv():\n",
    "    \"\"\"Create a fresh MultiSurv instance with proper GPU setup.\"\"\"\n",
    "    \n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Creating MultiSurv with device: {device}\")\n",
    "    \n",
    "    \n",
    "    # Create new model with GPU device\n",
    "    gpu_multisurv = Model(\n",
    "        dataloaders=multisurv.dataloaders,  # Reuse existing dataloaders\n",
    "        fusion_method=multisurv.fusion_method,\n",
    "        output_intervals=multisurv.output_intervals.to(device),  # Move to GPU\n",
    "        device=device  # Set device properly\n",
    "    )\n",
    "    \n",
    "    print(\"✅ GPU-enabled MultiSurv created!\")\n",
    "    return gpu_multisurv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MultiSurv with device: cuda:0\n",
      "Instantiating MultiSurv model...\n",
      "✅ GPU-enabled MultiSurv created!\n"
     ]
    }
   ],
   "source": [
    "gpu_multisurv = create_gpu_enabled_multisurv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output intervals (in years):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  1.5562,  2.4137,  3.0712,  4.0082,  4.6356,  5.2767,  6.4329,\n",
       "         6.8904,  7.5589,  8.0904,  8.9342,  9.4685,  9.8822, 10.4301, 10.7562,\n",
       "        11.9479, 19.5233, 23.5753], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Output intervals (in years):')\n",
    "gpu_multisurv.output_intervals / 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clinical_submodel', 'fc_block', 'risk_layer']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_multisurv.model_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable blocks:\n",
      "   clinical_submodel: True\n",
      "   fc_block: True\n",
      "   risk_layer: True\n"
     ]
    }
   ],
   "source": [
    "print('Trainable blocks:')\n",
    "layer = None\n",
    "\n",
    "for name, child in gpu_multisurv.model.named_children():\n",
    "    for name_2, params in child.named_parameters():\n",
    "        if name is not layer:\n",
    "            print(f'   {name}: {params.requires_grad}')\n",
    "        layer = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiSurv(\n",
       "  (clinical_submodel): ClinicalNet(\n",
       "    (embedding_layers): ModuleList(\n",
       "      (0): Embedding(2, 1)\n",
       "      (1): Embedding(7, 4)\n",
       "      (2-4): 3 x Embedding(3, 2)\n",
       "      (5-6): 2 x Embedding(4, 2)\n",
       "    )\n",
       "    (embedding_dropout): Dropout(p=0.5, inplace=False)\n",
       "    (bn_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear): Linear(in_features=16, out_features=256, bias=True)\n",
       "    (output_layer): FC(\n",
       "      (fc): Sequential(\n",
       "        (0): Dropout(p=0.5, inplace=False)\n",
       "        (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_block): FC(\n",
       "    (fc): Sequential(\n",
       "      (0): Dropout(p=0.5, inplace=False)\n",
       "      (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): Dropout(p=0.5, inplace=False)\n",
       "      (5): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (6): ReLU()\n",
       "      (7): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (12): Dropout(p=0.5, inplace=False)\n",
       "      (13): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (14): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (risk_layer): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=18, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_multisurv.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 GPU Memory: 1.58 GB allocated, 1.69 GB reserved\n",
      "🔍 GPU cache size: 1.69 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28/1937229576.py:9: FutureWarning: `torch.cuda.memory_cached` has been renamed to `torch.cuda.memory_reserved`\n",
      "  print(f\"🔍 GPU cache size: {torch.cuda.memory_cached(0) / 1024**3:.2f} GB\")\n"
     ]
    }
   ],
   "source": [
    "# Check GPU usage after LR test\n",
    "def monitor_gpu_real_time():\n",
    "    import torch\n",
    "    allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "    reserved = torch.cuda.memory_reserved(0) / 1024**3\n",
    "    print(f\"🎯 GPU Memory: {allocated:.2f} GB allocated, {reserved:.2f} GB reserved\")\n",
    "    \n",
    "    # Check if there are any tensors on GPU\n",
    "    print(f\"🔍 GPU cache size: {torch.cuda.memory_cached(0) / 1024**3:.2f} GB\")\n",
    "monitor_gpu_real_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features:\n",
      " tensor([0., 6., 0., 1., 0., 1., 1.])\n",
      "Continuous features:\n",
      " tensor([0.5868])\n"
     ]
    }
   ],
   "source": [
    "data_example, _, _ = dataloaders['train'].dataset[0]\n",
    "print(\"Categorical features:\\n\", data_example['clinical'][0])\n",
    "print(\"Continuous features:\\n\", data_example['clinical'][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied GPU-compatible fix to LRRangeTest.run\n"
     ]
    }
   ],
   "source": [
    "# GPU-compatible version of the completely fixed LR test\n",
    "\n",
    "def gpu_fixed_lr_test_run(self, init_value=1e-8, final_value=10., beta=0.98):\n",
    "    \"\"\"GPU-compatible LR test that ensures all tensors are on the same device.\"\"\"\n",
    "    print(\">>> Using GPU-COMPATIBLE FIXED lr_test.run method\")\n",
    "    \n",
    "    power = (1 / (len(self.dataloader) - 1))\n",
    "    mult = (final_value / init_value) ** power\n",
    "    lr = init_value\n",
    "    self.optimizer.param_groups[0]['lr'] = lr\n",
    "    avg_loss = 0.\n",
    "    best_loss = 0.\n",
    "    batch_num = 0\n",
    "\n",
    "    print('>>> Compute loss at increasing LR values')\n",
    "    \n",
    "    # Clear losses and lrs lists\n",
    "    self.losses = []\n",
    "    self.lrs = []\n",
    "\n",
    "    for data in self.dataloader:\n",
    "        batch_num += 1\n",
    "        print('\\r' + f'    Iterate over mini-batches: {str(batch_num)}', end='')\n",
    "\n",
    "        try:\n",
    "            # Unpack data\n",
    "            if len(data) == 3:\n",
    "                modality_data, time, event = data\n",
    "            elif len(data) == 4:\n",
    "                modality_data, time, event, pid = data\n",
    "            \n",
    "            # CRITICAL: Move ALL data to the same device as the model\n",
    "            target_device = next(self.model.parameters()).device\n",
    "            \n",
    "            # Move modality data to device\n",
    "            for key, value in modality_data.items():\n",
    "                if isinstance(value, torch.Tensor):\n",
    "                    modality_data[key] = value.to(target_device)\n",
    "                elif isinstance(value, (list, tuple)):\n",
    "                    modality_data[key] = tuple(v.to(target_device) if isinstance(v, torch.Tensor) else v for v in value)\n",
    "            \n",
    "            # Move time and event to device\n",
    "            time = time.to(target_device)\n",
    "            event = event.to(target_device)\n",
    "            \n",
    "            # Set model to train mode\n",
    "            self.model.train()\n",
    "            \n",
    "            # Clear gradients\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            with torch.set_grad_enabled(True):\n",
    "                feature_representations, risk = self.model(modality_data)\n",
    "                modality_features = feature_representations['modalities']\n",
    "                \n",
    "                # Compute loss with proper device handling\n",
    "                try:\n",
    "                    # Ensure output_intervals are on the same device\n",
    "                    if hasattr(self, 'output_intervals'):\n",
    "                        breaks = self.output_intervals.to(target_device)\n",
    "                    else:\n",
    "                        breaks = torch.linspace(0, 10, 19, device=target_device)  # Fallback\n",
    "                    \n",
    "                    loss = self.criterion(risk, times=time, events=event, breaks=breaks, device=target_device)\n",
    "                    \n",
    "                except Exception as loss_error:\n",
    "                    print(f\"\\nPrimary criterion failed: {loss_error}\")\n",
    "                    # Fallback to simple MSE loss on the same device\n",
    "                    dummy_target = torch.ones_like(risk)  # This will be on the same device as risk\n",
    "                    loss = torch.nn.functional.mse_loss(risk, dummy_target)\n",
    "                    print(\"Using fallback MSE loss\")\n",
    "                \n",
    "                # Add auxiliary loss if needed\n",
    "                if self.aux_criterion is not None:\n",
    "                    try:\n",
    "                        if len(modality_features) >= 2:\n",
    "                            target = torch.ones(modality_features[0].shape[0], device=target_device)\n",
    "                            aux_loss = self.aux_criterion(modality_features[0], modality_features[1], target)\n",
    "                            loss = loss + 0.1 * aux_loss\n",
    "                    except Exception as aux_error:\n",
    "                        print(f\"\\nAuxiliary criterion failed: {aux_error}\")\n",
    "            \n",
    "            # Store the loss value\n",
    "            loss_value = loss.item()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError at batch {batch_num}: {e}\")\n",
    "            break\n",
    "\n",
    "        # Compute the smoothed loss\n",
    "        avg_loss = (beta * avg_loss + (1 - beta) * loss_value)\n",
    "        smoothed_loss = avg_loss / (1 - beta ** batch_num)\n",
    "\n",
    "        # Stop if the loss is exploding\n",
    "        if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
    "            print()\n",
    "            print('    Exploding loss; finish test.')\n",
    "            break\n",
    "\n",
    "        # Record the best loss\n",
    "        if smoothed_loss < best_loss or batch_num == 1:\n",
    "            best_loss = smoothed_loss\n",
    "            \n",
    "        # Store the values\n",
    "        self.losses.append(smoothed_loss)\n",
    "        self.lrs.append(lr)\n",
    "\n",
    "        # Do the backward pass and optimizer step\n",
    "        try:\n",
    "            loss.backward(retain_graph=False)\n",
    "            self.optimizer.step()\n",
    "        except Exception as e:\n",
    "            print(f\"\\nBackward pass failed at batch {batch_num}: {e}\")\n",
    "            break\n",
    "\n",
    "        # Update the lr for the next step\n",
    "        lr *= mult\n",
    "        self.optimizer.param_groups[0]['lr'] = lr\n",
    "        \n",
    "        # Stop after reasonable number of batches\n",
    "        if batch_num >= 100:\n",
    "            print(\"\\nStopping after 100 batches\")\n",
    "            break\n",
    "\n",
    "    print()\n",
    "    print('    Completed test.')\n",
    "    return self\n",
    "\n",
    "# Apply the GPU-compatible fix\n",
    "import lr_range_test\n",
    "lr_range_test.LRRangeTest.run = gpu_fixed_lr_test_run\n",
    "print(\"Applied GPU-compatible fix to LRRangeTest.run\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Ultimate fix: Replace the entire lr_range_test.py run method\n",
    "\n",
    "def completely_fixed_lr_test_run(self, init_value=1e-8, final_value=10., beta=0.98):\n",
    "    \"\"\"Completely rewritten LR test that avoids the inplace operation issue.\"\"\"\n",
    "    print(\">>> Using COMPLETELY FIXED lr_test.run method\")\n",
    "    \n",
    "    power = (1 / (len(self.dataloader) - 1))\n",
    "    mult = (final_value / init_value) ** power\n",
    "    lr = init_value\n",
    "    self.optimizer.param_groups[0]['lr'] = lr\n",
    "    avg_loss = 0.\n",
    "    best_loss = 0.\n",
    "    batch_num = 0\n",
    "\n",
    "    print('>>> Compute loss at increasing LR values')\n",
    "    \n",
    "    # Clear losses and lrs lists\n",
    "    self.losses = []\n",
    "    self.lrs = []\n",
    "\n",
    "    for data in self.dataloader:\n",
    "        batch_num += 1\n",
    "        print('\\r' + f'    Iterate over mini-batches: {str(batch_num)}', end='')\n",
    "\n",
    "        try:\n",
    "            # COMPLETELY MANUAL APPROACH - avoid ModelCoach entirely\n",
    "            \n",
    "            # Unpack data\n",
    "            if len(data) == 3:\n",
    "                modality_data, time, event = data\n",
    "            elif len(data) == 4:\n",
    "                modality_data, time, event, pid = data\n",
    "            \n",
    "            # Move to device manually\n",
    "            for key, value in modality_data.items():\n",
    "                if isinstance(value, torch.Tensor):\n",
    "                    modality_data[key] = value.to(self.device)\n",
    "                elif isinstance(value, (list, tuple)):\n",
    "                    modality_data[key] = tuple(v.to(self.device) if isinstance(v, torch.Tensor) else v for v in value)\n",
    "            \n",
    "            time = time.to(self.device)\n",
    "            event = event.to(self.device)\n",
    "            \n",
    "            # Set model to train mode\n",
    "            self.model.train()\n",
    "            \n",
    "            # Clear gradients\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            with torch.set_grad_enabled(True):\n",
    "                feature_representations, risk = self.model(modality_data)\n",
    "                modality_features = feature_representations['modalities']\n",
    "                \n",
    "                # Compute loss manually (fix the arguments)\n",
    "                try:\n",
    "                    # The loss function signature is: forward(risk, times, events, breaks, device)\n",
    "                    # NOT forward(risk, times, events, modality_features, breaks)\n",
    "                    breaks = self.output_intervals\n",
    "                    if isinstance(breaks, (list, tuple)):\n",
    "                        breaks = torch.tensor(breaks, dtype=torch.float32, device=self.device)\n",
    "                    \n",
    "                    loss = self.criterion(risk, times=time, events=event, breaks=breaks, device=self.device)\n",
    "                        \n",
    "                except Exception as loss_error:\n",
    "                    print(f\"\\nPrimary criterion failed: {loss_error}\")\n",
    "                    # Fallback to simple MSE loss for LR range test\n",
    "                    dummy_target = torch.ones_like(risk)\n",
    "                    loss = torch.nn.functional.mse_loss(risk, dummy_target)\n",
    "                    print(\"Using fallback MSE loss\")\n",
    "                \n",
    "                # Add auxiliary loss if needed (fix the argument mismatch)\n",
    "                if self.aux_criterion is not None:\n",
    "                    try:\n",
    "                        # CosineEmbeddingLoss expects (input1, input2, target)\n",
    "                        # Let's use the two modality features\n",
    "                        if len(modality_features) >= 2:\n",
    "                            # Create a dummy target (1 for similar, -1 for dissimilar)\n",
    "                            target = torch.ones(modality_features[0].shape[0], device=self.device)\n",
    "                            aux_loss = self.aux_criterion(modality_features[0], modality_features[1], target)\n",
    "                            loss = loss + 0.1 * aux_loss  # Scale down aux loss\n",
    "                        else:\n",
    "                            print(\"Skipping aux loss - insufficient modality features\")\n",
    "                    except Exception as aux_error:\n",
    "                        print(f\"\\nAuxiliary criterion failed: {aux_error}\")\n",
    "                        print(\"Skipping auxiliary loss\")\n",
    "            \n",
    "            # Store the loss value\n",
    "            loss_value = loss.item()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError at batch {batch_num}: {e}\")\n",
    "            break\n",
    "\n",
    "        # Compute the smoothed loss\n",
    "        avg_loss = (beta * avg_loss + (1 - beta) * loss_value)\n",
    "        smoothed_loss = avg_loss / (1 - beta ** batch_num)\n",
    "\n",
    "        # Stop if the loss is exploding\n",
    "        if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
    "            print()\n",
    "            print('    Exploding loss; finish test.')\n",
    "            break\n",
    "\n",
    "        # Record the best loss\n",
    "        if smoothed_loss < best_loss or batch_num == 1:\n",
    "            best_loss = smoothed_loss\n",
    "            \n",
    "        # Store the values\n",
    "        self.losses.append(smoothed_loss)\n",
    "        self.lrs.append(lr)\n",
    "\n",
    "        # Do the backward pass and optimizer step\n",
    "        try:\n",
    "            # CRITICAL: Use retain_graph=False and no double backward pass\n",
    "            loss.backward(retain_graph=False)\n",
    "            self.optimizer.step()\n",
    "        except Exception as e:\n",
    "            print(f\"\\nBackward pass failed at batch {batch_num}: {e}\")\n",
    "            break\n",
    "\n",
    "        # Update the lr for the next step\n",
    "        lr *= mult\n",
    "        self.optimizer.param_groups[0]['lr'] = lr\n",
    "        \n",
    "        # Stop after reasonable number of batches to avoid infinite loops\n",
    "        if batch_num >= 100:\n",
    "            print(\"\\nStopping after 100 batches\")\n",
    "            break\n",
    "\n",
    "    print()\n",
    "    print('    Completed test.')\n",
    "    return self\n",
    "\n",
    "# Apply the complete fix\n",
    "import lr_range_test\n",
    "lr_range_test.LRRangeTest.run = completely_fixed_lr_test_run\n",
    "print(\"Applied COMPLETE fix to LRRangeTest.run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Using GPU-COMPATIBLE FIXED lr_test.run method\n",
      ">>> Compute loss at increasing LR values\n",
      "    Iterate over mini-batches: 27\n",
      "    Completed test.\n",
      "CPU times: user 632 ms, sys: 93.2 ms, total: 725 ms\n",
      "Wall time: 2.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)  # Disable anomaly detection too\n",
    "gpu_multisurv.test_lr_range()  # Use the new GPU instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loss values collected: 27\n",
      "Number of learning rates tested: 27\n",
      "LR range: 1.00e-06 to 1.00e+01\n",
      "Loss range: 0.056017 to 0.070558\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the results\n",
    "print(f\"Number of loss values collected: {len(gpu_multisurv.lr_test.losses)}\")\n",
    "print(f\"Number of learning rates tested: {len(gpu_multisurv.lr_test.lrs)}\")\n",
    "print(f\"LR range: {min(gpu_multisurv.lr_test.lrs):.2e} to {max(gpu_multisurv.lr_test.lrs):.2e}\")\n",
    "print(f\"Loss range: {min(gpu_multisurv.lr_test.losses):.6f} to {max(gpu_multisurv.lr_test.losses):.6f}\")\n",
    "\n",
    "# Plot the results to find optimal learning rate\n",
    "gpu_multisurv.plot_lr_range(trim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Fix for the _predictions_to_pycox method in coach.py\n",
    "\n",
    "def fixed_predictions_to_pycox(self, preds, time_points=None):\n",
    "    \"\"\"Fixed version that properly handles the DataFrame structure.\"\"\"\n",
    "    import pandas as pd\n",
    "    import torch\n",
    "    \n",
    "    # preds shape is [num_patients, num_intervals] e.g., [864, 18]\n",
    "    # Convert predictions to DataFrame\n",
    "    df = pd.DataFrame(preds.cpu().numpy())\n",
    "    \n",
    "    if time_points is None:\n",
    "        # Get the number of intervals from the model output\n",
    "        n_intervals = preds.shape[1]  # Should be 18 for your model\n",
    "        \n",
    "        # Use the model's actual output intervals\n",
    "        if hasattr(self, 'output_intervals') and self.output_intervals is not None:\n",
    "            # Use the midpoints of the output intervals\n",
    "            intervals = self.output_intervals\n",
    "            if len(intervals) > n_intervals:\n",
    "                # Take the first n_intervals midpoints\n",
    "                midpoints = (intervals[:-1] + intervals[1:]) / 2\n",
    "                time_points = midpoints[:n_intervals]\n",
    "            else:\n",
    "                # Fallback to evenly spaced points\n",
    "                time_points = torch.linspace(0.5, intervals[-1].item() / 365, n_intervals)\n",
    "        else:\n",
    "            # Fallback: create time points that match the output size\n",
    "            time_points = torch.arange(0.5, 0.5 + n_intervals, 1.0)\n",
    "    \n",
    "    # Ensure time_points matches the prediction dimensions\n",
    "    if len(time_points) != preds.shape[1]:\n",
    "        print(f\"Warning: Adjusting time_points from {len(time_points)} to {preds.shape[1]}\")\n",
    "        time_points = torch.linspace(time_points[0], time_points[-1], preds.shape[1])\n",
    "    \n",
    "    # FIXED: The DataFrame structure should be transposed\n",
    "    # We want columns to be time points, rows to be patients\n",
    "    df = df.T  # Transpose so shape becomes [num_intervals, num_patients]\n",
    "    \n",
    "    # Convert time_points to numpy if it's a tensor\n",
    "    if torch.is_tensor(time_points):\n",
    "        time_points = time_points.cpu().numpy()\n",
    "    \n",
    "    # Set the index to time points\n",
    "    df.index = time_points\n",
    "    df.index.name = 'time'\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the fix to ModelCoach\n",
    "from coach import ModelCoach\n",
    "ModelCoach._predictions_to_pycox = fixed_predictions_to_pycox\n",
    "print(\"Applied corrected fix to ModelCoach._predictions_to_pycox method\")\n",
    "\n",
    "# Debug info\n",
    "print(f\"Model output intervals shape: {len(gpu_multisurv.output_intervals)}\")\n",
    "print(f\"Model risk layer output: {gpu_multisurv.model.risk_layer[0].out_features}\")\n",
    "print(f\"Expected: {len(gpu_multisurv.output_intervals) - 1} intervals for {len(gpu_multisurv.output_intervals)} breakpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Applied GPU-compatible fix to ModelCoach._predictions_to_pycox method\n",
      "Model output intervals shape: 19\n",
      "Model output intervals device: cuda:0\n",
      "Model risk layer output: 18\n",
      "Expected: 18 intervals for 19 breakpoints\n"
     ]
    }
   ],
   "source": [
    "# GPU-compatible fix for _predictions_to_pycox method\n",
    "def gpu_fixed_predictions_to_pycox(self, preds, time_points=None):\n",
    "    \"\"\"GPU-compatible version that properly handles device transfers.\"\"\"\n",
    "    import pandas as pd\n",
    "    import torch\n",
    "    \n",
    "    # preds shape is [num_patients, num_intervals] e.g., [864, 18]\n",
    "    # Convert predictions to DataFrame (move to CPU first)\n",
    "    df = pd.DataFrame(preds.detach().cpu().numpy())  # Added .detach() for GPU tensors\n",
    "    \n",
    "    if time_points is None:\n",
    "        # Get the number of intervals from the model output\n",
    "        n_intervals = preds.shape[1]  # Should be 18 for your model\n",
    "        \n",
    "        # Use the model's actual output intervals\n",
    "        if hasattr(self, 'output_intervals') and self.output_intervals is not None:\n",
    "            # Handle GPU tensors properly\n",
    "            intervals = self.output_intervals\n",
    "            if torch.is_tensor(intervals):\n",
    "                intervals = intervals.detach().cpu()  # Move to CPU for calculations\n",
    "            \n",
    "            if len(intervals) > n_intervals:\n",
    "                # Take the first n_intervals midpoints\n",
    "                midpoints = (intervals[:-1] + intervals[1:]) / 2\n",
    "                time_points = midpoints[:n_intervals]\n",
    "            else:\n",
    "                # Fallback to evenly spaced points\n",
    "                last_interval = intervals[-1].item() if torch.is_tensor(intervals) else intervals[-1]\n",
    "                time_points = torch.linspace(0.5, last_interval / 365, n_intervals)\n",
    "        else:\n",
    "            # Fallback: create time points that match the output size\n",
    "            time_points = torch.arange(0.5, 0.5 + n_intervals, 1.0)\n",
    "    \n",
    "    # Ensure time_points matches the prediction dimensions\n",
    "    if len(time_points) != preds.shape[1]:\n",
    "        print(f\"Warning: Adjusting time_points from {len(time_points)} to {preds.shape[1]}\")\n",
    "        first_point = time_points[0].item() if torch.is_tensor(time_points) else time_points[0]\n",
    "        last_point = time_points[-1].item() if torch.is_tensor(time_points) else time_points[-1]\n",
    "        time_points = torch.linspace(first_point, last_point, preds.shape[1])\n",
    "    \n",
    "    # FIXED: The DataFrame structure should be transposed\n",
    "    # We want columns to be time points, rows to be patients\n",
    "    df = df.T  # Transpose so shape becomes [num_intervals, num_patients]\n",
    "    \n",
    "    # Convert time_points to numpy if it's a tensor (ensure CPU)\n",
    "    if torch.is_tensor(time_points):\n",
    "        time_points = time_points.detach().cpu().numpy()\n",
    "    \n",
    "    # Set the index to time points\n",
    "    df.index = time_points\n",
    "    df.index.name = 'time'\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the GPU-compatible fix to ModelCoach\n",
    "from coach import ModelCoach\n",
    "ModelCoach._predictions_to_pycox = gpu_fixed_predictions_to_pycox\n",
    "print(\"✅ Applied GPU-compatible fix to ModelCoach._predictions_to_pycox method\")\n",
    "\n",
    "# Debug info with GPU handling\n",
    "print(f\"Model output intervals shape: {len(gpu_multisurv.output_intervals)}\")\n",
    "print(f\"Model output intervals device: {gpu_multisurv.output_intervals.device}\")\n",
    "print(f\"Model risk layer output: {gpu_multisurv.model.risk_layer[0].out_features}\")\n",
    "print(f\"Expected: {len(gpu_multisurv.output_intervals) - 1} intervals for {len(gpu_multisurv.output_intervals)} breakpoints\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "import os\n",
    "import time\n",
    "import utils\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# 2. Set up training parameters\n",
    "picked_lr = 5e-3\n",
    "\n",
    "# Add timestamp to make unique run tags\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "run_tag = utils.compose_run_tag(\n",
    "    model=gpu_multisurv, \n",
    "    lr=picked_lr,\n",
    "    dataloaders=gpu_multisurv.dataloaders,\n",
    "    log_dir='./training_logs/',\n",
    "    suffix=f'_breast_cancer_{timestamp}'  # Add timestamp\n",
    ")\n",
    "\n",
    "# 3. Create log directory (now it will be unique)\n",
    "log_dir = os.path.join('./training_logs/', run_tag)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "print(f\"Log directory created: {log_dir}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "fit_args = {\n",
    "    'lr': picked_lr,\n",
    "    'num_epochs': 75,\n",
    "    'info_freq': 5,\n",
    "    'lr_factor': 0.5,\n",
    "    'scheduler_patience': 10,\n",
    "    'log_dir': log_dir,  # Use the verified directory\n",
    "}\n",
    "\n",
    "print(f\"Starting training with LR: {picked_lr}\")\n",
    "\n",
    "# 4. Train the model\n",
    "gpu_multisurv.fit(**fit_args)\n",
    "\n",
    "# 5. Calculate and display elapsed time\n",
    "hrs, mins, secs = utils.elapsed_time(start_time)\n",
    "print(f\"Training completed in {hrs}h {mins}m {secs}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PRE-TRAINING GPU VERIFICATION ===\n",
      "GPU model device: cuda:0\n",
      "GPU intervals device: cuda:0\n",
      "GPU device setting: cuda:0\n",
      "GPU memory before training: 1.70 GB\n",
      "Run tag: \"clinical_lr0.001_breast_cancer_gpu_20250619_161729\"\n",
      "✅ Log directory created: ./training_logs/clinical_lr0.001_breast_cancer_gpu_20250619_161729\n",
      "✅ Setup complete - ready for GPU training!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup with GPU verification\n",
    "import os\n",
    "import time\n",
    "import utils\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# 2. Verify GPU setup before training\n",
    "print(\"=== PRE-TRAINING GPU VERIFICATION ===\")\n",
    "print(f\"GPU model device: {next(gpu_multisurv.model.parameters()).device}\")\n",
    "print(f\"GPU intervals device: {gpu_multisurv.output_intervals.device}\")\n",
    "print(f\"GPU device setting: {gpu_multisurv.device}\")\n",
    "\n",
    "# Check GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "    print(f\"GPU memory before training: {allocated:.2f} GB\")\n",
    "\n",
    "# 3. Set up training parameters\n",
    "picked_lr = 1e-3\n",
    "\n",
    "# Add timestamp to make unique run tags\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "run_tag = utils.compose_run_tag(\n",
    "    model=gpu_multisurv, \n",
    "    lr=picked_lr,\n",
    "    dataloaders=gpu_multisurv.dataloaders,\n",
    "    log_dir='./training_logs/',\n",
    "    suffix=f'_breast_cancer_gpu_{timestamp}'  # Added 'gpu' to indicate GPU training\n",
    ")\n",
    "\n",
    "# 4. Create log directory\n",
    "log_dir = os.path.join('./training_logs/', run_tag)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "print(f\"✅ Log directory created: {log_dir}\")\n",
    "\n",
    "print(\"✅ Setup complete - ready for GPU training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting GPU training with LR: 0.001\n",
      "📊 Expected to see GPU utilization spike during training\n",
      "📁 Logs will be saved to: ./training_logs/clinical_lr0.001_breast_cancer_gpu_20250619_161729\n",
      "\n",
      "=== GPU STATUS BEFORE TRAINING ===\n",
      "🎯 GPU Memory: 1.70 GB allocated, 1.76 GB reserved\n",
      "\n",
      "⏰ Training started at: 16:17:37\n",
      "Instantiating MultiSurv model...\n",
      "\n",
      "------------------------------------------\n",
      "             Training        Validation\n",
      "           ------------     ------------\n",
      " Epoch     Loss     Ctd     Loss     Ctd\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/multisurv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/100    0.0278   0.558   0.0178   0.746\n",
      " 5/100    0.0189   0.661   0.0190   0.610\n",
      " 10/100   0.0177   0.625   0.0202   0.582\n",
      " 15/100   0.0179   0.576   0.0154   0.657\n",
      " 20/100   0.0173   0.620   0.0156   0.568\n",
      " 25/100   0.0158   0.625   0.0150   0.751\n",
      " 30/100   0.0154   0.672   0.0156   0.582\n",
      " 35/100   0.0153   0.666   0.0179   0.437\n",
      " 40/100   0.0149   0.692   0.0162   0.596\n",
      " 45/100   0.0150   0.647   0.0156   0.601\n",
      " 50/100   0.0145   0.658   0.0176   0.493\n",
      " 55/100   0.0146   0.695   0.0182   0.465\n",
      " 60/100   0.0139   0.679   0.0180   0.446\n",
      " 65/100   0.0134   0.691   0.0169   0.502\n",
      " 70/100   0.0137   0.683   0.0173   0.484\n",
      " 75/100   0.0138   0.695   0.0175   0.465\n",
      " 80/100   0.0135   0.707   0.0180   0.469\n",
      " 85/100   0.0137   0.688   0.0176   0.474\n",
      " 90/100   0.0133   0.666   0.0177   0.488\n",
      " 95/100   0.0135   0.660   0.0178   0.479\n",
      " 100/100  0.0138   0.691   0.0178   0.479\n",
      "\n",
      ">>>>> Training completed in 5m 35s\n",
      ">>>>> Best validation C-indices:\n",
      "     0.7230046948356808 (epoch16)\n",
      "     0.7793427230046949 (epoch24)\n",
      "     0.7511737089201878 (epoch25)\n",
      "\n",
      "✅ Training completed successfully!\n",
      "\n",
      "=== GPU STATUS AFTER TRAINING ===\n",
      "🎯 GPU Memory: 1.90 GB allocated, 2.05 GB reserved\n",
      "\n",
      "⏰ Training completed in 0h 5m 44s\n",
      "🏁 Training finished at: 16:23:13\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Training execution with GPU monitoring\n",
    "fit_args = {\n",
    "    'lr': picked_lr,\n",
    "    'num_epochs': 100,\n",
    "    'info_freq': 5,\n",
    "    'lr_factor': 0.5,\n",
    "    'scheduler_patience': 15,\n",
    "    'log_dir': log_dir,\n",
    "}\n",
    "\n",
    "print(f\"🚀 Starting GPU training with LR: {picked_lr}\")\n",
    "print(f\"📊 Expected to see GPU utilization spike during training\")\n",
    "print(f\"📁 Logs will be saved to: {log_dir}\")\n",
    "\n",
    "# Function to monitor GPU during training\n",
    "def check_gpu_status():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "        reserved = torch.cuda.memory_reserved(0) / 1024**3\n",
    "        print(f\"🎯 GPU Memory: {allocated:.2f} GB allocated, {reserved:.2f} GB reserved\")\n",
    "    else:\n",
    "        print(\"❌ CUDA not available\")\n",
    "\n",
    "# Check GPU before training\n",
    "print(\"\\n=== GPU STATUS BEFORE TRAINING ===\")\n",
    "check_gpu_status()\n",
    "\n",
    "# Clear any cached memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Start training\n",
    "print(f\"\\n⏰ Training started at: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "\n",
    "try:\n",
    "    # This is where the actual training happens\n",
    "    gpu_multisurv.fit(**fit_args)\n",
    "    \n",
    "    print(f\"\\n✅ Training completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Training failed with error: {e}\")\n",
    "    print(\"This might be due to GPU memory issues or device mismatches\")\n",
    "    # Print more debug info\n",
    "    print(f\"Model device: {next(gpu_multisurv.model.parameters()).device}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# Check GPU after training\n",
    "print(\"\\n=== GPU STATUS AFTER TRAINING ===\")\n",
    "check_gpu_status()\n",
    "\n",
    "# Calculate and display elapsed time\n",
    "hrs, mins, secs = utils.elapsed_time(start_time)\n",
    "print(f\"\\n⏰ Training completed in {hrs}h {mins}m {secs}s\")\n",
    "print(f\"🏁 Training finished at: {datetime.now().strftime('%H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model weights\n",
    "\n",
    "If desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch16', 'epoch24', 'epoch25'])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_multisurv.best_model_weights.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch16': 0.7230046948356808,\n",
       " 'epoch24': 0.7793427230046949,\n",
       " 'epoch25': 0.7511737089201878}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_multisurv.best_concord_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch100': 0.4788732394366197}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_multisurv.current_concord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model weights to file:\n",
      "    /mnt/data/multisurv_models/clinical_lr0.001_breast_cancer_gpu_20250619_161729_epoch24_concord0.78.pth\n"
     ]
    }
   ],
   "source": [
    "gpu_multisurv.save_weights(saved_epoch='epoch24', prefix=run_tag, weight_dir=MODELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data modalities:\n",
      "   clinical\n",
      "   mRNA\n",
      "\n",
      "Dataset sizes (# patients):\n",
      "   train: 876\n",
      "   val: 110\n",
      "   test: 108\n",
      "\n",
      "Batch size: 128\n"
     ]
    }
   ],
   "source": [
    "dataloaders = utils.get_dataloaders(data_location=DATA,\n",
    "                                    labels_file='data/labels.tsv',\n",
    "                                    modalities=data_modalities.value,\n",
    "                                    wsi_patch_size=299,\n",
    "                                    n_wsi_patches=5,\n",
    "#                                     exclude_patients=exclude_cancers,\n",
    "                                    \n",
    "                                    return_patient_id=True,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Applied fix to _BaseEvaluation._predictions_to_pycox\n",
      "✅ Applied fix to Evaluation._predictions_to_pycox\n",
      "💡 Note: There's a syntax warning in evaluation.py line 187\n",
      "   Change 'self.type is not 'MultiSurv'' to 'self.type != 'MultiSurv''\n",
      "   This doesn't affect functionality but should be fixed in the source code\n",
      "\n",
      "🔧 Evaluation fixes applied! Now try running your evaluation again.\n"
     ]
    }
   ],
   "source": [
    "# Fix for evaluation.py _predictions_to_pycox method\n",
    "\n",
    "def fixed_evaluation_predictions_to_pycox(self, data, time_points=None):\n",
    "    \"\"\"Fixed evaluation version that handles the correct dimensions.\"\"\"\n",
    "    import pandas as pd\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    \n",
    "    # Extract predictions from data\n",
    "    # data should be a list of tuples: (predictions, times, events, patient_ids)\n",
    "    predictions_list = []\n",
    "    for item in data:\n",
    "        pred = item[0]  # The prediction tensor\n",
    "        if torch.is_tensor(pred):\n",
    "            pred = pred.detach().cpu().numpy()\n",
    "        predictions_list.append(pred)\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    predictions = np.array(predictions_list)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(predictions)\n",
    "    \n",
    "    if time_points is None:\n",
    "        # Get the number of intervals from the model output\n",
    "        n_intervals = predictions.shape[1]  # Should be 18 for your model\n",
    "        \n",
    "        # Use the model's actual output intervals if available\n",
    "        if hasattr(self, 'model') and hasattr(self.model, 'output_intervals') and self.model.output_intervals is not None:\n",
    "            # Use the midpoints of the output intervals\n",
    "            intervals = self.model.output_intervals\n",
    "            if torch.is_tensor(intervals):\n",
    "                intervals = intervals.detach().cpu().numpy()\n",
    "            \n",
    "            if len(intervals) > n_intervals:\n",
    "                # Take the first n_intervals midpoints\n",
    "                midpoints = (intervals[:-1] + intervals[1:]) / 2\n",
    "                time_points = midpoints[:n_intervals]\n",
    "            else:\n",
    "                # Fallback to evenly spaced points\n",
    "                last_interval = intervals[-1] if not torch.is_tensor(intervals) else intervals[-1].item()\n",
    "                time_points = np.linspace(0.5, last_interval / 365, n_intervals)\n",
    "        else:\n",
    "            # Fallback: create time points that match the output size\n",
    "            time_points = np.arange(0.5, 0.5 + n_intervals, 1.0)\n",
    "    \n",
    "    # Ensure time_points matches the prediction dimensions\n",
    "    if len(time_points) != predictions.shape[1]:\n",
    "        print(f\"Warning: Adjusting time_points from {len(time_points)} to {predictions.shape[1]}\")\n",
    "        first_point = time_points[0] if len(time_points) > 0 else 0.5\n",
    "        last_point = time_points[-1] if len(time_points) > 0 else n_intervals + 0.5\n",
    "        time_points = np.linspace(first_point, last_point, predictions.shape[1])\n",
    "    \n",
    "    # FIXED: The DataFrame structure should be transposed\n",
    "    # We want columns to be time points, rows to be patients\n",
    "    df = df.T  # Transpose so shape becomes [num_intervals, num_patients]\n",
    "    \n",
    "    # Convert time_points to numpy if it's a tensor\n",
    "    if torch.is_tensor(time_points):\n",
    "        time_points = time_points.detach().cpu().numpy()\n",
    "    \n",
    "    # Set the index to time points\n",
    "    df.index = time_points\n",
    "    df.index.name = 'time'\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the fix to the evaluation module\n",
    "import evaluation\n",
    "\n",
    "# Check if the _BaseEvaluation class exists and patch it\n",
    "if hasattr(evaluation, '_BaseEvaluation'):\n",
    "    evaluation._BaseEvaluation._predictions_to_pycox = fixed_evaluation_predictions_to_pycox\n",
    "    print(\"✅ Applied fix to _BaseEvaluation._predictions_to_pycox\")\n",
    "else:\n",
    "    print(\"❌ _BaseEvaluation class not found\")\n",
    "\n",
    "# Also check for Evaluation class\n",
    "if hasattr(evaluation, 'Evaluation'):\n",
    "    evaluation.Evaluation._predictions_to_pycox = fixed_evaluation_predictions_to_pycox\n",
    "    print(\"✅ Applied fix to Evaluation._predictions_to_pycox\")\n",
    "\n",
    "# Fix the syntax warning too\n",
    "def patch_syntax_warning():\n",
    "    \"\"\"Fix the syntax warning in evaluation.py if possible.\"\"\"\n",
    "    print(\"💡 Note: There's a syntax warning in evaluation.py line 187\")\n",
    "    print(\"   Change 'self.type is not 'MultiSurv'' to 'self.type != 'MultiSurv''\")\n",
    "    print(\"   This doesn't affect functionality but should be fixed in the source code\")\n",
    "\n",
    "patch_syntax_warning()\n",
    "\n",
    "print(\"\\n🔧 Evaluation fixes applied! Now try running your evaluation again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collect patient predictions: 110/110\n",
      "\n",
      "C-index   0.809\n",
      "Ctd       0.842\n",
      "IBS       0.107\n",
      "INBLL     0.348\n"
     ]
    }
   ],
   "source": [
    "performance = utils.Evaluation(\n",
    "    model=gpu_multisurv, dataset=dataloaders['val'].dataset,\n",
    "    device=device)\n",
    "performance.compute_metrics()\n",
    "performance.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collect patient predictions: 108/108\n",
      "\n",
      "TEST SET RESULTS:\n",
      "C-index   0.538\n",
      "Ctd       0.485\n",
      "IBS       0.173\n",
      "INBLL     0.525\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on TEST set (not validation)\n",
    "performance = utils.Evaluation(\n",
    "    model=gpu_multisurv, \n",
    "    dataset=dataloaders['test'].dataset,  # Note: 'test' not 'val'\n",
    "    device=device\n",
    ")\n",
    "performance.compute_metrics()\n",
    "print(\"TEST SET RESULTS:\")\n",
    "performance.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watermark <a class='tocSkip'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark --iversions\n",
    "%watermark -v\n",
    "print()\n",
    "%watermark -u -n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of the page](#Top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "197px",
    "width": "372px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "236px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
