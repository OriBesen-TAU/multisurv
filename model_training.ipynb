{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Top'></a>\n",
    "\n",
    "# Multisurv model training<a class='tocSkip'></a>\n",
    "\n",
    "Train MultiSurv models with different combinations of input data modalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /opt/conda/envs/multisurv/lib/python3.8/site-packages (2.17.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (1.62.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (3.6)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (1.24.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (25.0)\n",
      "Requirement already satisfied: protobuf in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (4.25.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (75.3.0)\n",
      "Requirement already satisfied: six>1.9 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from tensorboard) (3.0.6)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard) (8.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/conda/envs/multisurv/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.21.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> PyTorch detected CUDA <<<\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%load_ext watermark\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('>>> PyTorch detected CUDA <<<')\n",
    "\n",
    "# Make modules in \"src\" dir visible\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.append(os.path.join(os.getcwd(), 'src'))\n",
    "\n",
    "import utils\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#DataLoader\" data-toc-modified-id=\"DataLoader-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span><code>DataLoader</code></a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Different-intervals\" data-toc-modified-id=\"Different-intervals-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Different intervals</a></span><ul class=\"toc-item\"><li><span><a href=\"#Equidistant-times\" data-toc-modified-id=\"Equidistant-times-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Equidistant times</a></span></li><li><span><a href=\"#By-duration-quantiles\" data-toc-modified-id=\"By-duration-quantiles-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>By duration quantiles</a></span></li></ul></li><li><span><a href=\"#Pick-learning-rate\" data-toc-modified-id=\"Pick-learning-rate-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Pick learning rate</a></span></li><li><span><a href=\"#Fit\" data-toc-modified-id=\"Fit-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Fit</a></span><ul class=\"toc-item\"><li><span><a href=\"#Save-model-weights\" data-toc-modified-id=\"Save-model-weights-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Save model weights</a></span></li></ul></li><li><span><a href=\"#Check-validation-metrics\" data-toc-modified-id=\"Check-validation-metrics-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Check validation metrics</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 PyTorch is using: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "✅ NVIDIA GPU detected - good for training!\n",
      "\n",
      "==================================================\n",
      "=== GPU DETECTION REPORT ===\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "PyTorch version: 2.4.0\n",
      "Number of CUDA devices: 1\n",
      "\n",
      "=== AVAILABLE GPUS ===\n",
      "GPU 0: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "  Memory: 8.0 GB\n",
      "  Compute Capability: 8.9\n",
      "  Multi Processors: 24\n",
      "\n",
      "=== CURRENT SELECTION ===\n",
      "Current CUDA device: 0\n",
      "Current GPU name: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "\n",
      "=== MEMORY USAGE ===\n",
      "GPU 0 (NVIDIA GeForce RTX 4060 Laptop GPU):\n",
      "  Allocated: 0.00 GB\n",
      "  Reserved: 0.00 GB\n",
      "  Total: 8.0 GB\n",
      "\n",
      "=== GPU FUNCTIONALITY TEST ===\n",
      "✅ GPU computation successful\n",
      "Test tensor device: cuda:0\n",
      "Result tensor device: cuda:0\n",
      "\n",
      "=== NVIDIA SYSTEM INFO ===\n",
      "NVIDIA-SMI Output:\n",
      "Fri Jun 20 16:14:13 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 575.64.01              Driver Version: 576.80         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 ...    On  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   41C    P0              5W /  124W |     123MiB /   8188MiB |      8%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A           30131      C   /python3.8                            N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n",
      "✅ Using single GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "\n",
      "=== PYTORCH GPU VERIFICATION ===\n",
      "✅ PyTorch using: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "✅ Confirmed: Using NVIDIA GPU\n",
      "\n",
      "=== RECOMMENDATION ===\n",
      "✅ Ready for GPU training with device: cuda:0\n",
      "Use: multisurv.device = cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import subprocess\n",
    "\n",
    "def check_gpu_setup():\n",
    "    \"\"\"Complete GPU detection and verification.\"\"\"\n",
    "    \n",
    "    print(\"=== GPU DETECTION REPORT ===\")\n",
    "    \n",
    "    # 1. Check CUDA availability\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    \n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"❌ CUDA not available - will use CPU\")\n",
    "        return\n",
    "    \n",
    "    # 2. Check number of GPUs\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"Number of CUDA devices: {gpu_count}\")\n",
    "    \n",
    "    # 3. List all available GPUs\n",
    "    print(\"\\n=== AVAILABLE GPUS ===\")\n",
    "    for i in range(gpu_count):\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        print(f\"GPU {i}: {props.name}\")\n",
    "        print(f\"  Memory: {props.total_memory / 1024**3:.1f} GB\")\n",
    "        print(f\"  Compute Capability: {props.major}.{props.minor}\")\n",
    "        print(f\"  Multi Processors: {props.multi_processor_count}\")\n",
    "    \n",
    "    # 4. Check current device\n",
    "    current_device = torch.cuda.current_device()\n",
    "    current_name = torch.cuda.get_device_name(current_device)\n",
    "    print(f\"\\n=== CURRENT SELECTION ===\")\n",
    "    print(f\"Current CUDA device: {current_device}\")\n",
    "    print(f\"Current GPU name: {current_name}\")\n",
    "    \n",
    "    # 5. Memory usage\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"\\n=== MEMORY USAGE ===\")\n",
    "        for i in range(gpu_count):\n",
    "            allocated = torch.cuda.memory_allocated(i) / 1024**3\n",
    "            reserved = torch.cuda.memory_reserved(i) / 1024**3\n",
    "            total = torch.cuda.get_device_properties(i).total_memory / 1024**3\n",
    "            print(f\"GPU {i} ({torch.cuda.get_device_name(i)}):\")\n",
    "            print(f\"  Allocated: {allocated:.2f} GB\")\n",
    "            print(f\"  Reserved: {reserved:.2f} GB\")\n",
    "            print(f\"  Total: {total:.1f} GB\")\n",
    "    \n",
    "    # 6. Test tensor creation on GPU\n",
    "    print(f\"\\n=== GPU FUNCTIONALITY TEST ===\")\n",
    "    try:\n",
    "        # Create test tensor on GPU\n",
    "        test_tensor = torch.randn(1000, 1000).cuda()\n",
    "        result = torch.mm(test_tensor, test_tensor)\n",
    "        print(f\"✅ GPU computation successful\")\n",
    "        print(f\"Test tensor device: {test_tensor.device}\")\n",
    "        print(f\"Result tensor device: {result.device}\")\n",
    "        \n",
    "        # Cleanup\n",
    "        del test_tensor, result\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ GPU computation failed: {e}\")\n",
    "\n",
    "def check_nvidia_system():\n",
    "    \"\"\"Check NVIDIA system information.\"\"\"\n",
    "    print(\"\\n=== NVIDIA SYSTEM INFO ===\")\n",
    "    \n",
    "    try:\n",
    "        # Run nvidia-smi command\n",
    "        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(\"NVIDIA-SMI Output:\")\n",
    "            print(result.stdout)\n",
    "        else:\n",
    "            print(\"❌ nvidia-smi command failed\")\n",
    "            print(result.stderr)\n",
    "    except FileNotFoundError:\n",
    "        print(\"❌ nvidia-smi not found - NVIDIA drivers may not be installed\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error running nvidia-smi: {e}\")\n",
    "\n",
    "def set_gpu_preference():\n",
    "    \"\"\"Set GPU preference if multiple GPUs available.\"\"\"\n",
    "    \n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"No CUDA GPUs available\")\n",
    "        return None\n",
    "    \n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    \n",
    "    if gpu_count == 1:\n",
    "        device = torch.device('cuda:0')\n",
    "        print(f\"✅ Using single GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        return device\n",
    "    \n",
    "    print(f\"\\n=== MULTIPLE GPUS DETECTED ({gpu_count}) ===\")\n",
    "    \n",
    "    # Show GPU options\n",
    "    for i in range(gpu_count):\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        print(f\"GPU {i}: {props.name} ({props.total_memory / 1024**3:.1f} GB)\")\n",
    "    \n",
    "    # Find the most powerful GPU (by memory)\n",
    "    best_gpu = 0\n",
    "    best_memory = 0\n",
    "    \n",
    "    for i in range(gpu_count):\n",
    "        memory = torch.cuda.get_device_properties(i).total_memory\n",
    "        if memory > best_memory:\n",
    "            best_memory = memory\n",
    "            best_gpu = i\n",
    "    \n",
    "    device = torch.device(f'cuda:{best_gpu}')\n",
    "    print(f\"✅ Auto-selected most powerful GPU: {torch.cuda.get_device_name(best_gpu)}\")\n",
    "    \n",
    "    # Set as current device\n",
    "    torch.cuda.set_device(best_gpu)\n",
    "    \n",
    "    return device\n",
    "\n",
    "def verify_pytorch_gpu_usage():\n",
    "    \"\"\"Verify PyTorch is actually using the NVIDIA GPU (not Intel).\"\"\"\n",
    "    \n",
    "    print(\"\\n=== PYTORCH GPU VERIFICATION ===\")\n",
    "    \n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"❌ PyTorch not using GPU - will use CPU\")\n",
    "        return False\n",
    "    \n",
    "    # Create tensor and check device\n",
    "    x = torch.randn(100, 100).cuda()\n",
    "    gpu_name = torch.cuda.get_device_name(x.device)\n",
    "    \n",
    "    print(f\"✅ PyTorch using: {gpu_name}\")\n",
    "    \n",
    "    # Check if it's NVIDIA (not Intel)\n",
    "    if 'nvidia' in gpu_name.lower() or 'geforce' in gpu_name.lower() or 'rtx' in gpu_name.lower() or 'gtx' in gpu_name.lower():\n",
    "        print(f\"✅ Confirmed: Using NVIDIA GPU\")\n",
    "        return True\n",
    "    elif 'intel' in gpu_name.lower():\n",
    "        print(f\"⚠️  Warning: Using Intel GPU - this may be slow for deep learning\")\n",
    "        return False\n",
    "    else:\n",
    "        print(f\"❓ Unknown GPU type: {gpu_name}\")\n",
    "        return True\n",
    "\n",
    "# Run all checks\n",
    "def complete_gpu_check():\n",
    "    \"\"\"Run complete GPU diagnostic.\"\"\"\n",
    "    check_gpu_setup()\n",
    "    check_nvidia_system()\n",
    "    device = set_gpu_preference()\n",
    "    is_nvidia = verify_pytorch_gpu_usage()\n",
    "    \n",
    "    print(f\"\\n=== RECOMMENDATION ===\")\n",
    "    if is_nvidia and device:\n",
    "        print(f\"✅ Ready for GPU training with device: {device}\")\n",
    "        print(f\"Use: multisurv.device = {device}\")\n",
    "    else:\n",
    "        print(\"⚠️  Consider using CPU training: multisurv.device = torch.device('cpu')\")\n",
    "    \n",
    "    return device\n",
    "\n",
    "# Quick check function\n",
    "def quick_gpu_check():\n",
    "    \"\"\"Quick GPU check for immediate feedback.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        print(f\"🎯 PyTorch is using: {gpu_name}\")\n",
    "        \n",
    "        if any(keyword in gpu_name.lower() for keyword in ['nvidia', 'geforce', 'rtx', 'gtx']):\n",
    "            print(\"✅ NVIDIA GPU detected - good for training!\")\n",
    "        else:\n",
    "            print(\"⚠️  Non-NVIDIA GPU detected\")\n",
    "    else:\n",
    "        print(\"❌ No GPU available - will use CPU\")\n",
    "\n",
    "# Run the checks\n",
    "quick_gpu_check()\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "complete_gpu_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = utils.INPUT_DATA_DIR\n",
    "MODELS = utils.TRAINED_MODEL_DIR\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b618d344aa24763892904a5fde48682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Input data', index=(0, 1), options=('clinical', 'mRNA', 'DNAm', 'miRNA', 'CNV', 'w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_modalities = widgets.SelectMultiple(\n",
    "    options=['clinical', 'mRNA', 'DNAm', 'miRNA', 'CNV', 'wsi'],\n",
    "    index=[0, 1],\n",
    "    rows=6,\n",
    "    description='Input data',\n",
    "    disabled=False\n",
    ")\n",
    "display(data_modalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   submitter_id      time  event  group\n",
      "0  TCGA-Z7-A8R6  8.920548      0   test\n",
      "1  TCGA-C8-A1HE  1.027397      0   test\n",
      "2  TCGA-A8-A07B  3.583562      0  train\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------------------------------#\n",
    "#                             20-CANCER SUBSET                                #\n",
    "#                 (to compare to Cheerla and Gevaert 2019)                    #\n",
    "#-----------------------------------------------------------------------------#\n",
    "\n",
    "cancers = ['BRCA']\n",
    "\n",
    "labels = pd.read_csv('/app/data/labels.tsv', sep='\\t')\n",
    "print(labels.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data modalities:\n",
      "   clinical\n",
      "\n",
      "Dataset sizes (# patients):\n",
      "   train: 710\n",
      "   val: 165\n",
      "   test: 219\n",
      "\n",
      "Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "dataloaders = utils.get_dataloaders(data_location=DATA,\n",
    "                                    labels_file='/app/data/labels.tsv',\n",
    "                                    modalities=data_modalities.value,\n",
    "                                    wsi_patch_size=299,\n",
    "                                    n_wsi_patches=5,\n",
    "#                                     batch_size=20,\n",
    "#                                    batch_size=64,\n",
    "                                     batch_size=32,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train event rate: 13.80%\n",
      "Val event rate: 13.94%\n",
      "Test event rate: 13.70%\n"
     ]
    }
   ],
   "source": [
    "# Compare event rates across splits\n",
    "def get_event_rate(dataset):\n",
    "    events = [e for _, e in dataset.label_map.values()]\n",
    "    return sum(events) / len(events)\n",
    "\n",
    "print(f\"Train event rate: {get_event_rate(dataloaders['train'].dataset):.2%}\")\n",
    "print(f\"Val event rate: {get_event_rate(dataloaders['val'].dataset):.2%}\")\n",
    "print(f\"Test event rate: {get_event_rate(dataloaders['test'].dataset):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN set (n=710):\n",
      "Clinical features shape: ({'clinical': (tensor([0., 5., 0., 0., 0., 0., 0.]), tensor([0.4466]))}, 0.0273972602739726, 0)\n",
      "\n",
      "VAL set (n=165):\n",
      "Clinical features shape: ({'clinical': (tensor([0., 2., 0., 0., 0., 0., 2.]), tensor([0.8071]))}, 10.846575342465751, 1)\n",
      "\n",
      "TEST set (n=219):\n",
      "Clinical features shape: ({'clinical': (tensor([0., 5., 0., 0., 0., 0., 2.]), tensor([0.5743]))}, 1.084931506849315, 0)\n"
     ]
    }
   ],
   "source": [
    "# Check if clinical features are similar across splits\n",
    "# Look for any systematic differences\n",
    "for split in ['train', 'val', 'test']:\n",
    "    data = dataloaders[split].dataset\n",
    "    print(f\"\\n{split.upper()} set (n={len(data)}):\")\n",
    "    # Get first patient's clinical data to see structure\n",
    "    if len(data) > 0:\n",
    "        clinical = data[0]\n",
    "        print(f\"Clinical features shape: {clinical}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train range: [0.000, 1.000]\n",
      "Val range: [0.007, 1.000]\n",
      "Test range: [0.037, 0.988]\n"
     ]
    }
   ],
   "source": [
    "# 1. First, check the continuous feature distribution\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract continuous feature values for all patients\n",
    "def get_continuous_feature(dataset):\n",
    "    values = []\n",
    "    for i in range(len(dataset)):\n",
    "        clinical_data = dataset[i][0]  # Get the data part\n",
    "        continuous_val = clinical_data['clinical'][1].item()  # The continuous feature\n",
    "        values.append(continuous_val)\n",
    "    return np.array(values)\n",
    "\n",
    "train_cont = get_continuous_feature(dataloaders['train'].dataset)\n",
    "val_cont = get_continuous_feature(dataloaders['val'].dataset)\n",
    "test_cont = get_continuous_feature(dataloaders['test'].dataset)\n",
    "\n",
    "# Plot distributions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(train_cont, alpha=0.5, label=f'Train (mean={train_cont.mean():.3f})', bins=30)\n",
    "plt.hist(val_cont, alpha=0.5, label=f'Val (mean={val_cont.mean():.3f})', bins=30)\n",
    "plt.hist(test_cont, alpha=0.5, label=f'Test (mean={test_cont.mean():.3f})', bins=30)\n",
    "plt.legend()\n",
    "plt.title('Distribution of Continuous Clinical Feature')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Train range: [{train_cont.min():.3f}, {train_cont.max():.3f}]\")\n",
    "print(f\"Val range: [{val_cont.min():.3f}, {val_cont.max():.3f}]\")\n",
    "print(f\"Test range: [{test_cont.min():.3f}, {test_cont.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different intervals\n",
    "\n",
    "If trying out different time interval outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equidistant times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_cuts = torch.arange(0., 365 * 5.1, 365 / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By duration quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [(t, e) for t, e in dataloaders['train'].dataset.label_map.values()]\n",
    "durations = [t for t, _ in labels]\n",
    "events = [e for _, e in labels]\n",
    "\n",
    "interval_cuts = utils.discretize_time_by_duration_quantiles(durations, events, 20)\n",
    "interval_cuts = torch.from_numpy(interval_cuts)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#-----------------------------------------------------------------------------#\n",
    "#                       PRE-TRAINED UNIMODAL MODELS                           #\n",
    "#-----------------------------------------------------------------------------#\n",
    "\n",
    "unimodal_weigths = {'clinical': 'clinical_lr0.005_epoch49_acc0.78.pth',\n",
    "                    'mRNA': 'mRNA_lr0.005_epoch54_acc0.76.pth',\n",
    "                    'DNAm': 'DNAm_lr0.005_epoch57_acc0.77.pth',\n",
    "                    'miRNA': None,\n",
    "                    'CNV': None,\n",
    "                    'wsi': None,}\n",
    "\n",
    "unimodal_weigths = {k: os.path.join(MODELS, v) if v is not None else None\n",
    "                    for k, v in unimodal_weigths.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiating MultiSurv model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/src/multisurv.py:84: UserWarning: Input data is unimodal: no fusion procedure.\n",
      "  warnings.warn('Input data is unimodal: no fusion procedure.')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "multisurv = Model(\n",
    "    dataloaders=dataloaders,\n",
    "    auxiliary_criterion=None,  # No auxiliary loss needed\n",
    "    output_intervals=interval_cuts,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gpu_enabled_multisurv():\n",
    "    \"\"\"Create a fresh MultiSurv instance with proper GPU setup.\"\"\"\n",
    "    \n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Creating MultiSurv with device: {device}\")\n",
    "    \n",
    "    \n",
    "    # Create new model with GPU device\n",
    "    gpu_multisurv = Model(\n",
    "        dataloaders=multisurv.dataloaders,  # Reuse existing dataloaders\n",
    "        fusion_method=multisurv.fusion_method,\n",
    "        output_intervals=multisurv.output_intervals.to(device),  # Move to GPU\n",
    "        device=device  # Set device properly\n",
    "    )\n",
    "    \n",
    "    print(\"✅ GPU-enabled MultiSurv created!\")\n",
    "    return gpu_multisurv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MultiSurv with device: cuda:0\n",
      "Instantiating MultiSurv model...\n",
      "✅ GPU-enabled MultiSurv created!\n"
     ]
    }
   ],
   "source": [
    "gpu_multisurv = create_gpu_enabled_multisurv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output intervals (in years):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  1.6767,  2.7123,  3.7342,  4.6247,  6.2712,  6.8849,  7.5808,\n",
       "         8.0000,  8.9342, 10.0274, 10.6110, 10.7973, 11.7397, 17.2384, 17.6877,\n",
       "        19.5233, 23.5753], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Output intervals (in years):')\n",
    "gpu_multisurv.output_intervals / 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clinical_submodel', 'fc_block', 'risk_layer']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_multisurv.model_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable blocks:\n",
      "   clinical_submodel: True\n",
      "   fc_block: True\n",
      "   risk_layer: True\n"
     ]
    }
   ],
   "source": [
    "print('Trainable blocks:')\n",
    "layer = None\n",
    "\n",
    "for name, child in gpu_multisurv.model.named_children():\n",
    "    for name_2, params in child.named_parameters():\n",
    "        if name is not layer:\n",
    "            print(f'   {name}: {params.requires_grad}')\n",
    "        layer = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiSurv(\n",
       "  (clinical_submodel): ClinicalNet(\n",
       "    (embedding_layers): ModuleList(\n",
       "      (0): Embedding(2, 1)\n",
       "      (1): Embedding(7, 4)\n",
       "      (2-4): 3 x Embedding(3, 2)\n",
       "      (5-6): 2 x Embedding(4, 2)\n",
       "    )\n",
       "    (embedding_dropout): Dropout(p=0.5, inplace=False)\n",
       "    (bn_layer): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear): Linear(in_features=16, out_features=256, bias=True)\n",
       "    (output_layer): FC(\n",
       "      (fc): Sequential(\n",
       "        (0): Dropout(p=0.5, inplace=False)\n",
       "        (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_block): FC(\n",
       "    (fc): Sequential(\n",
       "      (0): Dropout(p=0.5, inplace=False)\n",
       "      (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): Dropout(p=0.5, inplace=False)\n",
       "      (5): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (6): ReLU()\n",
       "      (7): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): Dropout(p=0.5, inplace=False)\n",
       "      (9): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (10): ReLU()\n",
       "      (11): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (12): Dropout(p=0.5, inplace=False)\n",
       "      (13): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (14): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (risk_layer): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=17, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_multisurv.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 GPU Memory: 0.09 GB allocated, 0.11 GB reserved\n",
      "🔍 GPU cache size: 0.11 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30131/1937229576.py:9: FutureWarning: `torch.cuda.memory_cached` has been renamed to `torch.cuda.memory_reserved`\n",
      "  print(f\"🔍 GPU cache size: {torch.cuda.memory_cached(0) / 1024**3:.2f} GB\")\n"
     ]
    }
   ],
   "source": [
    "# Check GPU usage after LR test\n",
    "def monitor_gpu_real_time():\n",
    "    import torch\n",
    "    allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "    reserved = torch.cuda.memory_reserved(0) / 1024**3\n",
    "    print(f\"🎯 GPU Memory: {allocated:.2f} GB allocated, {reserved:.2f} GB reserved\")\n",
    "    \n",
    "    # Check if there are any tensors on GPU\n",
    "    print(f\"🔍 GPU cache size: {torch.cuda.memory_cached(0) / 1024**3:.2f} GB\")\n",
    "monitor_gpu_real_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features:\n",
      " tensor([0., 5., 0., 0., 0., 0., 0.])\n",
      "Continuous features:\n",
      " tensor([0.4466])\n"
     ]
    }
   ],
   "source": [
    "data_example, _, _ = dataloaders['train'].dataset[0]\n",
    "print(\"Categorical features:\\n\", data_example['clinical'][0])\n",
    "print(\"Continuous features:\\n\", data_example['clinical'][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied GPU-compatible fix to LRRangeTest.run\n"
     ]
    }
   ],
   "source": [
    "# GPU-compatible version of the completely fixed LR test\n",
    "\n",
    "def gpu_fixed_lr_test_run(self, init_value=1e-8, final_value=10., beta=0.98):\n",
    "    \"\"\"GPU-compatible LR test that ensures all tensors are on the same device.\"\"\"\n",
    "    print(\">>> Using GPU-COMPATIBLE FIXED lr_test.run method\")\n",
    "    \n",
    "    power = (1 / (len(self.dataloader) - 1))\n",
    "    mult = (final_value / init_value) ** power\n",
    "    lr = init_value\n",
    "    self.optimizer.param_groups[0]['lr'] = lr\n",
    "    avg_loss = 0.\n",
    "    best_loss = 0.\n",
    "    batch_num = 0\n",
    "\n",
    "    print('>>> Compute loss at increasing LR values')\n",
    "    \n",
    "    # Clear losses and lrs lists\n",
    "    self.losses = []\n",
    "    self.lrs = []\n",
    "\n",
    "    for data in self.dataloader:\n",
    "        batch_num += 1\n",
    "        print('\\r' + f'    Iterate over mini-batches: {str(batch_num)}', end='')\n",
    "\n",
    "        try:\n",
    "            # Unpack data\n",
    "            if len(data) == 3:\n",
    "                modality_data, time, event = data\n",
    "            elif len(data) == 4:\n",
    "                modality_data, time, event, pid = data\n",
    "            \n",
    "            # CRITICAL: Move ALL data to the same device as the model\n",
    "            target_device = next(self.model.parameters()).device\n",
    "            \n",
    "            # Move modality data to device\n",
    "            for key, value in modality_data.items():\n",
    "                if isinstance(value, torch.Tensor):\n",
    "                    modality_data[key] = value.to(target_device)\n",
    "                elif isinstance(value, (list, tuple)):\n",
    "                    modality_data[key] = tuple(v.to(target_device) if isinstance(v, torch.Tensor) else v for v in value)\n",
    "            \n",
    "            # Move time and event to device\n",
    "            time = time.to(target_device)\n",
    "            event = event.to(target_device)\n",
    "            \n",
    "            # Set model to train mode\n",
    "            self.model.train()\n",
    "            \n",
    "            # Clear gradients\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            with torch.set_grad_enabled(True):\n",
    "                feature_representations, risk = self.model(modality_data)\n",
    "                modality_features = feature_representations['modalities']\n",
    "                \n",
    "                # Compute loss with proper device handling\n",
    "                try:\n",
    "                    # Ensure output_intervals are on the same device\n",
    "                    if hasattr(self, 'output_intervals'):\n",
    "                        breaks = self.output_intervals.to(target_device)\n",
    "                    else:\n",
    "                        breaks = torch.linspace(0, 10, 19, device=target_device)  # Fallback\n",
    "                    \n",
    "                    loss = self.criterion(risk, times=time, events=event, breaks=breaks, device=target_device)\n",
    "                    \n",
    "                except Exception as loss_error:\n",
    "                    print(f\"\\nPrimary criterion failed: {loss_error}\")\n",
    "                    # Fallback to simple MSE loss on the same device\n",
    "                    dummy_target = torch.ones_like(risk)  # This will be on the same device as risk\n",
    "                    loss = torch.nn.functional.mse_loss(risk, dummy_target)\n",
    "                    print(\"Using fallback MSE loss\")\n",
    "                \n",
    "                # Add auxiliary loss if needed\n",
    "                if self.aux_criterion is not None:\n",
    "                    try:\n",
    "                        if len(modality_features) >= 2:\n",
    "                            target = torch.ones(modality_features[0].shape[0], device=target_device)\n",
    "                            aux_loss = self.aux_criterion(modality_features[0], modality_features[1], target)\n",
    "                            loss = loss + 0.1 * aux_loss\n",
    "                    except Exception as aux_error:\n",
    "                        print(f\"\\nAuxiliary criterion failed: {aux_error}\")\n",
    "            \n",
    "            # Store the loss value\n",
    "            loss_value = loss.item()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError at batch {batch_num}: {e}\")\n",
    "            break\n",
    "\n",
    "        # Compute the smoothed loss\n",
    "        avg_loss = (beta * avg_loss + (1 - beta) * loss_value)\n",
    "        smoothed_loss = avg_loss / (1 - beta ** batch_num)\n",
    "\n",
    "        # Stop if the loss is exploding\n",
    "        if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
    "            print()\n",
    "            print('    Exploding loss; finish test.')\n",
    "            break\n",
    "\n",
    "        # Record the best loss\n",
    "        if smoothed_loss < best_loss or batch_num == 1:\n",
    "            best_loss = smoothed_loss\n",
    "            \n",
    "        # Store the values\n",
    "        self.losses.append(smoothed_loss)\n",
    "        self.lrs.append(lr)\n",
    "\n",
    "        # Do the backward pass and optimizer step\n",
    "        try:\n",
    "            loss.backward(retain_graph=False)\n",
    "            self.optimizer.step()\n",
    "        except Exception as e:\n",
    "            print(f\"\\nBackward pass failed at batch {batch_num}: {e}\")\n",
    "            break\n",
    "\n",
    "        # Update the lr for the next step\n",
    "        lr *= mult\n",
    "        self.optimizer.param_groups[0]['lr'] = lr\n",
    "        \n",
    "        # Stop after reasonable number of batches\n",
    "        if batch_num >= 100:\n",
    "            print(\"\\nStopping after 100 batches\")\n",
    "            break\n",
    "\n",
    "    print()\n",
    "    print('    Completed test.')\n",
    "    return self\n",
    "\n",
    "# Apply the GPU-compatible fix\n",
    "import lr_range_test\n",
    "lr_range_test.LRRangeTest.run = gpu_fixed_lr_test_run\n",
    "print(\"Applied GPU-compatible fix to LRRangeTest.run\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Ultimate fix: Replace the entire lr_range_test.py run method\n",
    "\n",
    "def completely_fixed_lr_test_run(self, init_value=1e-8, final_value=10., beta=0.98):\n",
    "    \"\"\"Completely rewritten LR test that avoids the inplace operation issue.\"\"\"\n",
    "    print(\">>> Using COMPLETELY FIXED lr_test.run method\")\n",
    "    \n",
    "    power = (1 / (len(self.dataloader) - 1))\n",
    "    mult = (final_value / init_value) ** power\n",
    "    lr = init_value\n",
    "    self.optimizer.param_groups[0]['lr'] = lr\n",
    "    avg_loss = 0.\n",
    "    best_loss = 0.\n",
    "    batch_num = 0\n",
    "\n",
    "    print('>>> Compute loss at increasing LR values')\n",
    "    \n",
    "    # Clear losses and lrs lists\n",
    "    self.losses = []\n",
    "    self.lrs = []\n",
    "\n",
    "    for data in self.dataloader:\n",
    "        batch_num += 1\n",
    "        print('\\r' + f'    Iterate over mini-batches: {str(batch_num)}', end='')\n",
    "\n",
    "        try:\n",
    "            # COMPLETELY MANUAL APPROACH - avoid ModelCoach entirely\n",
    "            \n",
    "            # Unpack data\n",
    "            if len(data) == 3:\n",
    "                modality_data, time, event = data\n",
    "            elif len(data) == 4:\n",
    "                modality_data, time, event, pid = data\n",
    "            \n",
    "            # Move to device manually\n",
    "            for key, value in modality_data.items():\n",
    "                if isinstance(value, torch.Tensor):\n",
    "                    modality_data[key] = value.to(self.device)\n",
    "                elif isinstance(value, (list, tuple)):\n",
    "                    modality_data[key] = tuple(v.to(self.device) if isinstance(v, torch.Tensor) else v for v in value)\n",
    "            \n",
    "            time = time.to(self.device)\n",
    "            event = event.to(self.device)\n",
    "            \n",
    "            # Set model to train mode\n",
    "            self.model.train()\n",
    "            \n",
    "            # Clear gradients\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            with torch.set_grad_enabled(True):\n",
    "                feature_representations, risk = self.model(modality_data)\n",
    "                modality_features = feature_representations['modalities']\n",
    "                \n",
    "                # Compute loss manually (fix the arguments)\n",
    "                try:\n",
    "                    # The loss function signature is: forward(risk, times, events, breaks, device)\n",
    "                    # NOT forward(risk, times, events, modality_features, breaks)\n",
    "                    breaks = self.output_intervals\n",
    "                    if isinstance(breaks, (list, tuple)):\n",
    "                        breaks = torch.tensor(breaks, dtype=torch.float32, device=self.device)\n",
    "                    \n",
    "                    loss = self.criterion(risk, times=time, events=event, breaks=breaks, device=self.device)\n",
    "                        \n",
    "                except Exception as loss_error:\n",
    "                    print(f\"\\nPrimary criterion failed: {loss_error}\")\n",
    "                    # Fallback to simple MSE loss for LR range test\n",
    "                    dummy_target = torch.ones_like(risk)\n",
    "                    loss = torch.nn.functional.mse_loss(risk, dummy_target)\n",
    "                    print(\"Using fallback MSE loss\")\n",
    "                \n",
    "                # Add auxiliary loss if needed (fix the argument mismatch)\n",
    "                if self.aux_criterion is not None:\n",
    "                    try:\n",
    "                        # CosineEmbeddingLoss expects (input1, input2, target)\n",
    "                        # Let's use the two modality features\n",
    "                        if len(modality_features) >= 2:\n",
    "                            # Create a dummy target (1 for similar, -1 for dissimilar)\n",
    "                            target = torch.ones(modality_features[0].shape[0], device=self.device)\n",
    "                            aux_loss = self.aux_criterion(modality_features[0], modality_features[1], target)\n",
    "                            loss = loss + 0.1 * aux_loss  # Scale down aux loss\n",
    "                        else:\n",
    "                            print(\"Skipping aux loss - insufficient modality features\")\n",
    "                    except Exception as aux_error:\n",
    "                        print(f\"\\nAuxiliary criterion failed: {aux_error}\")\n",
    "                        print(\"Skipping auxiliary loss\")\n",
    "            \n",
    "            # Store the loss value\n",
    "            loss_value = loss.item()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError at batch {batch_num}: {e}\")\n",
    "            break\n",
    "\n",
    "        # Compute the smoothed loss\n",
    "        avg_loss = (beta * avg_loss + (1 - beta) * loss_value)\n",
    "        smoothed_loss = avg_loss / (1 - beta ** batch_num)\n",
    "\n",
    "        # Stop if the loss is exploding\n",
    "        if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
    "            print()\n",
    "            print('    Exploding loss; finish test.')\n",
    "            break\n",
    "\n",
    "        # Record the best loss\n",
    "        if smoothed_loss < best_loss or batch_num == 1:\n",
    "            best_loss = smoothed_loss\n",
    "            \n",
    "        # Store the values\n",
    "        self.losses.append(smoothed_loss)\n",
    "        self.lrs.append(lr)\n",
    "\n",
    "        # Do the backward pass and optimizer step\n",
    "        try:\n",
    "            # CRITICAL: Use retain_graph=False and no double backward pass\n",
    "            loss.backward(retain_graph=False)\n",
    "            self.optimizer.step()\n",
    "        except Exception as e:\n",
    "            print(f\"\\nBackward pass failed at batch {batch_num}: {e}\")\n",
    "            break\n",
    "\n",
    "        # Update the lr for the next step\n",
    "        lr *= mult\n",
    "        self.optimizer.param_groups[0]['lr'] = lr\n",
    "        \n",
    "        # Stop after reasonable number of batches to avoid infinite loops\n",
    "        if batch_num >= 100:\n",
    "            print(\"\\nStopping after 100 batches\")\n",
    "            break\n",
    "\n",
    "    print()\n",
    "    print('    Completed test.')\n",
    "    return self\n",
    "\n",
    "# Apply the complete fix\n",
    "import lr_range_test\n",
    "lr_range_test.LRRangeTest.run = completely_fixed_lr_test_run\n",
    "print(\"Applied COMPLETE fix to LRRangeTest.run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Using GPU-COMPATIBLE FIXED lr_test.run method\n",
      ">>> Compute loss at increasing LR values\n",
      "    Iterate over mini-batches: 22\n",
      "    Completed test.\n",
      "CPU times: user 702 ms, sys: 234 ms, total: 936 ms\n",
      "Wall time: 2.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)  # Disable anomaly detection too\n",
    "gpu_multisurv.test_lr_range()  # Use the new GPU instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loss values collected: 22\n",
      "Number of learning rates tested: 22\n",
      "LR range: 1.00e-06 to 1.00e+01\n",
      "Loss range: 0.048564 to 0.059517\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the results\n",
    "print(f\"Number of loss values collected: {len(gpu_multisurv.lr_test.losses)}\")\n",
    "print(f\"Number of learning rates tested: {len(gpu_multisurv.lr_test.lrs)}\")\n",
    "print(f\"LR range: {min(gpu_multisurv.lr_test.lrs):.2e} to {max(gpu_multisurv.lr_test.lrs):.2e}\")\n",
    "print(f\"Loss range: {min(gpu_multisurv.lr_test.losses):.6f} to {max(gpu_multisurv.lr_test.losses):.6f}\")\n",
    "\n",
    "# Plot the results to find optimal learning rate\n",
    "gpu_multisurv.plot_lr_range(trim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Fix for the _predictions_to_pycox method in coach.py\n",
    "\n",
    "def fixed_predictions_to_pycox(self, preds, time_points=None):\n",
    "    \"\"\"Fixed version that properly handles the DataFrame structure.\"\"\"\n",
    "    import pandas as pd\n",
    "    import torch\n",
    "    \n",
    "    # preds shape is [num_patients, num_intervals] e.g., [864, 18]\n",
    "    # Convert predictions to DataFrame\n",
    "    df = pd.DataFrame(preds.cpu().numpy())\n",
    "    \n",
    "    if time_points is None:\n",
    "        # Get the number of intervals from the model output\n",
    "        n_intervals = preds.shape[1]  # Should be 18 for your model\n",
    "        \n",
    "        # Use the model's actual output intervals\n",
    "        if hasattr(self, 'output_intervals') and self.output_intervals is not None:\n",
    "            # Use the midpoints of the output intervals\n",
    "            intervals = self.output_intervals\n",
    "            if len(intervals) > n_intervals:\n",
    "                # Take the first n_intervals midpoints\n",
    "                midpoints = (intervals[:-1] + intervals[1:]) / 2\n",
    "                time_points = midpoints[:n_intervals]\n",
    "            else:\n",
    "                # Fallback to evenly spaced points\n",
    "                time_points = torch.linspace(0.5, intervals[-1].item() / 365, n_intervals)\n",
    "        else:\n",
    "            # Fallback: create time points that match the output size\n",
    "            time_points = torch.arange(0.5, 0.5 + n_intervals, 1.0)\n",
    "    \n",
    "    # Ensure time_points matches the prediction dimensions\n",
    "    if len(time_points) != preds.shape[1]:\n",
    "        print(f\"Warning: Adjusting time_points from {len(time_points)} to {preds.shape[1]}\")\n",
    "        time_points = torch.linspace(time_points[0], time_points[-1], preds.shape[1])\n",
    "    \n",
    "    # FIXED: The DataFrame structure should be transposed\n",
    "    # We want columns to be time points, rows to be patients\n",
    "    df = df.T  # Transpose so shape becomes [num_intervals, num_patients]\n",
    "    \n",
    "    # Convert time_points to numpy if it's a tensor\n",
    "    if torch.is_tensor(time_points):\n",
    "        time_points = time_points.cpu().numpy()\n",
    "    \n",
    "    # Set the index to time points\n",
    "    df.index = time_points\n",
    "    df.index.name = 'time'\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the fix to ModelCoach\n",
    "from coach import ModelCoach\n",
    "ModelCoach._predictions_to_pycox = fixed_predictions_to_pycox\n",
    "print(\"Applied corrected fix to ModelCoach._predictions_to_pycox method\")\n",
    "\n",
    "# Debug info\n",
    "print(f\"Model output intervals shape: {len(gpu_multisurv.output_intervals)}\")\n",
    "print(f\"Model risk layer output: {gpu_multisurv.model.risk_layer[0].out_features}\")\n",
    "print(f\"Expected: {len(gpu_multisurv.output_intervals) - 1} intervals for {len(gpu_multisurv.output_intervals)} breakpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Applied GPU-compatible fix to ModelCoach._predictions_to_pycox method\n",
      "Model output intervals shape: 18\n",
      "Model output intervals device: cuda:0\n",
      "Model risk layer output: 17\n",
      "Expected: 17 intervals for 18 breakpoints\n"
     ]
    }
   ],
   "source": [
    "# GPU-compatible fix for _predictions_to_pycox method\n",
    "def gpu_fixed_predictions_to_pycox(self, preds, time_points=None):\n",
    "    \"\"\"GPU-compatible version that properly handles device transfers.\"\"\"\n",
    "    import pandas as pd\n",
    "    import torch\n",
    "    \n",
    "    # preds shape is [num_patients, num_intervals] e.g., [864, 18]\n",
    "    # Convert predictions to DataFrame (move to CPU first)\n",
    "    df = pd.DataFrame(preds.detach().cpu().numpy())  # Added .detach() for GPU tensors\n",
    "    \n",
    "    if time_points is None:\n",
    "        # Get the number of intervals from the model output\n",
    "        n_intervals = preds.shape[1]  # Should be 18 for your model\n",
    "        \n",
    "        # Use the model's actual output intervals\n",
    "        if hasattr(self, 'output_intervals') and self.output_intervals is not None:\n",
    "            # Handle GPU tensors properly\n",
    "            intervals = self.output_intervals\n",
    "            if torch.is_tensor(intervals):\n",
    "                intervals = intervals.detach().cpu()  # Move to CPU for calculations\n",
    "            \n",
    "            if len(intervals) > n_intervals:\n",
    "                # Take the first n_intervals midpoints\n",
    "                midpoints = (intervals[:-1] + intervals[1:]) / 2\n",
    "                time_points = midpoints[:n_intervals]\n",
    "            else:\n",
    "                # Fallback to evenly spaced points\n",
    "                last_interval = intervals[-1].item() if torch.is_tensor(intervals) else intervals[-1]\n",
    "                time_points = torch.linspace(0.5, last_interval / 365, n_intervals)\n",
    "        else:\n",
    "            # Fallback: create time points that match the output size\n",
    "            time_points = torch.arange(0.5, 0.5 + n_intervals, 1.0)\n",
    "    \n",
    "    # Ensure time_points matches the prediction dimensions\n",
    "    if len(time_points) != preds.shape[1]:\n",
    "        print(f\"Warning: Adjusting time_points from {len(time_points)} to {preds.shape[1]}\")\n",
    "        first_point = time_points[0].item() if torch.is_tensor(time_points) else time_points[0]\n",
    "        last_point = time_points[-1].item() if torch.is_tensor(time_points) else time_points[-1]\n",
    "        time_points = torch.linspace(first_point, last_point, preds.shape[1])\n",
    "    \n",
    "    # FIXED: The DataFrame structure should be transposed\n",
    "    # We want columns to be time points, rows to be patients\n",
    "    df = df.T  # Transpose so shape becomes [num_intervals, num_patients]\n",
    "    \n",
    "    # Convert time_points to numpy if it's a tensor (ensure CPU)\n",
    "    if torch.is_tensor(time_points):\n",
    "        time_points = time_points.detach().cpu().numpy()\n",
    "    \n",
    "    # Set the index to time points\n",
    "    df.index = time_points\n",
    "    df.index.name = 'time'\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the GPU-compatible fix to ModelCoach\n",
    "from coach import ModelCoach\n",
    "ModelCoach._predictions_to_pycox = gpu_fixed_predictions_to_pycox\n",
    "print(\"✅ Applied GPU-compatible fix to ModelCoach._predictions_to_pycox method\")\n",
    "\n",
    "# Debug info with GPU handling\n",
    "print(f\"Model output intervals shape: {len(gpu_multisurv.output_intervals)}\")\n",
    "print(f\"Model output intervals device: {gpu_multisurv.output_intervals.device}\")\n",
    "print(f\"Model risk layer output: {gpu_multisurv.model.risk_layer[0].out_features}\")\n",
    "print(f\"Expected: {len(gpu_multisurv.output_intervals) - 1} intervals for {len(gpu_multisurv.output_intervals)} breakpoints\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "import os\n",
    "import time\n",
    "import utils\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# 2. Set up training parameters\n",
    "picked_lr = 5e-3\n",
    "\n",
    "# Add timestamp to make unique run tags\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "run_tag = utils.compose_run_tag(\n",
    "    model=gpu_multisurv, \n",
    "    lr=picked_lr,\n",
    "    dataloaders=gpu_multisurv.dataloaders,\n",
    "    log_dir='./training_logs/',\n",
    "    suffix=f'_breast_cancer_{timestamp}'  # Add timestamp\n",
    ")\n",
    "\n",
    "# 3. Create log directory (now it will be unique)\n",
    "log_dir = os.path.join('./training_logs/', run_tag)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "print(f\"Log directory created: {log_dir}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "fit_args = {\n",
    "    'lr': picked_lr,\n",
    "    'num_epochs': 75,\n",
    "    'info_freq': 5,\n",
    "    'lr_factor': 0.5,\n",
    "    'scheduler_patience': 10,\n",
    "    'log_dir': log_dir,  # Use the verified directory\n",
    "}\n",
    "\n",
    "print(f\"Starting training with LR: {picked_lr}\")\n",
    "\n",
    "# 4. Train the model\n",
    "gpu_multisurv.fit(**fit_args)\n",
    "\n",
    "# 5. Calculate and display elapsed time\n",
    "hrs, mins, secs = utils.elapsed_time(start_time)\n",
    "print(f\"Training completed in {hrs}h {mins}m {secs}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PRE-TRAINING GPU VERIFICATION ===\n",
      "GPU model device: cuda:0\n",
      "GPU intervals device: cuda:0\n",
      "GPU device setting: cuda:0\n",
      "GPU memory before training: 0.21 GB\n",
      "Run tag: \"clinical_lr0.001_breast_cancer_gpu_20250620_161530\"\n",
      "✅ Log directory created: ./training_logs/clinical_lr0.001_breast_cancer_gpu_20250620_161530\n",
      "✅ Setup complete - ready for GPU training!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup with GPU verification\n",
    "import os\n",
    "import time\n",
    "import utils\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# 2. Verify GPU setup before training\n",
    "print(\"=== PRE-TRAINING GPU VERIFICATION ===\")\n",
    "print(f\"GPU model device: {next(gpu_multisurv.model.parameters()).device}\")\n",
    "print(f\"GPU intervals device: {gpu_multisurv.output_intervals.device}\")\n",
    "print(f\"GPU device setting: {gpu_multisurv.device}\")\n",
    "\n",
    "# Check GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "    print(f\"GPU memory before training: {allocated:.2f} GB\")\n",
    "\n",
    "# 3. Set up training parameters\n",
    "picked_lr = 1e-3\n",
    "\n",
    "# Add timestamp to make unique run tags\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "run_tag = utils.compose_run_tag(\n",
    "    model=gpu_multisurv, \n",
    "    lr=picked_lr,\n",
    "    dataloaders=gpu_multisurv.dataloaders,\n",
    "    log_dir='./training_logs/',\n",
    "    suffix=f'_breast_cancer_gpu_{timestamp}'  # Added 'gpu' to indicate GPU training\n",
    ")\n",
    "\n",
    "# 4. Create log directory\n",
    "log_dir = os.path.join('./training_logs/', run_tag)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "print(f\"✅ Log directory created: {log_dir}\")\n",
    "\n",
    "print(\"✅ Setup complete - ready for GPU training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting GPU training with LR: 0.001\n",
      "📊 Expected to see GPU utilization spike during training\n",
      "📁 Logs will be saved to: ./training_logs/clinical_lr0.001_breast_cancer_gpu_20250620_161530\n",
      "\n",
      "=== GPU STATUS BEFORE TRAINING ===\n",
      "🎯 GPU Memory: 0.21 GB allocated, 0.28 GB reserved\n",
      "\n",
      "⏰ Training started at: 16:15:33\n",
      "Instantiating MultiSurv model...\n",
      "\n",
      "------------------------------------------\n",
      "             Training        Validation\n",
      "           ------------     ------------\n",
      " Epoch     Loss     Ctd     Loss     Ctd\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/multisurv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/100    0.0318   0.430   0.0166   0.699\n",
      " 5/100    0.0206   0.502   0.0203   0.719\n",
      " 10/100   0.0191   0.520   0.0161   0.576\n",
      " 15/100   0.0183   0.593   0.0185   0.656\n",
      " 20/100   0.0191   0.596   0.0172   0.558\n",
      " 25/100   0.0187   0.533   0.0152   0.627\n",
      " 30/100   0.0159   0.638   0.0154   0.660\n",
      " 35/100   0.0160   0.659   0.0156   0.669\n",
      " 40/100   0.0156   0.600   0.0164   0.702\n",
      " 45/100   0.0150   0.635   0.0170   0.671\n",
      " 50/100   0.0161   0.624   0.0162   0.641\n",
      " 55/100   0.0161   0.573   0.0158   0.693\n",
      " 60/100   0.0153   0.655   0.0164   0.668\n",
      " 65/100   0.0150   0.662   0.0166   0.681\n",
      " 70/100   0.0158   0.540   0.0164   0.662\n",
      " 75/100   0.0148   0.657   0.0168   0.652\n",
      " 80/100   0.0153   0.631   0.0164   0.726\n",
      " 85/100   0.0159   0.607   0.0159   0.740\n",
      " 90/100   0.0147   0.667   0.0164   0.688\n",
      " 95/100   0.0140   0.707   0.0160   0.697\n",
      " 100/100  0.0138   0.686   0.0162   0.707\n",
      "\n",
      ">>>>> Training completed in 4m 52s\n",
      ">>>>> Best validation C-indices:\n",
      "     0.7452934662236987 (epoch47)\n",
      "     0.7685492801771872 (epoch68)\n",
      "     0.7397563676633444 (epoch85)\n",
      "\n",
      "✅ Training completed successfully!\n",
      "\n",
      "=== GPU STATUS AFTER TRAINING ===\n",
      "🎯 GPU Memory: 0.41 GB allocated, 0.54 GB reserved\n",
      "\n",
      "⏰ Training completed in 0h 4m 55s\n",
      "🏁 Training finished at: 16:20:26\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Training execution with GPU monitoring\n",
    "fit_args = {\n",
    "    'lr': picked_lr,\n",
    "    'num_epochs': 100,\n",
    "    'info_freq': 5,\n",
    "    'lr_factor': 0.5,\n",
    "    'scheduler_patience': 20,\n",
    "    'log_dir': log_dir,\n",
    "}\n",
    "\n",
    "print(f\"🚀 Starting GPU training with LR: {picked_lr}\")\n",
    "print(f\"📊 Expected to see GPU utilization spike during training\")\n",
    "print(f\"📁 Logs will be saved to: {log_dir}\")\n",
    "\n",
    "# Function to monitor GPU during training\n",
    "def check_gpu_status():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "        reserved = torch.cuda.memory_reserved(0) / 1024**3\n",
    "        print(f\"🎯 GPU Memory: {allocated:.2f} GB allocated, {reserved:.2f} GB reserved\")\n",
    "    else:\n",
    "        print(\"❌ CUDA not available\")\n",
    "\n",
    "# Check GPU before training\n",
    "print(\"\\n=== GPU STATUS BEFORE TRAINING ===\")\n",
    "check_gpu_status()\n",
    "\n",
    "# Clear any cached memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Start training\n",
    "print(f\"\\n⏰ Training started at: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "\n",
    "try:\n",
    "    # This is where the actual training happens\n",
    "    gpu_multisurv.fit(**fit_args)\n",
    "    \n",
    "    print(f\"\\n✅ Training completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Training failed with error: {e}\")\n",
    "    print(\"This might be due to GPU memory issues or device mismatches\")\n",
    "    # Print more debug info\n",
    "    print(f\"Model device: {next(gpu_multisurv.model.parameters()).device}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# Check GPU after training\n",
    "print(\"\\n=== GPU STATUS AFTER TRAINING ===\")\n",
    "check_gpu_status()\n",
    "\n",
    "# Calculate and display elapsed time\n",
    "hrs, mins, secs = utils.elapsed_time(start_time)\n",
    "print(f\"\\n⏰ Training completed in {hrs}h {mins}m {secs}s\")\n",
    "print(f\"🏁 Training finished at: {datetime.now().strftime('%H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model weights\n",
    "\n",
    "If desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch47', 'epoch68', 'epoch85'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_multisurv.best_model_weights.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch47': 0.7452934662236987,\n",
       " 'epoch68': 0.7685492801771872,\n",
       " 'epoch85': 0.7397563676633444}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_multisurv.best_concord_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch100': 0.7065337763012182}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_multisurv.current_concord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model weights to file:\n",
      "    /mnt/data/multisurv_models/clinical_lr0.001_breast_cancer_gpu_20250620_161530_epoch68_concord0.77.pth\n"
     ]
    }
   ],
   "source": [
    "gpu_multisurv.save_weights(saved_epoch='epoch68', prefix=run_tag, weight_dir=MODELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Applied fix to _BaseEvaluation._predictions_to_pycox\n",
      "✅ Applied fix to Evaluation._predictions_to_pycox\n",
      "💡 Note: There's a syntax warning in evaluation.py line 187\n",
      "   Change 'self.type is not 'MultiSurv'' to 'self.type != 'MultiSurv''\n",
      "   This doesn't affect functionality but should be fixed in the source code\n",
      "\n",
      "🔧 Evaluation fixes applied! Now try running your evaluation again.\n"
     ]
    }
   ],
   "source": [
    "# Fix for evaluation.py _predictions_to_pycox method\n",
    "\n",
    "def fixed_evaluation_predictions_to_pycox(self, data, time_points=None):\n",
    "    \"\"\"Fixed evaluation version that handles the correct dimensions.\"\"\"\n",
    "    import pandas as pd\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    \n",
    "    # Extract predictions from data\n",
    "    # data should be a list of tuples: (predictions, times, events, patient_ids)\n",
    "    predictions_list = []\n",
    "    for item in data:\n",
    "        pred = item[0]  # The prediction tensor\n",
    "        if torch.is_tensor(pred):\n",
    "            pred = pred.detach().cpu().numpy()\n",
    "        predictions_list.append(pred)\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    predictions = np.array(predictions_list)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(predictions)\n",
    "    \n",
    "    if time_points is None:\n",
    "        # Get the number of intervals from the model output\n",
    "        n_intervals = predictions.shape[1]  # Should be 18 for your model\n",
    "        \n",
    "        # Use the model's actual output intervals if available\n",
    "        if hasattr(self, 'model') and hasattr(self.model, 'output_intervals') and self.model.output_intervals is not None:\n",
    "            # Use the midpoints of the output intervals\n",
    "            intervals = self.model.output_intervals\n",
    "            if torch.is_tensor(intervals):\n",
    "                intervals = intervals.detach().cpu().numpy()\n",
    "            \n",
    "            if len(intervals) > n_intervals:\n",
    "                # Take the first n_intervals midpoints\n",
    "                midpoints = (intervals[:-1] + intervals[1:]) / 2\n",
    "                time_points = midpoints[:n_intervals]\n",
    "            else:\n",
    "                # Fallback to evenly spaced points\n",
    "                last_interval = intervals[-1] if not torch.is_tensor(intervals) else intervals[-1].item()\n",
    "                time_points = np.linspace(0.5, last_interval / 365, n_intervals)\n",
    "        else:\n",
    "            # Fallback: create time points that match the output size\n",
    "            time_points = np.arange(0.5, 0.5 + n_intervals, 1.0)\n",
    "    \n",
    "    # Ensure time_points matches the prediction dimensions\n",
    "    if len(time_points) != predictions.shape[1]:\n",
    "        print(f\"Warning: Adjusting time_points from {len(time_points)} to {predictions.shape[1]}\")\n",
    "        first_point = time_points[0] if len(time_points) > 0 else 0.5\n",
    "        last_point = time_points[-1] if len(time_points) > 0 else n_intervals + 0.5\n",
    "        time_points = np.linspace(first_point, last_point, predictions.shape[1])\n",
    "    \n",
    "    # FIXED: The DataFrame structure should be transposed\n",
    "    # We want columns to be time points, rows to be patients\n",
    "    df = df.T  # Transpose so shape becomes [num_intervals, num_patients]\n",
    "    \n",
    "    # Convert time_points to numpy if it's a tensor\n",
    "    if torch.is_tensor(time_points):\n",
    "        time_points = time_points.detach().cpu().numpy()\n",
    "    \n",
    "    # Set the index to time points\n",
    "    df.index = time_points\n",
    "    df.index.name = 'time'\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the fix to the evaluation module\n",
    "import evaluation\n",
    "\n",
    "# Check if the _BaseEvaluation class exists and patch it\n",
    "if hasattr(evaluation, '_BaseEvaluation'):\n",
    "    evaluation._BaseEvaluation._predictions_to_pycox = fixed_evaluation_predictions_to_pycox\n",
    "    print(\"✅ Applied fix to _BaseEvaluation._predictions_to_pycox\")\n",
    "else:\n",
    "    print(\"❌ _BaseEvaluation class not found\")\n",
    "\n",
    "# Also check for Evaluation class\n",
    "if hasattr(evaluation, 'Evaluation'):\n",
    "    evaluation.Evaluation._predictions_to_pycox = fixed_evaluation_predictions_to_pycox\n",
    "    print(\"✅ Applied fix to Evaluation._predictions_to_pycox\")\n",
    "\n",
    "# Fix the syntax warning too\n",
    "def patch_syntax_warning():\n",
    "    \"\"\"Fix the syntax warning in evaluation.py if possible.\"\"\"\n",
    "    print(\"💡 Note: There's a syntax warning in evaluation.py line 187\")\n",
    "    print(\"   Change 'self.type is not 'MultiSurv'' to 'self.type != 'MultiSurv''\")\n",
    "    print(\"   This doesn't affect functionality but should be fixed in the source code\")\n",
    "\n",
    "patch_syntax_warning()\n",
    "\n",
    "print(\"\\n🔧 Evaluation fixes applied! Now try running your evaluation again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Applied clinical data shape fix to Evaluation._get_patient_predictions\n"
     ]
    }
   ],
   "source": [
    "# Fix the data shape issue in get_patient_predictions\n",
    "def fixed_get_patient_predictions(self, idx):\n",
    "    \"\"\"Fixed version that handles 1D continuous tensor correctly.\"\"\"\n",
    "    patient_data = self.dataset[idx]\n",
    "    data_dict, time, event = patient_data\n",
    "    \n",
    "    # Create batch data\n",
    "    batch_data = {}\n",
    "    for key, value in data_dict.items():\n",
    "        if key == 'clinical' and isinstance(value, tuple):\n",
    "            cat, cont = value\n",
    "            # Fix: ensure continuous is 2D [1, n_features]\n",
    "            if cont.dim() == 1:\n",
    "                cont = cont.unsqueeze(0)\n",
    "            batch_data[key] = (cat.unsqueeze(0).to(self.device), \n",
    "                              cont.unsqueeze(0).to(self.device))\n",
    "        else:\n",
    "            batch_data[key] = value.unsqueeze(0).to(self.device)\n",
    "    \n",
    "    # Get prediction\n",
    "    with torch.no_grad():\n",
    "        _, risk = self.model.model(batch_data)\n",
    "    \n",
    "    return risk.squeeze(0).cpu()\n",
    "\n",
    "# Apply the fix\n",
    "import evaluation\n",
    "evaluation.Evaluation._get_patient_predictions = fixed_get_patient_predictions\n",
    "print(\"✅ Applied clinical data shape fix to Evaluation._get_patient_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Applied final fix for nested dictionary structure\n"
     ]
    }
   ],
   "source": [
    "# Final fix for _predictions_to_pycox\n",
    "def fixed_evaluation_predictions_to_pycox_final(self, data, time_points=None):\n",
    "    \"\"\"Fixed version that handles the nested dictionary structure.\"\"\"\n",
    "    import pandas as pd\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    \n",
    "    # Extract predictions from the nested dictionary structure\n",
    "    predictions_list = []\n",
    "    times_list = []\n",
    "    events_list = []\n",
    "    patient_ids = []\n",
    "    \n",
    "    for patient_id, patient_data in data.items():\n",
    "        if isinstance(patient_data, dict):\n",
    "            # Extract probabilities from the dictionary\n",
    "            prob = patient_data['probabilities']\n",
    "            if torch.is_tensor(prob):\n",
    "                prob = prob.detach().cpu().numpy()\n",
    "            predictions_list.append(prob)\n",
    "            \n",
    "            # Also collect times and events for verification\n",
    "            times_list.append(patient_data['time'])\n",
    "            events_list.append(patient_data['event'])\n",
    "            patient_ids.append(patient_id)\n",
    "        else:\n",
    "            # Fallback for other formats\n",
    "            if torch.is_tensor(patient_data):\n",
    "                predictions_list.append(patient_data.detach().cpu().numpy())\n",
    "            else:\n",
    "                predictions_list.append(patient_data[0])\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    predictions = np.array(predictions_list)\n",
    "    print(f\"Extracted predictions shape: {predictions.shape}\")\n",
    "    \n",
    "    # Create DataFrame with patients as rows, time intervals as columns\n",
    "    df = pd.DataFrame(predictions)\n",
    "    \n",
    "    if time_points is None:\n",
    "        n_intervals = predictions.shape[1]\n",
    "        \n",
    "        # Use the model's actual output intervals if available\n",
    "        if hasattr(self, 'model') and hasattr(self.model, 'output_intervals') and self.model.output_intervals is not None:\n",
    "            intervals = self.model.output_intervals\n",
    "            if torch.is_tensor(intervals):\n",
    "                intervals = intervals.detach().cpu().numpy()\n",
    "            \n",
    "            # Create midpoints for time intervals\n",
    "            if len(intervals) == n_intervals + 1:\n",
    "                # intervals are boundaries, we need midpoints\n",
    "                time_points = (intervals[:-1] + intervals[1:]) / 2\n",
    "            else:\n",
    "                # Fallback\n",
    "                time_points = np.linspace(0.5, 20, n_intervals)\n",
    "        else:\n",
    "            # Fallback: create evenly spaced time points\n",
    "            time_points = np.arange(0.5, 0.5 + n_intervals, 1.0)\n",
    "    \n",
    "    # Ensure time_points matches prediction dimensions\n",
    "    if len(time_points) != predictions.shape[1]:\n",
    "        time_points = np.linspace(0.5, 20, predictions.shape[1])\n",
    "    \n",
    "    # Transpose so time is the index (required by pycox)\n",
    "    df = df.T\n",
    "    df.index = time_points\n",
    "    df.index.name = 'time'\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the final fix\n",
    "import evaluation\n",
    "evaluation.Evaluation._predictions_to_pycox = fixed_evaluation_predictions_to_pycox_final\n",
    "print(\"✅ Applied final fix for nested dictionary structure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_weights() got an unexpected keyword argument 'epoch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmultisurv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch68\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODELS\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: load_weights() got an unexpected keyword argument 'epoch'"
     ]
    }
   ],
   "source": [
    "multisurv.load_weights(epoch='epoch68', weight_dir=MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collect patient predictions: 165/165\n",
      "\n",
      "Extracted predictions shape: (165, 17)\n",
      "C-index   0.685\n",
      "Ctd       0.685\n",
      "IBS       0.222\n",
      "INBLL     0.907\n"
     ]
    }
   ],
   "source": [
    "performance = utils.Evaluation(\n",
    "    model=gpu_multisurv, dataset=dataloaders['val'].dataset,\n",
    "    device=device)\n",
    "performance.compute_metrics()\n",
    "performance.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collect patient predictions: 219/219\n",
      "\n",
      "Extracted predictions shape: (219, 17)\n",
      "TEST SET RESULTS:\n",
      "C-index   0.581\n",
      "Ctd       0.58\n",
      "IBS       0.31\n",
      "INBLL     1.254\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on TEST set (not validation)\n",
    "performance = utils.Evaluation(\n",
    "    model=gpu_multisurv, \n",
    "    dataset=dataloaders['test'].dataset,  # Note: 'test' not 'val'\n",
    "    device=device\n",
    ")\n",
    "performance.compute_metrics()\n",
    "print(\"TEST SET RESULTS:\")\n",
    "performance.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watermark <a class='tocSkip'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark --iversions\n",
    "%watermark -v\n",
    "print()\n",
    "%watermark -u -n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of the page](#Top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "197px",
    "width": "372px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "236px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
